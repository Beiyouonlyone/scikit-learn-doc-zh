

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

    <title>5. 数据集加载工具 &#8212; scikit-learn 0.19.0 中文文档 - ApacheCN</title>
<!-- htmltitle is before nature.css - we use this hack to load bootstrap first -->
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="stylesheet" href="../_static/css/bootstrap.min.css" media="screen" />
<link rel="stylesheet" href="../_static/css/bootstrap-responsive.css"/>

    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/js/copybutton.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5.6.1. Olivetti 脸部数据集" href="olivetti_faces.html" />
    <link rel="prev" title="4.8. 预测目标 (y) 的转换" href="../modules/preprocessing_targets.html" />


<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<script src="../_static/js/bootstrap.min.js" type="text/javascript"></script>
<link rel="canonical" href="http://scikit-learn.org/stable/datasets/index.html" />

<script type="text/javascript">
  $("div.buttonNext, div.buttonPrevious").hover(
     function () {
         $(this).css('background-color', '#FF9C34');
     },
     function () {
         $(this).css('background-color', '#A7D6E2');
     }
  );
  function showMenu() {
    var topNav = document.getElementById("scikit-navbar");
    if (topNav.className === "navbar") {
        topNav.className += " responsive";
    } else {
        topNav.className = "navbar";
    }
  };
</script>

  </head><body>

<div class="header-wrapper">
  <div class="header">
      <p class="logo"><a href="../index.html">
          <img src="../_static/scikit-learn-logo-small.png" alt="Logo"/>
      </a>
      </p><div class="navbar" id="scikit-navbar">
          <ul>
              <li><a href="../index.html">首页</a></li>
              <li><a href="../install.html">安装</a></li>
              <li class="btn-li">
                <div class="btn-group">
                    <a href="../documentation.html">文档</a>
                    <a class="btn dropdown-toggle" data-toggle="dropdown">
                      <span class="caret"></span>
                    </a>
                    <ul class="dropdown-menu">
                      <li class="link-title">Scikit-learn 0.19</li>
                      <li><a href="../tutorial/index.html">教程</a></li>
                      <li><a href="../user_guide.html">用户指南</a></li>
                      <li><a href="../modules/classes.html">API</a></li>
                      <li><a href="../faq.html">FAQ</a></li>
                      <li><a href="../developers/contributing.html">贡献</a></li>
                      <li class="divider"></li>
                      <li><a href="http://scikit-learn.org/stable/documentation.html">Scikit-learn 0.19 (stable)</a></li>
                      <li><a href="http://scikit-learn.org/0.18/documentation.html">Scikit-learn 0.18</a></li>
                      <li><a href="http://scikit-learn.org/0.17/documentation.html">Scikit-learn 0.17</a></li>
                      <li><a href="../_downloads/scikit-learn-docs.pdf">PDF 文档</a></li>
                    </ul>
                </div>
              </li>
              <li><a href="../auto_examples/index.html">示例</a></li>
              <li><a href="../project-timeline.html">时光轴</a></li>
              <li class="btn-li">
                <div class="btn-group">
                    <a href="javascript:void(0)">项目相关</a>
                    <a class="btn dropdown-toggle" data-toggle="dropdown">
                      <span class="caret"></span>
                    </a>
                    <ul class="dropdown-menu">
                      <li><a href="../project-role.html">项目角色</a></li>
                      <li><a href="../project-check-progress.html">校验进度</a></li>
                      <li><a href="../project-translation-progress.html">翻译进度</a></li>
                      <li><a href="//github.com/apachecn/scikit-learn-doc-zh#%E8%B4%A1%E7%8C%AE%E8%80%85" target="_blank">贡献者</a></li>
                      <li class="divider"></li>
                      <li><a href="../project-timeline.html">时光轴</a></li>
                      <li class="divider"></li>
                      <li><a href="../project-reward.html">项目奖励</a></li>
                      <li class="divider"></li>
                      <li><a href="http://www.apachecn.org/organization/244.html" target="_blank">积分物品</a></li>
                      <li><a href="http://www.apachecn.org/organization/269.html" target="_blank">兑换记录</a></li>
                      <li class="divider"></li>
                      <li><a href="../project-feedback.html">建议反馈</a></li>
                      <li><a href="../project-communication-group.html">技术交流</a></li>
                    </ul>
                </div>
              </li>
              <li><a href="//github.com/apachecn/scikit-learn-doc-zh#%E8%B4%A1%E7%8C%AE%E8%80%85" target="_blank">贡献者</a></li>
              <li><a href="//github.com/apachecn/scikit-learn-doc-zh" target="_blank">GitHub</a></li>
          </ul>
          <a href="javascript:void(0);" onclick="showMenu()">
              <div class="nav-icon">
                  <div class="hamburger-line"></div>
                  <div class="hamburger-line"></div>
                  <div class="hamburger-line"></div>
              </div>
          </a>
          <div class="search_form">
              <div class="gcse-search" id="cse" style="width: 100%;"></div>
          </div>
      </div> <!-- end navbar --></div>
</div>


<!-- Github "fork me" ribbon -->
<a href="https://github.com/apachecn/scikit-learn-doc-zh">
<img class="fork-me"
     style="position: absolute; top: 0; right: 0; border: 0;"
     src="../_static/img/starme.png"
     alt="Star me on GitHub" />
</a>

<div class="content-wrapper">
  <div class="sphinxsidebar">
  <div class="sphinxsidebarwrapper">
      <div class="rel">
  
      <div class="rellink">
      <a href="../modules/preprocessing_targets.html"
      accesskey="P">Previous
      <br/>
      <span class="smallrellink">
      4.8. 预测目标 (y) 的转换
      </span>
          <span class="hiddenrellink">
          4.8. 预测目标 (y) 的转换
          </span>
      </a>
      </div>
          <div class="spacer">
          &nbsp;
          </div>
      <div class="rellink">
      <a href="olivetti_faces.html"
      accesskey="N">Next
      <br/>
      <span class="smallrellink">
      5.6.1. Olivetti 脸部数据集
      </span>
          <span class="hiddenrellink">
          5.6.1. Olivetti 脸部数据集
          </span>
      </a>
      </div>

  <!-- Ad a link to the 'up' page -->
      <div class="spacer">
      &nbsp;
      </div>
      <div class="rellink">
      <a href="../user_guide.html">
      Up
      <br/>
      <span class="smallrellink">
      用户指南
      </span>
          <span class="hiddenrellink">
          用户指南
          </span>
          
      </a>
      </div>
  </div>
  
    <p class="doc-version"><b>scikit-learn v0.19.0</b><br/>
    <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
  <p class="citing">Please <b><a href="../about.html#citing-scikit-learn" style="font-size: 110%;">cite us </a></b>if you use the software.</p>
  <ul>
<li><a class="reference internal" href="#">5. 数据集加载工具</a><ul>
<li><a class="reference internal" href="#api">5.1. 通用数据集 API</a></li>
<li><a class="reference internal" href="#id4">5.2. 玩具数据集</a></li>
<li><a class="reference internal" href="#sample-images">5.3. 样本图片</a></li>
<li><a class="reference internal" href="#sample-generators">5.4. 样本生成器</a><ul>
<li><a class="reference internal" href="#id7">5.4.1. 分类和聚类生成器</a><ul>
<li><a class="reference internal" href="#id8">5.4.1.1. 单标签</a></li>
<li><a class="reference internal" href="#id11">5.4.1.2. 多标签</a></li>
<li><a class="reference internal" href="#id12">5.4.1.3. 二分聚类</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id13">5.4.2. 回归生成器</a></li>
<li><a class="reference internal" href="#id14">5.4.3. 流形学习生成器</a></li>
<li><a class="reference internal" href="#id15">5.4.4. 生成器分解</a></li>
</ul>
</li>
<li><a class="reference internal" href="#datasets-in-svmlight-libsvm-format">5.5. Datasets in svmlight / libsvm format</a></li>
<li><a class="reference internal" href="#external-datasets">5.6. 从外部数据集加载</a></li>
<li><a class="reference internal" href="#olivetti">5.7. Olivetti 脸部数据集</a></li>
<li><a class="reference internal" href="#newsgroups">5.8. 20个新闻组文本数据集</a><ul>
<li><a class="reference internal" href="#id22">5.8.1. 用法</a></li>
<li><a class="reference internal" href="#id23">5.8.2. 将文本转换成向量</a></li>
<li><a class="reference internal" href="#id24">5.8.3. 过滤文本进行更加逼真的训练</a></li>
</ul>
</li>
<li><a class="reference internal" href="#mldata-org">5.9. 从 mldata.org 上下载数据集</a></li>
<li><a class="reference internal" href="#labeled-faces-in-the-wild">5.10. 带标签的人脸识别数据集</a><ul>
<li><a class="reference internal" href="#id30">5.10.1. 用法</a></li>
<li><a class="reference internal" href="#id33">5.10.2. 示例</a></li>
</ul>
</li>
<li><a class="reference internal" href="#covtype">5.11. 森林覆盖类型</a></li>
<li><a class="reference internal" href="#rcv1">5.12. RCV1 数据集</a></li>
<li><a class="reference internal" href="#boston-house-prices">5.13. 波士顿房价数据集</a><ul>
<li><a class="reference internal" href="#id40">5.13.1. 注释</a></li>
</ul>
</li>
<li><a class="reference internal" href="#breast-cancer">5.14. 威斯康辛州乳腺癌（诊断）数据库</a><ul>
<li><a class="reference internal" href="#id42">5.14.1. 注释</a></li>
<li><a class="reference internal" href="#id43">5.14.2. 参考资料</a></li>
</ul>
</li>
<li><a class="reference internal" href="#diabetes">5.15. 糖尿病数据集</a><ul>
<li><a class="reference internal" href="#id45">5.15.1. 注释</a></li>
</ul>
</li>
<li><a class="reference internal" href="#digits">5.16. 光学识别手写数字数据集</a><ul>
<li><a class="reference internal" href="#id47">5.16.1. 注释</a></li>
<li><a class="reference internal" href="#id48">5.16.2. 参考资料</a></li>
</ul>
</li>
<li><a class="reference internal" href="#iris">5.17. 鸢尾花数据集</a><ul>
<li><a class="reference internal" href="#id50">5.17.1. 注释</a></li>
<li><a class="reference internal" href="#id51">5.17.2. 参考资料</a></li>
</ul>
</li>
<li><a class="reference internal" href="#linnerrud">5.18. Linnerrud 数据集</a><ul>
<li><a class="reference internal" href="#id52">5.18.1. 注释</a></li>
<li><a class="reference internal" href="#id53">5.18.2. 参考资料</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </div>
</div>

<input type="checkbox" id="nav-trigger" class="nav-trigger" checked />
<label for="nav-trigger"></label>




    <div class="content">
          
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="datasets">
<span id="id1"></span><h1>5. 数据集加载工具<a class="headerlink" href="#datasets" title="Permalink to this headline">¶</a></h1>
<p>该 <code class="docutils literal notranslate"><span class="pre">sklearn.datasets</span></code> 包装在 <a class="reference internal" href="../tutorial/basic/tutorial.html#loading-example-dataset"><span class="std std-ref">Getting Started</span></a> 部分中嵌入了介绍一些小型玩具的数据集。</p>
<p>为了在控制数据的统计特性（通常是特征的 correlation （相关性）和 informativeness （信息性））的同时评估数据集 (<code class="docutils literal notranslate"><span class="pre">n_samples</span></code> 和 <code class="docutils literal notranslate"><span class="pre">n_features</span></code>) 的规模的影响，也可以生成综合数据。</p>
<p>这个软件包还具有帮助用户获取更大的数据集的功能，这些数据集通常由机器学习社区使用，用于对来自 ‘real world’ 的数据进行检测算法。</p>
<div class="section" id="api">
<h2>5.1. 通用数据集 API<a class="headerlink" href="#api" title="Permalink to this headline">¶</a></h2>
<p>对于不同类型的数据集，有三种不同类型的数据集接口。最简单的是样品图像的界面，下面在 <a class="reference internal" href="#sample-images"><span class="std std-ref">样本图片</span></a> 部分中进行了描述。</p>
<p>数据集生成函数和 svmlight 加载器分享了一个较为简化的接口，返回一个由 <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> * <code class="docutils literal notranslate"><span class="pre">n_features</span></code> 组成的 tuple <code class="docutils literal notranslate"><span class="pre">(X,</span> <span class="pre">y)</span></code> 其中的 <code class="docutils literal notranslate"><span class="pre">X</span></code> 是 numpy 数组 <code class="docutils literal notranslate"><span class="pre">y</span></code> 是包含目标值的长度为 <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> 的数组</p>
<p>玩具数据集以及 ‘real world’ 数据集和从 mldata.org 获取的数据集具有更复杂的结构。这些函数返回一个类似于字典的对象包含至少两项：一个具有 <code class="docutils literal notranslate"><span class="pre">data</span></code> 键（key）的 <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> * <code class="docutils literal notranslate"><span class="pre">n_features</span></code> 形状的数组（除了20个新组之外except for 20newsgroups）和一个具有 <code class="docutils literal notranslate"><span class="pre">target</span></code> 键（key）的包含 target values （目标值）的 <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> 长度的 numpy 数组。</p>
<p>数据集还包含一些对``DESCR`` 描述，同时一部分也包含 <code class="docutils literal notranslate"><span class="pre">feature_names</span></code> 和 <a href="#id2"><span class="problematic" id="id3">``</span></a>target_names``的特征。有关详细信息，请参阅下面的数据集说明</p>
</div>
<div class="section" id="id4">
<h2>5.2. 玩具数据集<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h2>
<p>scikit-learn 内置有一些小型标准数据集，不需要从某个外部网站下载任何文件。</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="../modules/generated/sklearn.datasets.load_boston.html#sklearn.datasets.load_boston" title="sklearn.datasets.load_boston"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_boston</span></code></a>([return_X_y])</td>
<td>Load and return the boston house-prices dataset (regression).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="../modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris" title="sklearn.datasets.load_iris"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_iris</span></code></a>([return_X_y])</td>
<td>Load and return the iris dataset (classification).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="../modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes" title="sklearn.datasets.load_diabetes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_diabetes</span></code></a>([return_X_y])</td>
<td>Load and return the diabetes dataset (regression).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="../modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits" title="sklearn.datasets.load_digits"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_digits</span></code></a>([n_class,&nbsp;return_X_y])</td>
<td>Load and return the digits dataset (classification).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="../modules/generated/sklearn.datasets.load_linnerud.html#sklearn.datasets.load_linnerud" title="sklearn.datasets.load_linnerud"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_linnerud</span></code></a>([return_X_y])</td>
<td>Load and return the linnerud dataset (multivariate regression).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="../modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine" title="sklearn.datasets.load_wine"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_wine</span></code></a>([return_X_y])</td>
<td>Load and return the wine dataset (classification).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="../modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer" title="sklearn.datasets.load_breast_cancer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_breast_cancer</span></code></a>([return_X_y])</td>
<td>Load and return the breast cancer wisconsin dataset (classification).</td>
</tr>
</tbody>
</table>
<p>这些数据集有助于快速说明在 scikit 中实现的各种算法的行为。然而，它们数据规模往往太小，无法代表真实世界的机器学习任务。</p>
</div>
<div class="section" id="sample-images">
<span id="id5"></span><h2>5.3. 样本图片<a class="headerlink" href="#sample-images" title="Permalink to this headline">¶</a></h2>
<p>scikit 在通过图片的作者共同授权下嵌入了几个样本 JPEG 图片。这些图像为了方便用户对 test algorithms （测试算法）和 pipeline on 2D data （二维数据管道）进行测试。</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="../modules/generated/sklearn.datasets.load_sample_images.html#sklearn.datasets.load_sample_images" title="sklearn.datasets.load_sample_images"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_sample_images</span></code></a>()</td>
<td>Load sample images for image manipulation.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="../modules/generated/sklearn.datasets.load_sample_image.html#sklearn.datasets.load_sample_image" title="sklearn.datasets.load_sample_image"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_sample_image</span></code></a>(image_name)</td>
<td>Load the numpy array of a single sample image</td>
</tr>
</tbody>
</table>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_color_quantization.html"><img alt="datasets/../auto_examples/cluster/images/sphx_glr_plot_color_quantization_001.png" class="align-right" src="datasets/../auto_examples/cluster/images/sphx_glr_plot_color_quantization_001.png" /></a>
<p>默认编码的图像是基于 <code class="docutils literal notranslate"><span class="pre">uint8</span></code> dtype 到空闲内存。通常，如果把输入转换为浮点数表示，机器学习算法的效果最好。另外，如果你计划使用 <code class="docutils literal notranslate"><span class="pre">matplotlib.pyplpt.imshow</span></code> 别忘了尺度范围 0 - 1，如下面的示例所做的。</p>
<div class="topic">
<p class="topic-title first">示例:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/cluster/plot_color_quantization.html#sphx-glr-auto-examples-cluster-plot-color-quantization-py"><span class="std std-ref">Color Quantization using K-Means</span></a></li>
</ul>
</div>
</div>
<div class="section" id="sample-generators">
<span id="id6"></span><h2>5.4. 样本生成器<a class="headerlink" href="#sample-generators" title="Permalink to this headline">¶</a></h2>
<p>此外，scikit-learn 包括各种随机样本的生成器，可以用来建立可控制的大小和复杂性人工数据集。</p>
<div class="section" id="id7">
<h3>5.4.1. 分类和聚类生成器<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>这些生成器将产生一个相应特征的离散矩阵。</p>
<div class="section" id="id8">
<h4>5.4.1.1. 单标签<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h4>
<p><a class="reference internal" href="../modules/generated/sklearn.datasets.make_blobs.html#sklearn.datasets.make_blobs" title="sklearn.datasets.make_blobs"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_blobs</span></code></a> 和  <a class="reference internal" href="../modules/generated/sklearn.datasets.make_classification.html#sklearn.datasets.make_classification" title="sklearn.datasets.make_classification"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_classification</span></code></a> 通过分配每个类的一个或多个正态分布的点的群集创建的多类数据集。 <a class="reference internal" href="../modules/generated/sklearn.datasets.make_blobs.html#sklearn.datasets.make_blobs" title="sklearn.datasets.make_blobs"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_blobs</span></code></a> 对于中心和各簇的标准偏差提供了更好的控制，可用于演示聚类。 <a class="reference internal" href="../modules/generated/sklearn.datasets.make_classification.html#sklearn.datasets.make_classification" title="sklearn.datasets.make_classification"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_classification</span></code></a> 专门通过引入相关的，冗余的和未知的噪音特征；将高斯集群的每类复杂化；在特征空间上进行线性变换。</p>
<p><a class="reference internal" href="../modules/generated/sklearn.datasets.make_gaussian_quantiles.html#sklearn.datasets.make_gaussian_quantiles" title="sklearn.datasets.make_gaussian_quantiles"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_gaussian_quantiles</span></code></a>  将single Gaussian cluster （单高斯簇）分成近乎相等大小的同心超球面分离。 <a class="reference internal" href="../modules/generated/sklearn.datasets.make_hastie_10_2.html#sklearn.datasets.make_hastie_10_2" title="sklearn.datasets.make_hastie_10_2"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_hastie_10_2</span></code></a> 产生类似的二进制、10维问题。</p>
<a class="reference external image-reference" href="../auto_examples/datasets/plot_random_dataset.html"><img alt="datasets/../auto_examples/datasets/images/sphx_glr_plot_random_dataset_001.png" class="align-center" src="datasets/../auto_examples/datasets/images/sphx_glr_plot_random_dataset_001.png" /></a>
<p><a class="reference internal" href="../modules/generated/sklearn.datasets.make_circles.html#sklearn.datasets.make_circles" title="sklearn.datasets.make_circles"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_circles</span></code></a> and :func:<a href="#id9"><span class="problematic" id="id10">`</span></a>make_moons`生成二维分类数据集时可以帮助确定算法（如质心聚类或线性分类），包括可以选择性加入高斯噪声。它们有利于可视化。用球面决策边界对高斯数据生成二值分类。</p>
</div>
<div class="section" id="id11">
<h4>5.4.1.2. 多标签<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h4>
<p><a class="reference internal" href="../modules/generated/sklearn.datasets.make_multilabel_classification.html#sklearn.datasets.make_multilabel_classification" title="sklearn.datasets.make_multilabel_classification"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_multilabel_classification</span></code></a> 生成多个标签的随机样本，反映从a mixture of topics（一个混合的主题）中引用a bag of words （一个词袋）。每个文档的主题数是基于泊松分布随机提取的，同时主题本身也是从固定的随机分布中提取的。同样地，单词的数目是基于泊松分布提取的，单词通过多项式被抽取，其中每个主题定义了单词的概率分布。在以下方面真正简化了 bag-of-words mixtures （单词混合包）：</p>
<ul class="simple">
<li>独立绘制的每个主题词分布，在现实中，所有这些都会受到稀疏基分布的影响，并将相互关联。</li>
<li>对于从文档中生成多个主题，所有主题在生成单词包时都是同等权重的。</li>
<li>随机产生没有标签的文件，而不是基于分布（base distribution）来产生文档</li>
</ul>
<a class="reference external image-reference" href="../auto_examples/datasets/plot_random_multilabel_dataset.html"><img alt="datasets/../auto_examples/datasets/images/sphx_glr_plot_random_multilabel_dataset_001.png" class="align-center" src="datasets/../auto_examples/datasets/images/sphx_glr_plot_random_multilabel_dataset_001.png" /></a>
</div>
<div class="section" id="id12">
<h4>5.4.1.3. 二分聚类<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h4>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="../modules/generated/sklearn.datasets.make_biclusters.html#sklearn.datasets.make_biclusters" title="sklearn.datasets.make_biclusters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_biclusters</span></code></a>(shape,&nbsp;n_clusters[,&nbsp;noise,&nbsp;…])</td>
<td>Generate an array with constant block diagonal structure for biclustering.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="../modules/generated/sklearn.datasets.make_checkerboard.html#sklearn.datasets.make_checkerboard" title="sklearn.datasets.make_checkerboard"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_checkerboard</span></code></a>(shape,&nbsp;n_clusters[,&nbsp;…])</td>
<td>Generate an array with block checkerboard structure for biclustering.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="id13">
<h3>5.4.2. 回归生成器<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../modules/generated/sklearn.datasets.make_regression.html#sklearn.datasets.make_regression" title="sklearn.datasets.make_regression"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_regression</span></code></a> 产生的回归目标作为一个可选择的稀疏线性组合的具有噪声的随机的特征。它的信息特征可能是不相关的或低秩（少数特征占大多数的方差）。</p>
<p>其他回归生成器产生确定性的随机特征函数。 <a class="reference internal" href="../modules/generated/sklearn.datasets.make_sparse_uncorrelated.html#sklearn.datasets.make_sparse_uncorrelated" title="sklearn.datasets.make_sparse_uncorrelated"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_sparse_uncorrelated</span></code></a> 产生目标为一个有四个固定系数的线性组合。其他编码明确的非线性关系：<a class="reference internal" href="../modules/generated/sklearn.datasets.make_friedman1.html#sklearn.datasets.make_friedman1" title="sklearn.datasets.make_friedman1"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_friedman1</span></code></a> 与多项式和正弦相关变换相联系； <a class="reference internal" href="../modules/generated/sklearn.datasets.make_friedman2.html#sklearn.datasets.make_friedman2" title="sklearn.datasets.make_friedman2"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_friedman2</span></code></a> 包括特征相乘与交互； <a class="reference internal" href="../modules/generated/sklearn.datasets.make_friedman3.html#sklearn.datasets.make_friedman3" title="sklearn.datasets.make_friedman3"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_friedman3</span></code></a> 类似与对目标的反正切变换。</p>
</div>
<div class="section" id="id14">
<h3>5.4.3. 流形学习生成器<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="../modules/generated/sklearn.datasets.make_s_curve.html#sklearn.datasets.make_s_curve" title="sklearn.datasets.make_s_curve"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_s_curve</span></code></a>([n_samples,&nbsp;noise,&nbsp;random_state])</td>
<td>Generate an S curve dataset.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="../modules/generated/sklearn.datasets.make_swiss_roll.html#sklearn.datasets.make_swiss_roll" title="sklearn.datasets.make_swiss_roll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_swiss_roll</span></code></a>([n_samples,&nbsp;noise,&nbsp;random_state])</td>
<td>Generate a swiss roll dataset.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id15">
<h3>5.4.4. 生成器分解<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="../modules/generated/sklearn.datasets.make_low_rank_matrix.html#sklearn.datasets.make_low_rank_matrix" title="sklearn.datasets.make_low_rank_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_low_rank_matrix</span></code></a>([n_samples,&nbsp;…])</td>
<td>Generate a mostly low rank matrix with bell-shaped singular values</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="../modules/generated/sklearn.datasets.make_sparse_coded_signal.html#sklearn.datasets.make_sparse_coded_signal" title="sklearn.datasets.make_sparse_coded_signal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_sparse_coded_signal</span></code></a>(n_samples,&nbsp;…[,&nbsp;…])</td>
<td>Generate a signal as a sparse combination of dictionary elements.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="../modules/generated/sklearn.datasets.make_spd_matrix.html#sklearn.datasets.make_spd_matrix" title="sklearn.datasets.make_spd_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_spd_matrix</span></code></a>(n_dim[,&nbsp;random_state])</td>
<td>Generate a random symmetric, positive-definite matrix.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="../modules/generated/sklearn.datasets.make_sparse_spd_matrix.html#sklearn.datasets.make_sparse_spd_matrix" title="sklearn.datasets.make_sparse_spd_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_sparse_spd_matrix</span></code></a>([dim,&nbsp;alpha,&nbsp;…])</td>
<td>Generate a sparse symmetric definite positive matrix.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="datasets-in-svmlight-libsvm-format">
<span id="libsvm-loader"></span><h2>5.5. Datasets in svmlight / libsvm format<a class="headerlink" href="#datasets-in-svmlight-libsvm-format" title="Permalink to this headline">¶</a></h2>
<p>scikit-learn 中有加载svmlight / libsvm格式的数据集的功能函数。此种格式中，每行
采用如 <code class="docutils literal notranslate"><span class="pre">&lt;label&gt;</span> <span class="pre">&lt;feature-id&gt;:&lt;feature-value&gt;&lt;feature-id&gt;:&lt;feature-value&gt;</span> <span class="pre">...</span></code>
的形式。这种格式尤其适合稀疏数据集，在该模块中，数据集 <code class="docutils literal notranslate"><span class="pre">X</span></code> 使用的是scipy稀疏CSR矩阵，
特征集 <code class="docutils literal notranslate"><span class="pre">y</span></code> 使用的是numpy数组。</p>
<p>你可以通过如下步骤加载数据集:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_svmlight_file</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">load_svmlight_file</span><span class="p">(</span><span class="s2">&quot;/path/to/train_dataset.txt&quot;</span><span class="p">)</span>
<span class="gp">... </span>                                                        
</pre></div>
</div>
<p>你也可以一次加载两个或多个的数据集:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">load_svmlight_files</span><span class="p">(</span>
<span class="gp">... </span>    <span class="p">(</span><span class="s2">&quot;/path/to/train_dataset.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;/path/to/test_dataset.txt&quot;</span><span class="p">))</span>
<span class="gp">... </span>                                                        
</pre></div>
</div>
<p>这种情况下，保证了 <code class="docutils literal notranslate"><span class="pre">X_train</span></code> 和 <code class="docutils literal notranslate"><span class="pre">X_test</span></code> 具有相同的特征数量。
固定特征的数量也可以得到同样的结果:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">load_svmlight_file</span><span class="p">(</span>
<span class="gp">... </span>    <span class="s2">&quot;/path/to/test_dataset.txt&quot;</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="gp">... </span>                                                        
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">相关链接:</p>
<p><span class="target" id="svmlight-libsvm">svmlight / libsvm 格式的公共数据集</span>: <a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets">https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets</a></p>
<p><span class="target" id="id16">更快的API兼容的实现</span>: <a class="reference external" href="https://github.com/mblondel/svmlight-loader">https://github.com/mblondel/svmlight-loader</a></p>
</div>
</div>
<div class="section" id="external-datasets">
<span id="id17"></span><h2>5.6. 从外部数据集加载<a class="headerlink" href="#external-datasets" title="Permalink to this headline">¶</a></h2>
<p>scikit-learn使用任何存储为numpy数组或者scipy稀疏数组的数值数据。
其他可以转化成数值数组的类型也可以接受，如pandas中的DataFrame。</p>
<p>以下推荐一些将标准纵列形式的数据转换为scikit-learn可以使用的格式的方法:</p>
<ul class="simple">
<li><a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/io.html">pandas.io</a>
提供了从常见格式(包括CSV,Excel,JSON,SQL等)中读取数据的工具.DateFrame 也可以从由
元组或者字典组成的列表构建而成.Pandas能顺利的处理异构的数据，并且提供了处理和转换
成方便scikit-learn使用的数值数据的工具。</li>
<li><a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/io.html">scipy.io</a>
专门处理科学计算领域经常使用的二进制格式，例如.mat和.arff格式的内容。</li>
<li><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/routines.io.html">numpy/routines.io</a>
将纵列形式的数据标准的加载为numpy数组</li>
<li>scikit-learn的 :func:<a href="#id18"><span class="problematic" id="id19">`</span></a>datasets.load_svmlight_file`处理svmlight或者libSVM稀疏矩阵</li>
<li>scikit-learn的 <code class="xref py py-func docutils literal notranslate"><span class="pre">datasets.load_files</span></code> 处理文本文件组成的目录，每个目录名是每个
类别的名称，每个目录内的每个文件对应该类别的一个样本</li>
</ul>
<p>对于一些杂项数据，例如图像，视屏，音频。您可以参考:</p>
<ul class="simple">
<li><a class="reference external" href="http://scikit-image.org/docs/dev/api/skimage.io.html">skimage.io</a> 或
<a class="reference external" href="https://imageio.readthedocs.io/en/latest/userapi.html">Imageio</a>
将图像或者视屏加载为numpy数组</li>
<li><a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.misc.imread.html#scipy.misc.imread">scipy.misc.imread</a> (requires the <a class="reference external" href="https://pypi.python.org/pypi/Pillow">Pillow</a> package)将各种图像文件格式加载为
像素灰度数据</li>
<li><a class="reference external" href="https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.io.wavfile.read.html">scipy.io.wavfile.read</a>
将WAV文件读入一个numpy数组</li>
</ul>
<p>存储为字符串的无序(或者名字)特征(在pandas的DataFrame中很常见)需要转换为整数，当整数类别变量
被编码成独热变量(<a class="reference internal" href="../modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder" title="sklearn.preprocessing.OneHotEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.preprocessing.OneHotEncoder</span></code></a>)或类似数据时，它或许可以被最好的利用。
参见 <a class="reference internal" href="../modules/preprocessing.html#preprocessing"><span class="std std-ref">预处理数据</span></a>.</p>
<p>注意：如果你要管理你的数值数据，建议使用优化后的文件格式来减少数据加载时间,例如HDF5。像
H5Py, PyTables和pandas等的各种库提供了一个Python接口，来读写该格式的数据。</p>
<div class="toctree-wrapper compound">
</div>
</div>
<div class="section" id="olivetti">
<span id="olivetti-faces"></span><h2>5.7. Olivetti 脸部数据集<a class="headerlink" href="#olivetti" title="Permalink to this headline">¶</a></h2>
<p>该数据集包含 1992年4月至1994年4月在AT＆T实验室剑桥采集的一组面部图像。
该 <a class="reference internal" href="../modules/generated/sklearn.datasets.fetch_olivetti_faces.html#sklearn.datasets.fetch_olivetti_faces" title="sklearn.datasets.fetch_olivetti_faces"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.datasets.fetch_olivetti_faces</span></code></a> 函数是从AT＆T下载
数据存档的数据获取/缓存函数。</p>
<dl class="docutils">
<dt>如原网站所述：</dt>
<dd>有四十个不同的个体，每个个体有十张不同的图片。对于某些个体，图像在不同时间拍摄并且改变
照明和面部表情(睁开/闭上眼睛， 微小/不微笑)和面部细节(戴眼镜/不带眼镜)。所有的图像采用
黑色均匀的背景，个体处于直立的正面位置。(容许一定的侧移)</dd>
</dl>
<p>图像被量化为256个的灰度级并以8位无符号整数的形式存储；加载器将这些无符号整数转换为[0,1]之间
的浮点值，这样能方面很多算法的使用。</p>
<p>该数据库的”目标”一个是从0到39的整数，代表着图中人物的身份。然而，由于每一类只有十个样例，从
无监督学习或半监督学习的角度来看，这个相对较小的数据集更加有趣。</p>
<p>原始的数据集由92 x 112大小的图像组成，然而这里提供的版本由64 x 64大小的图像组成。</p>
<p>当使用这些图像时， 请致谢AT&amp;T剑桥实验室。</p>
</div>
<div class="section" id="newsgroups">
<span id="id21"></span><h2>5.8. 20个新闻组文本数据集<a class="headerlink" href="#newsgroups" title="Permalink to this headline">¶</a></h2>
<p>20个新闻组文本数据集包含有关20个主题的大约18000个新闻组，被分为两个子集：一个用于
训练(或者开发)，另一个用于测试(或者用于性能评估)。训练和测试集的划分是基于某个特定日期
前后发布的消息。</p>
<p>这个模块包含两个加载器。第一个是 <a class="reference internal" href="../modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups" title="sklearn.datasets.fetch_20newsgroups"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.datasets.fetch_20newsgroups</span></code></a>，
返回一个能够被文本特征提取器接受的原始文本列表，例如 <a class="reference internal" href="../modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer" title="sklearn.feature_extraction.text.CountVectorizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.feature_extraction.text.CountVectorizer</span></code></a>
使用自定义的参数来提取特征向量。第二个是 <a class="reference internal" href="../modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized.html#sklearn.datasets.fetch_20newsgroups_vectorized" title="sklearn.datasets.fetch_20newsgroups_vectorized"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.datasets.fetch_20newsgroups_vectorized</span></code></a>，
返回即用特征，换句话说就是，这样就没必要使用特征提取器了。</p>
<div class="section" id="id22">
<h3>5.8.1. 用法<a class="headerlink" href="#id22" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><a class="reference internal" href="../modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups" title="sklearn.datasets.fetch_20newsgroups"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.datasets.fetch_20newsgroups</span></code></a>  是一个用于从原始的20个新闻组网址( <a class="reference external" href="http://people.csail.mit.edu/jrennie/20Newsgroups/">20 newsgroups website</a>)</div></blockquote>
<p>下载数据归档的数据获取/缓存函数，提取 <code class="docutils literal notranslate"><span class="pre">~/scikit_learn_data/20news_home</span></code> 文件夹中的
归档内容。并且在训练集或测试集文件夹，或者两者上调用函数 <a class="reference internal" href="../modules/generated/sklearn.datasets.load_files.html#sklearn.datasets.load_files" title="sklearn.datasets.load_files"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.datasets.load_files</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">fetch_20newsgroups</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">newsgroups_train</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pprint</span> <span class="k">import</span> <span class="n">pprint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pprint</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">target_names</span><span class="p">))</span>
<span class="go">[&#39;alt.atheism&#39;,</span>
<span class="go"> &#39;comp.graphics&#39;,</span>
<span class="go"> &#39;comp.os.ms-windows.misc&#39;,</span>
<span class="go"> &#39;comp.sys.ibm.pc.hardware&#39;,</span>
<span class="go"> &#39;comp.sys.mac.hardware&#39;,</span>
<span class="go"> &#39;comp.windows.x&#39;,</span>
<span class="go"> &#39;misc.forsale&#39;,</span>
<span class="go"> &#39;rec.autos&#39;,</span>
<span class="go"> &#39;rec.motorcycles&#39;,</span>
<span class="go"> &#39;rec.sport.baseball&#39;,</span>
<span class="go"> &#39;rec.sport.hockey&#39;,</span>
<span class="go"> &#39;sci.crypt&#39;,</span>
<span class="go"> &#39;sci.electronics&#39;,</span>
<span class="go"> &#39;sci.med&#39;,</span>
<span class="go"> &#39;sci.space&#39;,</span>
<span class="go"> &#39;soc.religion.christian&#39;,</span>
<span class="go"> &#39;talk.politics.guns&#39;,</span>
<span class="go"> &#39;talk.politics.mideast&#39;,</span>
<span class="go"> &#39;talk.politics.misc&#39;,</span>
<span class="go"> &#39;talk.religion.misc&#39;]</span>
</pre></div>
</div>
<p>真实数据在属性 <code class="docutils literal notranslate"><span class="pre">filenames</span></code> 和 <code class="docutils literal notranslate"><span class="pre">target</span></code> 中，target属性就是类别的整数索引:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">filenames</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(11314,)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(11314,)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">target</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
<span class="go">array([12,  6,  9,  8,  6,  7,  9,  2, 13, 19])</span>
</pre></div>
</div>
<p>可以通过将类别列表传给 <a class="reference internal" href="../modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups" title="sklearn.datasets.fetch_20newsgroups"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.datasets.fetch_20newsgroups</span></code></a> 函数来实现只加载一部分的类别:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cats</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;alt.atheism&#39;</span><span class="p">,</span> <span class="s1">&#39;sci.space&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">newsgroups_train</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">categories</span><span class="o">=</span><span class="n">cats</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">list</span><span class="p">(</span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">target_names</span><span class="p">)</span>
<span class="go">[&#39;alt.atheism&#39;, &#39;sci.space&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">filenames</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(1073,)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(1073,)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">target</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
<span class="go">array([1, 1, 1, 0, 1, 0, 0, 1, 1, 1])</span>
</pre></div>
</div>
</div>
<div class="section" id="id23">
<h3>5.8.2. 将文本转换成向量<a class="headerlink" href="#id23" title="Permalink to this headline">¶</a></h3>
<p>为了用文本数据训练预测或者聚类模型，首先需要做的是将文本转换成适合统计分析的数值
向量。这能使用 <code class="docutils literal notranslate"><span class="pre">sklearn.feature_extraction.text</span></code> 的功能来实现，正如下面展示的
从一个20个新闻的子集中提取单个词的 <a class="reference external" href="https://en.wikipedia.org/wiki/Tf-idf">TF-IDF</a> 向量的例子</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="k">import</span> <span class="n">TfidfVectorizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;alt.atheism&#39;</span><span class="p">,</span> <span class="s1">&#39;talk.religion.misc&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;comp.graphics&#39;</span><span class="p">,</span> <span class="s1">&#39;sci.space&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">newsgroups_train</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span>
<span class="gp">... </span>                                      <span class="n">categories</span><span class="o">=</span><span class="n">categories</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vectors</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vectors</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2034, 34118)</span>
</pre></div>
</div>
<p>提取的TF-IDF向量非常稀疏，在一个超过30000维的空间中采样，
平均只有159个非零成分(少于.5%的非零成分):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">vectors</span><span class="o">.</span><span class="n">nnz</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="go">159.01327433628319</span>
</pre></div>
</div>
<p><a class="reference internal" href="../modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized.html#sklearn.datasets.fetch_20newsgroups_vectorized" title="sklearn.datasets.fetch_20newsgroups_vectorized"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.datasets.fetch_20newsgroups_vectorized</span></code></a> 是一个返回即用的tfidf特征的函数
，而不是返回文件名。</p>
</div>
<div class="section" id="id24">
<h3>5.8.3. 过滤文本进行更加逼真的训练<a class="headerlink" href="#id24" title="Permalink to this headline">¶</a></h3>
<p>分类器很容易过拟合一个出现在20个新闻组数据中的特定事物，例如新闻组标头。许多分类器有
很好的F分数，但是他们的结果不能泛化到不在这个时间窗的其他文档。</p>
<p>例如，我们来看一下多项式贝叶斯分类器，它训练速度快并且能获得很好的F分数。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="k">import</span> <span class="n">MultinomialNB</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">newsgroups_test</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">,</span>
<span class="gp">... </span>                                     <span class="n">categories</span><span class="o">=</span><span class="n">categories</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vectors_test</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">newsgroups_test</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">(</span><span class="n">alpha</span><span class="o">=.</span><span class="mi">01</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">newsgroups_train</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">vectors_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">newsgroups_test</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.88213592402729568</span>
</pre></div>
</div>
<p>(<a class="reference internal" href="../auto_examples/text/document_classification_20newsgroups.html#sphx-glr-auto-examples-text-document-classification-20newsgroups-py"><span class="std std-ref">Classification of text documents using sparse features</span></a> 的例子将训练和测试数据混合，
而不是按时间划分，这种情况下，多项式贝叶斯能得到更高的0.88的F分数.你是否还不信任这个分类器的内部实现？)</p>
<p>让我们看看信息量最大一些特征是:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">show_top10</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">,</span> <span class="n">categories</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">feature_names</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
<span class="gp">... </span>    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">category</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">categories</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">top10</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">classifier</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="n">i</span><span class="p">])[</span><span class="o">-</span><span class="mi">10</span><span class="p">:]</span>
<span class="gp">... </span>        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">category</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">feature_names</span><span class="p">[</span><span class="n">top10</span><span class="p">])))</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">show_top10</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">,</span> <span class="n">newsgroups_train</span><span class="o">.</span><span class="n">target_names</span><span class="p">)</span>
<span class="go">alt.atheism: sgi livesey atheists writes people caltech com god keith edu</span>
<span class="go">comp.graphics: organization thanks files subject com image lines university edu graphics</span>
<span class="go">sci.space: toronto moon gov com alaska access henry nasa edu space</span>
<span class="go">talk.religion.misc: article writes kent people christian jesus sandvik edu com god</span>
</pre></div>
</div>
<p>你现在可以看到这些特征过拟合了许多东西:</p>
<ul class="simple">
<li>几乎所有的组都通过标题是出现更多还是更少来区分，例如 <code class="docutils literal notranslate"><span class="pre">NNTP-Posting-Host:</span></code> 和 <code class="docutils literal notranslate"><span class="pre">Distribution:</span></code> 标题</li>
<li>正如他的标头或者签名所表示，另外重要的特征有关发送者是否隶属于一个大学。</li>
<li>“article”这个单词是一个重要的特征，它基于人们像 “In article [article ID], [name] &lt;[e-mail address]&gt;
wrote:” 的方式引用原先的帖子频率。</li>
<li>其他特征和当时发布的特定的人的名字和e-mail相匹配。</li>
</ul>
<p>有如此大量的线索来区分新闻组，分类器根本不需要从文本中识别主题，而且他们的性能都一样好。</p>
<p>由于这个原因，加载20个新闻组数据的函数提供了一个叫做 <strong>remove</strong> 的参数，来告诉函数需要从文件
中去除什么类别的信息。 <strong>remove</strong> 应该是一个来自集合 <code class="docutils literal notranslate"><span class="pre">('headers',</span> <span class="pre">'footers',</span> <span class="pre">'quotes')</span></code> 的子集
的元组，来告诉函数分别移除标头标题，签名块还有引用块。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">newsgroups_test</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">,</span>
<span class="gp">... </span>                                     <span class="n">remove</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;headers&#39;</span><span class="p">,</span> <span class="s1">&#39;footers&#39;</span><span class="p">,</span> <span class="s1">&#39;quotes&#39;</span><span class="p">),</span>
<span class="gp">... </span>                                     <span class="n">categories</span><span class="o">=</span><span class="n">categories</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vectors_test</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">newsgroups_test</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">vectors_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">newsgroups_test</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.77310350681274775</span>
</pre></div>
</div>
<p>由于我们移除了跟主题分类几乎没有关系的元数据，分类器的F分数降低了很多。
如果我们从训练数据中也移除这个元数据，F分数将会更低:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">newsgroups_train</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span>
<span class="gp">... </span>                                      <span class="n">remove</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;headers&#39;</span><span class="p">,</span> <span class="s1">&#39;footers&#39;</span><span class="p">,</span> <span class="s1">&#39;quotes&#39;</span><span class="p">),</span>
<span class="gp">... </span>                                      <span class="n">categories</span><span class="o">=</span><span class="n">categories</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vectors</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">(</span><span class="n">alpha</span><span class="o">=.</span><span class="mi">01</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">newsgroups_train</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vectors_test</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">newsgroups_test</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">vectors_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">newsgroups_test</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.76995175184521725</span>
</pre></div>
</div>
<dl class="docutils">
<dt>其他的一些分类器能够更好的处理这个更难版本的任务。试着带 <code class="docutils literal notranslate"><span class="pre">--filter</span></code> 选项和不带 <code class="docutils literal notranslate"><span class="pre">--filter</span></code> 选项运行</dt>
<dd><a class="reference internal" href="../auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py"><span class="std std-ref">Sample pipeline for text feature extraction and evaluation</span></a> 来比较结果间的差异。</dd>
</dl>
<div class="topic">
<p class="topic-title first">推荐</p>
<dl class="docutils">
<dt>当使用20个新闻组数据中评估文本分类器时，你应该移除与新闻组相关的元数据。你可以通过设置</dt>
<dd><code class="docutils literal notranslate"><span class="pre">remove=('headers',</span> <span class="pre">'footers',</span> <span class="pre">'quotes')</span></code> 来实现。F分数将更加低因为这更符合实际</dd>
</dl>
</div>
<div class="topic">
<p class="topic-title first">例子</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py"><span class="std std-ref">Sample pipeline for text feature extraction and evaluation</span></a></li>
<li><a class="reference internal" href="../auto_examples/text/document_classification_20newsgroups.html#sphx-glr-auto-examples-text-document-classification-20newsgroups-py"><span class="std std-ref">Classification of text documents using sparse features</span></a></li>
</ul>
</div>
</div>
</div>
<div class="section" id="mldata-org">
<span id="mldata"></span><h2>5.9. 从 mldata.org 上下载数据集<a class="headerlink" href="#mldata-org" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="http://mldata.org">mldata.org</a> 是一个公开的机器学习数据 repository ,由 <a class="reference external" href="http://www.pascal-network.org">PASCAL network</a> 负责支持。</p>
<p><code class="docutils literal notranslate"><span class="pre">sklearn.datasets</span></code> 包可以使用函数 <a class="reference internal" href="../modules/generated/sklearn.datasets.fetch_mldata.html#sklearn.datasets.fetch_mldata" title="sklearn.datasets.fetch_mldata"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.datasets.fetch_mldata</span></code></a> 直接从 repository 下载数据集。</p>
<p>举个例子，下载 MNIST 手写数字字符识别数据集:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">fetch_mldata</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mnist</span> <span class="o">=</span> <span class="n">fetch_mldata</span><span class="p">(</span><span class="s1">&#39;MNIST original&#39;</span><span class="p">,</span> <span class="n">data_home</span><span class="o">=</span><span class="n">custom_data_home</span><span class="p">)</span>
</pre></div>
</div>
<p>MNIST 手写数字字符数据集包含有 70000 个样本，每个样本带有从 0 到 9 的标签，并且样本像素尺寸大小为 28x28:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mnist</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(70000, 784)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mnist</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(70000,)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="go">array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.])</span>
</pre></div>
</div>
<p>首次下载之后，数据集被缓存在本地的由 <code class="docutils literal notranslate"><span class="pre">data_home</span></code> 关键字指定的路径中，路径默认是 <code class="docutils literal notranslate"><span class="pre">~/scikit_learn_data/</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">custom_data_home</span><span class="p">,</span> <span class="s1">&#39;mldata&#39;</span><span class="p">))</span>
<span class="go">[&#39;mnist-original.mat&#39;]</span>
</pre></div>
</div>
<p><a class="reference external" href="http://mldata.org">mldata.org</a> 里的数据集在命名规则和数据格式上不遵循严格的约定。
<a class="reference internal" href="../modules/generated/sklearn.datasets.fetch_mldata.html#sklearn.datasets.fetch_mldata" title="sklearn.datasets.fetch_mldata"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.datasets.fetch_mldata</span></code></a> 可以应对大多数的常见情况，并且允许个人对数据集的默认设置进行调整:</p>
<ul>
<li><p class="first"><a class="reference external" href="http://mldata.org">mldata.org</a> 中的数据大多都是以 <code class="docutils literal notranslate"><span class="pre">(n_features,</span> <span class="pre">n_samples)</span></code> 这样的组织形式存在。
这与 <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> 中的习惯约定是不一致的，所以 <a class="reference internal" href="../modules/generated/sklearn.datasets.fetch_mldata.html#sklearn.datasets.fetch_mldata" title="sklearn.datasets.fetch_mldata"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.datasets.fetch_mldata</span></code></a> 默认情况下通过 <code class="docutils literal notranslate"><span class="pre">transpose_data</span></code> 关键字控制对这个矩阵进行转置运算。:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">fetch_mldata</span><span class="p">(</span><span class="s1">&#39;iris&#39;</span><span class="p">,</span> <span class="n">data_home</span><span class="o">=</span><span class="n">custom_data_home</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(150, 4)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">fetch_mldata</span><span class="p">(</span><span class="s1">&#39;iris&#39;</span><span class="p">,</span> <span class="n">transpose_data</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="n">data_home</span><span class="o">=</span><span class="n">custom_data_home</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(4, 150)</span>
</pre></div>
</div>
</li>
<li><p class="first">数据集有多列的时候，<a class="reference internal" href="../modules/generated/sklearn.datasets.fetch_mldata.html#sklearn.datasets.fetch_mldata" title="sklearn.datasets.fetch_mldata"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.datasets.fetch_mldata</span></code></a> 这个函数会识别目标列和数据列，
并将它们重命名为 <code class="docutils literal notranslate"><span class="pre">target（目标）</span></code> 和 <code class="docutils literal notranslate"><span class="pre">data（数据）</span></code> 。
这是通过在数据集中寻找名为 <code class="docutils literal notranslate"><span class="pre">label（标签）</span></code> 和 <code class="docutils literal notranslate"><span class="pre">data（数据）</span></code> 的数组来完成的，
如果选择第一个数组是 <code class="docutils literal notranslate"><span class="pre">target（目标）</span></code>，而第二个数组是 <code class="docutils literal notranslate"><span class="pre">data（数据）</span></code> ，则前边的设置会失效。
这个行为可以通过对关键字 <code class="docutils literal notranslate"><span class="pre">target_name</span></code> 和 <code class="docutils literal notranslate"><span class="pre">data_name</span></code> 进行设置来改变，设置的值可以是具体的名字也可以是索引数字，
数据集中列的名字和索引序号都可以在 <a class="reference external" href="http://mldata.org">mldata.org</a> 中的 “Data” 选项卡下找到:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">iris2</span> <span class="o">=</span> <span class="n">fetch_mldata</span><span class="p">(</span><span class="s1">&#39;datasets-UCI iris&#39;</span><span class="p">,</span> <span class="n">target_name</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">data_name</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="gp">... </span>                     <span class="n">data_home</span><span class="o">=</span><span class="n">custom_data_home</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris3</span> <span class="o">=</span> <span class="n">fetch_mldata</span><span class="p">(</span><span class="s1">&#39;datasets-UCI iris&#39;</span><span class="p">,</span> <span class="n">target_name</span><span class="o">=</span><span class="s1">&#39;class&#39;</span><span class="p">,</span>
<span class="gp">... </span>                     <span class="n">data_name</span><span class="o">=</span><span class="s1">&#39;double0&#39;</span><span class="p">,</span> <span class="n">data_home</span><span class="o">=</span><span class="n">custom_data_home</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</div>
<div class="section" id="labeled-faces-in-the-wild">
<span id="id29"></span><h2>5.10. 带标签的人脸识别数据集<a class="headerlink" href="#labeled-faces-in-the-wild" title="Permalink to this headline">¶</a></h2>
<p>这个数据集是一个在互联网上收集的名人 JPEG 图片集，所有详细信息都可以在官方网站上获得:</p>
<blockquote>
<div><a class="reference external" href="http://vis-www.cs.umass.edu/lfw/">http://vis-www.cs.umass.edu/lfw/</a></div></blockquote>
<p>每张图片的居中部分都是一张脸。典型人物人脸验证是给定两幅图片，二元分类器必须能够预测这两幅图片是否是同一个人。</p>
<p>另一项任务人脸识别或面部识别说的是给定一个未知的面孔，通过参考一系列已经学习经过鉴定的人的照片来识别此人的名字。</p>
<p>人脸验证和人脸识别都是基于经过训练用于人脸检测的模型的输出所进行的任务。 最流行的人脸检测模型叫作 Viola Jones是在 OpenCV 库中实现的。 LFW 人脸数据库中的人脸是使用该人脸检测器从各种在线网站上提取的。</p>
<div class="section" id="id30">
<h3>5.10.1. 用法<a class="headerlink" href="#id30" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> 提供两个可以自动下载、缓存、解析元数据文件的 loader (加载器)，解码 JPEG
并且将 slices 转换成内存映射过的 NumPy 数组(numpy.memmap)。
这个数据集大小超过 200 MB。第一个加载器通常需要超过几分钟才能完全解码 JPEG 文件的相关部分为 NumPy 数组。
如果数据集已经被加载过，通过在磁盘上采用内存映射版( memmaped version )的 memoized，
即 <code class="docutils literal notranslate"><span class="pre">~/scikit_learn_data/lfw_home/</span></code> 文件夹使用 <code class="docutils literal notranslate"><span class="pre">joblib</span></code>，再次加载时间会小于 200ms。</p>
<p>第一个 loader (加载器)用于人脸识别任务:一个多类分类任务(属于监督学习):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">fetch_lfw_people</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lfw_people</span> <span class="o">=</span> <span class="n">fetch_lfw_people</span><span class="p">(</span><span class="n">min_faces_per_person</span><span class="o">=</span><span class="mi">70</span><span class="p">,</span> <span class="n">resize</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">lfw_people</span><span class="o">.</span><span class="n">target_names</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">Ariel Sharon</span>
<span class="go">Colin Powell</span>
<span class="go">Donald Rumsfeld</span>
<span class="go">George W Bush</span>
<span class="go">Gerhard Schroeder</span>
<span class="go">Hugo Chavez</span>
<span class="go">Tony Blair</span>
</pre></div>
</div>
<p>默认的 slice 是一个删除掉大部分背景，只剩下围绕着脸周围的长方形的形状:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lfw_people</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">dtype(&#39;float32&#39;)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">lfw_people</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(1288, 1850)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">lfw_people</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(1288, 50, 37)</span>
</pre></div>
</div>
<p>在 <code class="docutils literal notranslate"><span class="pre">target(目标)</span></code> 数组中，<a href="#id31"><span class="problematic" id="id32">``</span></a>1140``个人脸图片中的每一个图都分配一个属于某人的 id:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lfw_people</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(1288,)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">list</span><span class="p">(</span><span class="n">lfw_people</span><span class="o">.</span><span class="n">target</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
<span class="go">[5, 6, 3, 1, 0, 1, 3, 4, 3, 0]</span>
</pre></div>
</div>
<p>第二个 loader (加载器)通常用于人脸验证任务: 每个样本是属于或不属于同一个人的两张图片:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> &gt;&gt;&gt; from sklearn.datasets import fetch_lfw_pairs
 &gt;&gt;&gt; lfw_pairs_train = fetch_lfw_pairs(subset=&#39;train&#39;)

 &gt;&gt;&gt; list(lfw_pairs_train.target_names)
 [&#39;Different persons&#39;, &#39;Same person&#39;]

 &gt;&gt;&gt; lfw_pairs_train.pairs.shape
 (2200, 2, 62, 47)

 &gt;&gt;&gt; lfw_pairs_train.data.shape
 (2200, 5828)

 &gt;&gt;&gt; lfw_pairs_train.target.shape
 (2200,)

:func:`sklearn.datasets.fetch_lfw_people` 和 :func:`sklearn.datasets.fetch_lfw_pairs` 函数，都可以通过 ``color=True`` 来获得 RGB 颜色通道的维度，在这种情况下尺寸将为 ``(2200, 2, 62, 47, 3)`` 。
</pre></div>
</div>
<p><a class="reference internal" href="../modules/generated/sklearn.datasets.fetch_lfw_pairs.html#sklearn.datasets.fetch_lfw_pairs" title="sklearn.datasets.fetch_lfw_pairs"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.datasets.fetch_lfw_pairs</span></code></a> 数据集细分为 3 类:
<code class="docutils literal notranslate"><span class="pre">train</span></code> set(训练集)、<code class="docutils literal notranslate"><span class="pre">test</span></code> set(测试集)和一个 <code class="docutils literal notranslate"><span class="pre">10_folds</span></code> 评估集, <code class="docutils literal notranslate"><span class="pre">10_folds</span></code> 评估集意味着性能的计算指标使用 10 折交叉验证( 10-folds cross validation )方案。</p>
<div class="topic">
<p class="topic-title first">参考文献:</p>
<ul class="simple">
<li><a class="reference external" href="http://vis-www.cs.umass.edu/lfw/lfw.pdf">Labeled Faces in the Wild: A Database for Studying Face Recognition
in Unconstrained Environments.</a>
Gary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller.
University of Massachusetts, Amherst, Technical Report 07-49, October, 2007.</li>
</ul>
</div>
</div>
<div class="section" id="id33">
<h3>5.10.2. 示例<a class="headerlink" href="#id33" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../auto_examples/applications/plot_face_recognition.html#sphx-glr-auto-examples-applications-plot-face-recognition-py"><span class="std std-ref">Faces recognition example using eigenfaces and SVMs</span></a></p>
</div>
</div>
<div class="section" id="covtype">
<span id="id34"></span><h2>5.11. 森林覆盖类型<a class="headerlink" href="#covtype" title="Permalink to this headline">¶</a></h2>
<p>这个数据集中的样本对应美国的 30×30m 的 patches of forest(森林区域)，
收集这些数据用于预测每个 patch 的植被 cover type (覆盖类型)，即优势树种。
总共有七个植被类型，使得这是一个多分类问题。
每个样本有 54 个特征，在 <a class="reference external" href="http://archive.ics.uci.edu/ml/datasets/Covertype">dataset’s 的主页</a> 中有具体的描述。
有些特征是布尔指标，其他的是离散或者连续的量。</p>
<p><a class="reference internal" href="../modules/generated/sklearn.datasets.fetch_covtype.html#sklearn.datasets.fetch_covtype" title="sklearn.datasets.fetch_covtype"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.datasets.fetch_covtype</span></code></a> 将加载 covertype 数据集；
它返回一个类似字典的对象，并在数据成员中使用特征矩阵以及 <code class="docutils literal notranslate"><span class="pre">target</span></code> 中的目标值。
如果需要，数据集可以从网上下载。</p>
</div>
<div class="section" id="rcv1">
<span id="id35"></span><h2>5.12. RCV1 数据集<a class="headerlink" href="#rcv1" title="Permalink to this headline">¶</a></h2>
<p>路透社语料库第一卷( RCV1 )是路透社为了研究目的提供的一个拥有超过 800,000 份手动分类的新闻报导的文档库。该数据集在 <a class="footnote-reference" href="#id38" id="id36">[1]</a> 中有详细描述。</p>
<p><a class="reference internal" href="../modules/generated/sklearn.datasets.fetch_rcv1.html#sklearn.datasets.fetch_rcv1" title="sklearn.datasets.fetch_rcv1"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.datasets.fetch_rcv1</span></code></a> 将加载以下版本: RCV1-v2, vectors, full sets, topics multilabels:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">fetch_rcv1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rcv1</span> <span class="o">=</span> <span class="n">fetch_rcv1</span><span class="p">()</span>
</pre></div>
</div>
<p>它返回一个类似字典的对象，具有以下属性:</p>
<p><code class="docutils literal notranslate"><span class="pre">data</span></code>:
特征矩阵是一个 scipy CSR 稀疏矩阵，有 804414 个样品和 47236 个特征。
非零值包含 cosine-normalized(余弦归一化)，log TF-IDF vectors。
按照年代顺序近似划分，在 <a class="footnote-reference" href="#id38" id="id37">[1]</a> 提出: 前 23149 个样本是训练集。后 781265 个样本是测试集。
这是官方的 LYRL2004 时间划分。数组有 0.16% 个非零值:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rcv1</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(804414, 47236)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">target</span></code>:
目标值是存储在 scipy CSR 的稀疏矩阵，有 804414 个样本和 103 个类别。
每个样本在其所属的类别中的值为 1，在其他类别中值为 0。数组有 3.15% 个非零值:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rcv1</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(804414, 103)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">sample_id</span></code>:
每个样本都可以通过从 2286 到 810596 不等的 ID 来标识:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rcv1</span><span class="o">.</span><span class="n">sample_id</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
<span class="go">array([2286, 2287, 2288], dtype=uint32)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">target_names</span></code>:
目标值是每个样本的 topic (主题)。每个样本至少属于一个 topic (主题)最多 17 个 topic 。
总共有 103 个 topics ，每个 topic 用一个字符串表示。
从 <cite>GMIL</cite> 出现 5 次到 <cite>CCAT</cite> 出现 381327 次，该语料库频率跨越五个数量级:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rcv1</span><span class="o">.</span><span class="n">target_names</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>  
<span class="go">[&#39;E11&#39;, &#39;ECAT&#39;, &#39;M11&#39;]</span>
</pre></div>
</div>
<p>如果有需要的话，可以从 <a class="reference external" href="http://jmlr.csail.mit.edu/papers/volume5/lewis04a/">rcv1 homepage</a> 上下载该数据集。
数据集压缩后的大小大约是 656 MB。</p>
<div class="topic">
<p class="topic-title first">参考文献</p>
<table class="docutils footnote" frame="void" id="id38" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td><em>(<a class="fn-backref" href="#id36">1</a>, <a class="fn-backref" href="#id37">2</a>)</em> Lewis, D. D., Yang, Y., Rose, T. G., &amp; Li, F. (2004). RCV1: A new benchmark collection for text categorization research. The Journal of Machine Learning Research, 5, 361-397.</td></tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="boston-house-prices">
<span id="id39"></span><h2>5.13. 波士顿房价数据集<a class="headerlink" href="#boston-house-prices" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id40">
<h3>5.13.1. 注释<a class="headerlink" href="#id40" title="Permalink to this headline">¶</a></h3>
<p>数据集特征:</p>
<blockquote>
<div><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">实例数量:</th><td class="field-body">506</td>
</tr>
<tr class="field-even field"><th class="field-name">属性数量:</th><td class="field-body">13 数值型或类别型，帮助预测的属性</td>
</tr>
</tbody>
</table>
<p>:中位数（第14个属性）经常是学习目标</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">属性信息 (按顺序):</th><td class="field-body"><ul class="first simple">
<li>CRIM     城镇人均犯罪率</li>
<li>ZN       占地面积超过2.5万平方英尺的住宅用地比例</li>
<li>INDUS    城镇非零售业务地区的比例</li>
<li>CHAS     查尔斯河虚拟变量 (= 1 如果土地在河边；否则是0)</li>
<li>NOX      一氧化氮浓度（每1000万份）</li>
<li>RM       平均每居民房数</li>
<li>AGE      在1940年之前建成的所有者占用单位的比例</li>
<li>DIS      与五个波士顿就业中心的加权距离</li>
<li>RAD      辐射状公路的可达性指数</li>
<li>TAX      每10,000美元的全额物业税率</li>
<li>PTRATIO  城镇师生比例</li>
<li>B        1000(Bk - 0.63)^2 其中 Bk 是城镇的黑人比例</li>
<li>LSTAT    人口中地位较低人群的百分数</li>
<li>MEDV     以1000美元计算的自有住房的中位数</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">缺失属性值:</th><td class="field-body"><p class="first">无</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">创建者:</th><td class="field-body"><p class="first last">Harrison, D. and Rubinfeld, D.L.</p>
</td>
</tr>
</tbody>
</table>
</div></blockquote>
<p>这是UCI ML（欧文加利福尼亚大学 机器学习库）房价数据集的副本。
<a class="reference external" href="http://archive.ics.uci.edu/ml/datasets/Housing">http://archive.ics.uci.edu/ml/datasets/Housing</a></p>
<p>该数据集是从位于卡内基梅隆大学维护的StatLib图书馆取得的。</p>
<p>Harrison, D. 和 Rubinfeld, D.L. 的波士顿房价数据：’Hedonic
prices and the demand for clean air’, J. Environ. Economics &amp; Management,
vol.5, 81-102, 1978，也被使用在 Belsley, Kuh &amp; Welsch 的 ‘Regression diagnostics
…’, Wiley, 1980。
注释：许多变化已经被应用在后者第244-261页的表中。</p>
<p>波士顿房价数据已被用于许多涉及回归问题的机器学习论文中。</p>
<p><strong>参考资料</strong></p>
<blockquote>
<div><ul class="simple">
<li>Belsley, Kuh &amp; Welsch, ‘Regression diagnostics: Identifying Influential Data and Sources of Collinearity’, Wiley, 1980. 244-261.</li>
<li>Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.</li>
<li>many more! (see <a class="reference external" href="http://archive.ics.uci.edu/ml/datasets/Housing">http://archive.ics.uci.edu/ml/datasets/Housing</a>)</li>
</ul>
</div></blockquote>
</div>
</div>
<div class="section" id="breast-cancer">
<span id="id41"></span><h2>5.14. 威斯康辛州乳腺癌（诊断）数据库<a class="headerlink" href="#breast-cancer" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id42">
<h3>5.14.1. 注释<a class="headerlink" href="#id42" title="Permalink to this headline">¶</a></h3>
<dl class="docutils">
<dt>数据集特征：</dt>
<dd><table class="first last docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">实例数量:</th><td class="field-body"><p class="first">569</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">属性数量:</th><td class="field-body"><p class="first">30 (数值型，帮助预测的属性和类)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name" colspan="2">Attribute Information:</th></tr>
<tr class="field-odd field"><td>&#160;</td><td class="field-body"><ul class="first simple">
<li>radius 半径（从中心到边缘上点的距离的平均值）</li>
<li>texture 纹理（灰度值的标准偏差）</li>
<li>perimeter 周长</li>
<li>area 区域</li>
<li>smoothness 平滑度（半径长度的局部变化）</li>
<li>compactness 紧凑度（周长 ^ 2 /面积 - 1.0）</li>
<li>concavity 凹面（轮廓的凹部的严重性）</li>
<li>concave points 凹点（轮廓的凹部的数量）</li>
<li>symmetry 对称性</li>
<li>fractal dimension 分形维数（海岸线近似 - 1）</li>
<li><dl class="first docutils">
<dt>类:</dt>
<dd><ul class="first last">
<li>WDBC-Malignant 恶性</li>
<li>WDBC-Benign 良性</li>
</ul>
</dd>
</dl>
</li>
</ul>
<p class="last">对每个图像计算这些特征的平均值，标准误差，以及“最差”（因为是肿瘤）或最大值（最大的前三个值的平均值）</p>
</td>
</tr>
</tbody>
</table>
</dd>
</dl>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;得到30个特征。例如，字段 3 是平均半径，字段 13 是半径的标准误差，字段 23 是最差半径。</p>
<blockquote>
<div><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">统计摘要:</th><td class="field-body"><table border="1" class="first docutils">
<colgroup>
<col width="76%" />
<col width="12%" />
<col width="12%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">&#160;</th>
<th class="head">&#160;</th>
<th class="head">&#160;</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>radius (mean):</td>
<td>6.981</td>
<td>28.11</td>
</tr>
<tr class="row-odd"><td>texture (mean):</td>
<td>9.71</td>
<td>39.28</td>
</tr>
<tr class="row-even"><td>perimeter (mean):</td>
<td>43.79</td>
<td>188.5</td>
</tr>
<tr class="row-odd"><td>area (mean):</td>
<td>143.5</td>
<td>2501.0</td>
</tr>
<tr class="row-even"><td>smoothness (mean):</td>
<td>0.053</td>
<td>0.163</td>
</tr>
<tr class="row-odd"><td>compactness (mean):</td>
<td>0.019</td>
<td>0.345</td>
</tr>
<tr class="row-even"><td>concavity (mean):</td>
<td>0.0</td>
<td>0.427</td>
</tr>
<tr class="row-odd"><td>concave points (mean):</td>
<td>0.0</td>
<td>0.201</td>
</tr>
<tr class="row-even"><td>symmetry (mean):</td>
<td>0.106</td>
<td>0.304</td>
</tr>
<tr class="row-odd"><td>fractal dimension (mean):</td>
<td>0.05</td>
<td>0.097</td>
</tr>
<tr class="row-even"><td>radius (standard error):</td>
<td>0.112</td>
<td>2.873</td>
</tr>
<tr class="row-odd"><td>texture (standard error):</td>
<td>0.36</td>
<td>4.885</td>
</tr>
<tr class="row-even"><td>perimeter (standard error):</td>
<td>0.757</td>
<td>21.98</td>
</tr>
<tr class="row-odd"><td>area (standard error):</td>
<td>6.802</td>
<td>542.2</td>
</tr>
<tr class="row-even"><td>smoothness (standard error):</td>
<td>0.002</td>
<td>0.031</td>
</tr>
<tr class="row-odd"><td>compactness (standard error):</td>
<td>0.002</td>
<td>0.135</td>
</tr>
<tr class="row-even"><td>concavity (standard error):</td>
<td>0.0</td>
<td>0.396</td>
</tr>
<tr class="row-odd"><td>concave points (standard error):</td>
<td>0.0</td>
<td>0.053</td>
</tr>
<tr class="row-even"><td>symmetry (standard error):</td>
<td>0.008</td>
<td>0.079</td>
</tr>
<tr class="row-odd"><td>fractal dimension (standard error):</td>
<td>0.001</td>
<td>0.03</td>
</tr>
<tr class="row-even"><td>radius (worst):</td>
<td>7.93</td>
<td>36.04</td>
</tr>
<tr class="row-odd"><td>texture (worst):</td>
<td>12.02</td>
<td>49.54</td>
</tr>
<tr class="row-even"><td>perimeter (worst):</td>
<td>50.41</td>
<td>251.2</td>
</tr>
<tr class="row-odd"><td>area (worst):</td>
<td>185.2</td>
<td>4254.0</td>
</tr>
<tr class="row-even"><td>smoothness (worst):</td>
<td>0.071</td>
<td>0.223</td>
</tr>
<tr class="row-odd"><td>compactness (worst):</td>
<td>0.027</td>
<td>1.058</td>
</tr>
<tr class="row-even"><td>concavity (worst):</td>
<td>0.0</td>
<td>1.252</td>
</tr>
<tr class="row-odd"><td>concave points (worst):</td>
<td>0.0</td>
<td>0.291</td>
</tr>
<tr class="row-even"><td>symmetry (worst):</td>
<td>0.156</td>
<td>0.664</td>
</tr>
<tr class="row-odd"><td>fractal dimension (worst):</td>
<td>0.055</td>
<td>0.208</td>
</tr>
</tbody>
</table>
<table class="last docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">缺失属性值:</th><td class="field-body">无</td>
</tr>
<tr class="field-even field"><th class="field-name">类别分布:</th><td class="field-body">212 - 恶性, 357 - 良性</td>
</tr>
<tr class="field-odd field"><th class="field-name">创建者:</th><td class="field-body">Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian</td>
</tr>
<tr class="field-even field"><th class="field-name">捐助者:</th><td class="field-body">Nick Street</td>
</tr>
<tr class="field-odd field"><th class="field-name">日期:</th><td class="field-body">1995年11月</td>
</tr>
</tbody>
</table>
</td>
</tr>
</tbody>
</table>
</div></blockquote>
<p>这是UCI ML（欧文加利福尼亚大学 机器学习库）威斯康星州乳腺癌（诊断）数据集的副本。
<a class="reference external" href="https://goo.gl/U2Uwz2">https://goo.gl/U2Uwz2</a></p>
<p>这些特征是从乳房肿块的细针抽吸术（FNA）的数字图像中计算得到，描述了图像中存在的细胞核的特征。</p>
<p>上述的分离平面是由多表面方法树（MSM-T）[K.P.Bennett, “Decision Tree Construction Via
Linear Programming.” Proceedings of the 4th Midwest Artificial Intelligence and
Cognitive Science Society, pp.97-101, 1992], a classification method which uses
linear programming to construct a decision tree.
相关特征是在1-4的特征和1-3的分离平面中使用穷举法搜索选取出的。</p>
<p>用于分离平面的线性规划在三维空间中描述如下：
[K. P. Bennett and O. L. Mangasarian: “Robust Linear Programming Discrimination
of Two Linearly Inseparable Sets”, Optimization Methods and Software 1, 1992, 23-34].</p>
<p>该数据库也可通过UW CS ftp服务器获得：</p>
<p>ftp ftp.cs.wisc.edu
cd math-prog/cpo-dataset/machine-learn/WDBC/</p>
</div>
<div class="section" id="id43">
<h3>5.14.2. 参考资料<a class="headerlink" href="#id43" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li>W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction
for breast tumor diagnosis. IS&amp;T/SPIE 1993 International Symposium on
Electronic Imaging: Science and Technology, volume 1905, pages 861-870,
San Jose, CA, 1993.</li>
<li>O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and
prognosis via linear programming. Operations Research, 43(4), pages 570-577,
July-August 1995.</li>
<li>W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques
to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994)
163-171.</li>
</ul>
</div></blockquote>
</div>
</div>
<div class="section" id="diabetes">
<span id="id44"></span><h2>5.15. 糖尿病数据集<a class="headerlink" href="#diabetes" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id45">
<h3>5.15.1. 注释<a class="headerlink" href="#id45" title="Permalink to this headline">¶</a></h3>
<p>从442例糖尿病患者中获得了十个基线变量，年龄，性别，体重指数，平均血压和六个血清测量值，以及一个我们感兴趣的，在基线后一年疾病发展的定量测量值。</p>
<p>数据集特征:</p>
<blockquote>
<div><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">实例数量:</th><td class="field-body"><p class="first">442</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">属性数量:</th><td class="field-body"><p class="first">前10列是数值型的帮助预测的值</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">目标:</th><td class="field-body"><p class="first">第11列是基线后一年疾病进展的定量测量址</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">属性:</th><td class="field-body"><table class="first last docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Age年龄:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Sex性别:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name" colspan="2">Body mass index体重指数:</th></tr>
<tr class="field-odd field"><td>&#160;</td><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name" colspan="2">Average blood pressure平均血压:</th></tr>
<tr class="field-even field"><td>&#160;</td><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">S1血清测量值1:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">S2血清测量值2:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">S3血清测量值3:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">S4血清测量值4:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">S5血清测量值5:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">S6血清测量值6:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
</tbody>
</table>
</div></blockquote>
<p>注意: 这10个特征变量都已经分别以均值为中心，并按照标准偏差乘以样本数（n_samples）进行缩放（即每列的平方和为1）。</p>
<p>源 URL:
<a class="reference external" href="http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html">http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html</a></p>
<p>更多信息，请参阅:
Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) “Least Angle Regression,” Annals of Statistics (with discussion), 407-499.
(<a class="reference external" href="http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf">http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf</a>)</p>
</div>
</div>
<div class="section" id="digits">
<span id="id46"></span><h2>5.16. 光学识别手写数字数据集<a class="headerlink" href="#digits" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id47">
<h3>5.16.1. 注释<a class="headerlink" href="#id47" title="Permalink to this headline">¶</a></h3>
<dl class="docutils">
<dt>数据集特征：</dt>
<dd><table class="first last docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">实例数量:</th><td class="field-body"><p class="first">5620</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">属性数量:</th><td class="field-body"><p class="first">64</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">属性信息:</th><td class="field-body"><p class="first">8x8 范围在（0-16）的整型像素值图片</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">缺失属性值:</th><td class="field-body"><p class="first">无</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">创建者:</th><td class="field-body"><ol class="first upperalpha simple" start="5">
<li>Alpaydin (<a class="reference external" href="mailto:alpaydin&#37;&#52;&#48;boun&#46;edu&#46;tr">alpaydin<span>&#64;</span>boun<span>&#46;</span>edu<span>&#46;</span>tr</a>)</li>
</ol>
</td>
</tr>
<tr class="field-even field"><th class="field-name">日期:</th><td class="field-body"><p class="first last">1998年7月</p>
</td>
</tr>
</tbody>
</table>
</dd>
</dl>
<p>这是UCI ML（欧文加利福尼亚大学 机器学习库）手写数字数据集的测试集的副本。
<a class="reference external" href="http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits">http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits</a></p>
<p>数据集包含手写数字的图像：10个类别中每个类都是一个数字。</p>
<p>从预印表格中提取手写数字的标准化的位图这一过程，应用了NIST提供的预处理程序。
这些数据是从43人中得到，其中30人为训练集，13人为测试集。32x32位图被划分为4x4的非重叠块，
并且在每个块中计数像素数。这产生8×8的输入矩阵，其中每个元素是0-16范围内的整数。
这个过程降低了维度，并且在小的变形中提供了不变性。</p>
<p>有关NIST处理程序的信息，请参见 M. D. Garris, J. L. Blue, G.T. Candela,
D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.
L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,
1994.</p>
</div>
<div class="section" id="id48">
<h3>5.16.2. 参考资料<a class="headerlink" href="#id48" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li>C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their
Applications to Handwritten Digit Recognition, MSc Thesis, Institute of
Graduate Studies in Science and Engineering, Bogazici University.</li>
<li><ol class="first upperalpha" start="5">
<li>Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.</li>
</ol>
</li>
<li>Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.
Linear dimensionalityreduction using relevance weighted LDA. School of
Electrical and Electronic Engineering Nanyang Technological University.
2005.</li>
<li>Claudio Gentile. A New Approximate Maximal Margin Classification
Algorithm. NIPS. 2000.</li>
</ul>
</div></blockquote>
</div>
</div>
<div class="section" id="iris">
<span id="id49"></span><h2>5.17. 鸢尾花数据集<a class="headerlink" href="#iris" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id50">
<h3>5.17.1. 注释<a class="headerlink" href="#id50" title="Permalink to this headline">¶</a></h3>
<dl class="docutils">
<dt>数据集特征:</dt>
<dd><table class="first docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">实例数量:</th><td class="field-body"><p class="first">150 (三个类各有50个)</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">属性数量:</th><td class="field-body"><p class="first">4 (数值型，数值型，帮助预测的属性和类)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name" colspan="2">Attribute Information:</th></tr>
<tr class="field-odd field"><td>&#160;</td><td class="field-body"><ul class="first simple">
<li>sepal length 萼片长度（厘米）</li>
<li>sepal width 萼片宽度（厘米）</li>
<li>petal length 花瓣长度（厘米）</li>
<li>petal width 花瓣宽度（厘米）</li>
<li><dl class="first docutils">
<dt>class:</dt>
<dd><ul class="first last">
<li>Iris-Setosa 山鸢尾</li>
<li>Iris-Versicolour 变色鸢尾</li>
<li>Iris-Virginica 维吉尼亚鸢尾</li>
</ul>
</dd>
</dl>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">统计摘要:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
<table border="1" class="docutils">
<colgroup>
<col width="26%" />
<col width="7%" />
<col width="7%" />
<col width="13%" />
<col width="9%" />
<col width="37%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">&#160;</th>
<th class="head">&#160;</th>
<th class="head">&#160;</th>
<th class="head">&#160;</th>
<th class="head">&#160;</th>
<th class="head">&#160;</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>sepal length:</td>
<td>4.3</td>
<td>7.9</td>
<td>5.84</td>
<td>0.83</td>
<td>0.7826</td>
</tr>
<tr class="row-odd"><td>sepal width:</td>
<td>2.0</td>
<td>4.4</td>
<td>3.05</td>
<td>0.43</td>
<td>-0.4194</td>
</tr>
<tr class="row-even"><td>petal length:</td>
<td>1.0</td>
<td>6.9</td>
<td>3.76</td>
<td>1.76</td>
<td>0.9490  (high!)</td>
</tr>
<tr class="row-odd"><td>petal width:</td>
<td>0.1</td>
<td>2.5</td>
<td>1.20</td>
<td>0.76</td>
<td>0.9565  (high!)</td>
</tr>
</tbody>
</table>
<table class="last docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">缺失属性值:</th><td class="field-body">无</td>
</tr>
<tr class="field-even field"><th class="field-name">类别分布:</th><td class="field-body">3个类别各占33.3%</td>
</tr>
<tr class="field-odd field"><th class="field-name">创建者:</th><td class="field-body">R.A. Fisher</td>
</tr>
<tr class="field-even field"><th class="field-name">捐助者:</th><td class="field-body">Michael Marshall (<a class="reference external" href="mailto:MARSHALL%PLU&#37;&#52;&#48;io&#46;arc&#46;nasa&#46;gov">MARSHALL%PLU<span>&#64;</span>io<span>&#46;</span>arc<span>&#46;</span>nasa<span>&#46;</span>gov</a>)</td>
</tr>
<tr class="field-odd field"><th class="field-name">日期:</th><td class="field-body">1988年7月</td>
</tr>
</tbody>
</table>
</dd>
</dl>
<p>这是UCI ML（欧文加利福尼亚大学 机器学习库）鸢尾花数据集的副本。
<a class="reference external" href="http://archive.ics.uci.edu/ml/datasets/Iris">http://archive.ics.uci.edu/ml/datasets/Iris</a></p>
<p>著名的鸢尾花数据库，首先由R. Fisher先生使用。</p>
<p>这可能是在模式识别文献中最有名的数据库。Fisher的论文是这个领域的经典之作，到今天也经常被引用。（例如：Duda＆Hart）
数据集包含3个类，每类有50个实例，每个类指向一种类型的鸢尾花。一类与另外两类线性分离，而后者不能彼此线性分离。</p>
</div>
<div class="section" id="id51">
<h3>5.17.2. 参考资料<a class="headerlink" href="#id51" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li>Fisher,R.A. “The use of multiple measurements in taxonomic problems”
Annual Eugenics, 7, Part II, 179-188 (1936); also in “Contributions to
Mathematical Statistics” (John Wiley, NY, 1950).</li>
<li>Duda,R.O., &amp; Hart,P.E. (1973) Pattern Classification and Scene Analysis.
(Q327.D83) John Wiley &amp; Sons.  ISBN 0-471-22361-1.  See page 218.</li>
<li>Dasarathy, B.V. (1980) “Nosing Around the Neighborhood: A New System
Structure and Classification Rule for Recognition in Partially Exposed
Environments”.  IEEE Transactions on Pattern Analysis and Machine
Intelligence, Vol. PAMI-2, No. 1, 67-71.</li>
<li>Gates, G.W. (1972) “The Reduced Nearest Neighbor Rule”.  IEEE Transactions
on Information Theory, May 1972, 431-433.</li>
<li>See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al”s AUTOCLASS II
conceptual clustering system finds 3 classes in the data.</li>
<li>Many, many more …</li>
</ul>
</div></blockquote>
</div>
</div>
<div class="section" id="linnerrud">
<span id="linnerud"></span><h2>5.18. Linnerrud 数据集<a class="headerlink" href="#linnerrud" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id52">
<h3>5.18.1. 注释<a class="headerlink" href="#id52" title="Permalink to this headline">¶</a></h3>
<dl class="docutils">
<dt>数据集特征:</dt>
<dd><table class="first last docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">实例数量:</th><td class="field-body">20</td>
</tr>
<tr class="field-even field"><th class="field-name">属性数量:</th><td class="field-body">3</td>
</tr>
<tr class="field-odd field"><th class="field-name">缺失属性值:</th><td class="field-body">无</td>
</tr>
</tbody>
</table>
</dd>
</dl>
<p>Linnerud 数据集包含两个小的数据集:</p>
<ul class="simple">
<li><em>运动</em> ： 一个包含以下内容的列表：运动数据，关于3个运动相关变量的20个观测值：体重，腰围和脉搏。</li>
<li><em>生理</em> ： 一个包含以下内容的数据表：生理数据，关于三个生理变量的20个观测值：下巴，仰卧起坐和跳跃。</li>
</ul>
</div>
<div class="section" id="id53">
<h3>5.18.2. 参考资料<a class="headerlink" href="#id53" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li>Tenenhaus, M. (1998). La regression PLS: theorie et pratique. Paris: Editions Technic.</li>
</ul>
</div></blockquote>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>

      <!-- 评论留言区代码 start -->
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zNDAwMi8xMDU0MA==">
        <script type="text/javascript">
        (function(d, s) {
            var j, e = d.getElementsByTagName(s)[0];

            if (typeof LivereTower === 'function') { return; }

            j = d.createElement(s);
            j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
            j.async = true;

            e.parentNode.insertBefore(j, e);
        })(document, 'script');
        </script>
      </div>
      <!-- 评论留言区代码 end -->

    </div>

    <!-- 提 PR 时按原来文档的字母排序 -->

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    
    
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    
    <!-- datasets/index.html -->
    <div class="apachecn_doc_right">
      校验者: <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@不吃曲奇的趣多多</a><br/>
                 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@A</a><br/>
                 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@火星</a><br/>
                 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@Trembleguy</a><br/>
      翻译者: <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@cowboy</a><br/>
                 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@peels</a><br/>
                 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@t9UhoI</a><br/>
                 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@Sun</a><br/>     
    </div>
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

  </div>

  <div class="footer">
      &copy; 2007 - 2017, scikit-learn developers (BSD License).
    <a href="../_sources/datasets/index.rst.txt" rel="nofollow">Show this page source</a>
  </div>
   <div class="rel">
  
  <div class="buttonPrevious">
    <a href="../modules/preprocessing_targets.html">Previous
    </a>
  </div>
  <div class="buttonNext">
    <a href="olivetti_faces.html">Next
    </a>
  </div>
  
   </div>

  <!-- google analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  
    ga('create', 'UA-102475051-5', 'auto');
    ga('send', 'pageview');
  
  </script>
  
  <!-- baidu tongji -->
  <script>
  var _hmt = _hmt || [];
  (function() {
    var hm = document.createElement("script");
    hm.src = "https://hm.baidu.com/hm.js?9cbab13b4d28a9811ae1d2d2176dab66";
    var s = document.getElementsByTagName("script")[0]; 
    s.parentNode.insertBefore(hm, s);
  })();
  </script>

  <!-- baidu push -->
  <script>
  (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
          bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      }
      else {
          bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
  })();
  </script>
  </body>
</html>