{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# RBF kernels \u7684\u663e\u793a\u7279\u5f81\u56fe\u8fd1\u4f3c\n\n\n\u8bf4\u660e RBF kernel \u7684\u7279\u5f81\u56fe\u8fd1\u4f3c\u7684\u793a\u4f8b\u3002\n\n.. currentmodule:: sklearn.kernel_approximation\n\n\u5b83\u663e\u793a\u5982\u4f55\u4f7f\u7528 :class:`RBFSampler` \u548c :class:`Nystroem` \u6765\u8fd1\u4f3c RBF kernel \u7684 feature map \uff0c\u4ee5\u4fbf\u5728\u6570\u5b57\u6570\u636e\u96c6\u4e0a\u4f7f\u7528 SVM \u8fdb\u884c\u5206\u7c7b\u3002 \u6bd4\u8f83\u5728\u539f\u59cb\u7a7a\u95f4\u4e2d\u4f7f\u7528\u7ebf\u6027 SVM \u7684\u7ed3\u679c\uff0c\u4f7f\u7528 approximate mapping \u5e76\u4f7f\u7528\u6838\u5fc3\u5316 SVM \u7684\u7ebf\u6027 SVM \u8fdb\u884c\u6bd4\u8f83\u3002\n\u5bf9\u4e8e\u4e0d\u540c\u6570\u91cf\u7684 Monte Carlo \u53d6\u6837\uff08\u5728 :class:`RBFSampler` \uff09\u548c\u7528\u4e8e approximate mapping \u7684\u8bad\u7ec3\u96c6\uff08\u7528\u4e8e :class:`Nystroem` \uff09\u7684\u4e0d\u540c\u5927\u5c0f\u7684\u5b50\u96c6\u7684\u65f6\u95f4\u548c\u7cbe\u5ea6\u6240\u793a\u3002\n\n\u8bf7\u6ce8\u610f\uff0c\u8fd9\u91cc\u7684\u6570\u636e\u96c6\u4e0d\u8db3\u4ee5\u663e\u793a\u5185\u6838\u8fd1\u4f3c\u7684\u597d\u5904\uff0c\u56e0\u4e3a\u786e\u5207\u7684 SVM \u4ecd\u7136\u76f8\u5f53\u5feb\u3002\n\n\u62bd\u6837\u66f4\u591a\u7684\u7ef4\u5ea6\u660e\u663e\u5730\u80fd\u591f\u5f97\u5230\u66f4\u597d\u7684\u5206\u7c7b\u7ed3\u679c\uff0c\u4f46\u662f\u6210\u672c\u76f8\u5bf9\u6765\u8bf4\u4f1a\u66f4\u9ad8\u3002\u8fd9\u610f\u5473\u7740\u7531\u53c2\u6570 n_components \u7ed9\u51fa\u7684\u8fd0\u884c\u65f6\u95f4\u548c\u7cbe\u5ea6\u4e4b\u95f4\u5b58\u5728\u6298\u4e2d\u6548\u679c\u3002\u8bf7\u6ce8\u610f\uff0c\u901a\u8fc7\u4f7f\u7528\u968f\u673a\u68af\u5ea6\u4e0b\u964d class:`sklearn.linear_model.SGDClassifier` \uff0c\u53ef\u4ee5\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\u5927\u5927\u52a0\u5feb\u6c42\u89e3\u7ebf\u6027 SVM \u53ca\u8fd1\u4f3c kernel SVM \u3002\n\u5728 kernelized SVM \u7684\u60c5\u51b5\u4e0b\uff0c\u8fd9\u662f\u4e0d\u5bb9\u6613\u7684\u3002\n\n\u7b2c\u4e8c\u4e2a\u56fe\u5c55\u793a\u4e86 RBF kernel SVM \u7684\u51b3\u7b56\u9762\u548c\u5177\u6709 approximate kernel maps \u7684\u7ebf\u6027 SVM \u3002\n\u8be5\u56fe\u663e\u793a\u4e86\u6295\u5f71\u5230\u6570\u636e\u7684\u524d\u4e24\u4e2a\u4e3b\u8981\u5206\u91cf\u4e0a\u7684\u5206\u7c7b\u5668\u7684\u51b3\u7b56\u9762\u3002 \u8fd9\u79cd\u53ef\u89c6\u5316\u5e94\u8be5\u91c7\u7528 a grain of salt \uff0c\u56e0\u4e3a\u5b83\u53ea\u662f\u4e00\u4e2a\u901a\u8fc7\u51b3\u7b56\u8868\u9762\u572864\u7ef4\u5ea6\u7684\u6709\u8da3\u7684\u5207\u7247\u3002 \u7279\u522b\u8981\u6ce8\u610f\u7684\u662f\uff0c\u6570\u636e\u70b9\uff08\u8868\u793a\u4e3a\u70b9\uff09\u4e0d\u4e00\u5b9a\u88ab\u5206\u7c7b\u5230\u5b83\u6240\u5728\u7684\u533a\u57df\u4e2d\uff0c\u56e0\u4e3a\u5b83\u4e0d\u4f1a\u4f4d\u4e8e\u524d\u4e24\u4e2a\u4e3b\u8981\u5206\u91cf\u8de8\u8d8a\u7684\u5e73\u9762\u4e0a\u3002\n\n:class:`RBFSampler` \u548c :class:`Nystroem` \u7684\u4f7f\u7528\uff0c\u5728 `kernel_approximation` \u8be6\u7ec6\u4ecb\u7ecd\u4e86\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)\n\n# Author: Gael Varoquaux <gael dot varoquaux at normalesup dot org>\n#         Andreas Mueller <amueller@ais.uni-bonn.de>\n#         Joy yx <chinachenyyx@gmail.com>\n# License: BSD 3 clause\n\n# \u5bfc\u5165 numpy, matplotlib \u7b49\u9700\u8981\u4f7f\u7528\u7684\u6a21\u5757\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom time import time\n\n# \u5bfc\u5165\u6570\u636e\u96c6\uff0c\u5206\u7c7b\u5668\u548c\u6027\u80fd\u6307\u6807\nfrom sklearn import datasets, svm, pipeline\nfrom sklearn.kernel_approximation import (RBFSampler,\n                                          Nystroem)\nfrom sklearn.decomposition import PCA\n\n# \u5bfc\u5165 digits \u6570\u636e\u96c6\ndigits = datasets.load_digits(n_class=9)\n\n# \u8981\u5bf9\u6b64\u6570\u636e\u5e94\u7528\u5206\u7c7b\u5668\uff0c\u6211\u4eec\u9700\u8981 flatten images\uff0c\u4ee5 (\u6837\u672c, \u7279\u5f81) \u77e9\u9635\u8f6c\u6362\u6570\u636e\nn_samples = len(digits.data)\ndata = digits.data / 16.\n# mean() \u6c42\u53d6\u5747\u503c\ndata -= data.mean(axis=0)\n\n# \u6211\u4eec\u5728\u6570\u5b57\u7684\u524d\u534a\u90e8\u5206\u5b66\u4e60\u6570\u5b57\uff0c\u5373 data_train \u662f\u6570\u636e\u96c6\u7684\u524d\u534a\u90e8\u5206\n# targets_train \u662f\u6570\u636e\u96c6\u7684\u6807\u7b7e\u7684\u524d\u534a\u90e8\u5206\ndata_train, targets_train = (data[:n_samples // 2],\n                             digits.target[:n_samples // 2])\n\n\n# \u73b0\u5728\u6211\u4eec\u9884\u6d4b\u5269\u4e0b\u7684\u534a\u90e8\u5206\u6570\u636e\u96c6\u7684\u6807\u7b7e\ndata_test, targets_test = (data[n_samples // 2:],\n                           digits.target[n_samples // 2:])\n# data_test = scaler.transform(data_test)\n\n# \u521b\u5efa\u4e00\u4e2a svc \u5206\u7c7b\u5668\nkernel_svm = svm.SVC(gamma=.2)\nlinear_svm = svm.LinearSVC()\n\n# \u4ece kernel approximation \u548c \u7ebf\u6027 SVM \u4e2d\u521b\u5efa pipeline\n# RBFSampler() --- \u901a\u8fc7\u5176\u5085\u7acb\u53f6\u53d8\u6362\u7684 Monte Carlo \u8fd1\u4f3c\u7684 \u8fd1\u4f3c RBF kernel \u7684\u7279\u5f81\u56fe\u3002\u5b83\u5b9e\u73b0\u4e86 Random Kitchen Sinks \u7684\u53d8\u4f53\u3002\nfeature_map_fourier = RBFSampler(gamma=.2, random_state=1)\n# Nystroem() --- \u4f7f\u7528\u8bad\u7ec3\u6570\u636e\u7684\u5b50\u96c6\u8fd1\u4f3c\u4e00\u4e2a kernel map, \u4f7f\u7528\u6570\u636e\u7684\u5b50\u96c6\u4f5c\u4e3a\u57fa\u7840\u6784\u5efa\u4efb\u610f kernel \u7684\u8fd1\u4f3c\u7279\u5f81\u56fe\u3002\nfeature_map_nystroem = Nystroem(gamma=.2, random_state=1)\n# pipeline.Pipeline() --- final estimator \u7684\u53d8\u6362 pipeline \u3002pipeline \u7684\u76ee\u7684\u662f\u7ec4\u88c5\u51e0\u4e2a\u53ef\u4ee5\u4ea4\u53c9\u9a8c\u8bc1\u7684\u6b65\u9aa4\uff0c\u540c\u65f6\u8bbe\u7f6e\u4e0d\u540c\u7684\u53c2\u6570\u3002\n# \u8be6\u60c5\u53c2\u89c1\uff1ahttp://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\nfourier_approx_svm = pipeline.Pipeline([(\"feature_map\", feature_map_fourier),\n                                        (\"svm\", svm.LinearSVC())])\n\nnystroem_approx_svm = pipeline.Pipeline([(\"feature_map\", feature_map_nystroem),\n                                        (\"svm\", svm.LinearSVC())])\n\n# \u4f7f\u7528 \u7ebf\u6027 svm \u548c kernel svm \u6765\u62df\u5408\u5e76\u9884\u6d4b\n\nkernel_svm_time = time()\nkernel_svm.fit(data_train, targets_train)\nkernel_svm_score = kernel_svm.score(data_test, targets_test)\nkernel_svm_time = time() - kernel_svm_time\n\nlinear_svm_time = time()\nlinear_svm.fit(data_train, targets_train)\nlinear_svm_score = linear_svm.score(data_test, targets_test)\nlinear_svm_time = time() - linear_svm_time\n\nsample_sizes = 30 * np.arange(1, 10)\nfourier_scores = []\nnystroem_scores = []\nfourier_times = []\nnystroem_times = []\n\nfor D in sample_sizes:\n    fourier_approx_svm.set_params(feature_map__n_components=D)\n    nystroem_approx_svm.set_params(feature_map__n_components=D)\n    start = time()\n    nystroem_approx_svm.fit(data_train, targets_train)\n    nystroem_times.append(time() - start)\n\n    start = time()\n    fourier_approx_svm.fit(data_train, targets_train)\n    fourier_times.append(time() - start)\n\n    fourier_score = fourier_approx_svm.score(data_test, targets_test)\n    nystroem_score = nystroem_approx_svm.score(data_test, targets_test)\n    nystroem_scores.append(nystroem_score)\n    fourier_scores.append(fourier_score)\n\n# \u5c06\u9884\u6d4b\u7684\u7ed3\u679c\u7ed8\u5236\u51fa\u6765\nplt.figure(figsize=(8, 8))\naccuracy = plt.subplot(211)\n# \u7b2c\u4e8c\u4e2a y \u8f74\u4e3a\u65f6\u95f4\ntimescale = plt.subplot(212)\n\naccuracy.plot(sample_sizes, nystroem_scores, label=\"Nystroem approx. kernel\")\ntimescale.plot(sample_sizes, nystroem_times, '--',\n               label='Nystroem approx. kernel')\n\naccuracy.plot(sample_sizes, fourier_scores, label=\"Fourier approx. kernel\")\ntimescale.plot(sample_sizes, fourier_times, '--',\n               label='Fourier approx. kernel')\n\n# \u7cbe\u786e rbf \u548c \u7ebf\u6027 kernel \u7684\u6c34\u5e73\u7ebf\naccuracy.plot([sample_sizes[0], sample_sizes[-1]],\n              [linear_svm_score, linear_svm_score], label=\"linear svm\")\ntimescale.plot([sample_sizes[0], sample_sizes[-1]],\n               [linear_svm_time, linear_svm_time], '--', label='linear svm')\n\naccuracy.plot([sample_sizes[0], sample_sizes[-1]],\n              [kernel_svm_score, kernel_svm_score], label=\"rbf svm\")\ntimescale.plot([sample_sizes[0], sample_sizes[-1]],\n               [kernel_svm_time, kernel_svm_time], '--', label='rbf svm')\n\n# \u6570\u636e\u96c6\u7ef4\u6570\u7684\u5782\u76f4\u7ebf = 64\naccuracy.plot([64, 64], [0.7, 1], label=\"n_features\")\n\n# \u56fe\u4f8b \u548c \u6807\u7b7e\naccuracy.set_title(\"Classification accuracy\")\ntimescale.set_title(\"Training times\")\naccuracy.set_xlim(sample_sizes[0], sample_sizes[-1])\naccuracy.set_xticks(())\naccuracy.set_ylim(np.min(fourier_scores), 1)\ntimescale.set_xlabel(\"Sampling steps = transformed feature dimension\")\naccuracy.set_ylabel(\"Classification accuracy\")\ntimescale.set_ylabel(\"Training time in seconds\")\naccuracy.legend(loc='best')\ntimescale.legend(loc='best')\n\n# \u53ef\u89c6\u5316\u51b3\u7b56\u9762\uff0c\u9884\u6d4b\u5230\u6570\u636e\u96c6\u7684\u524d\u4e24\u4e2a\u4e3b\u8981\u5206\u91cf\npca = PCA(n_components=8).fit(data_train)\n\nX = pca.transform(data_train)\n\n# \u6cbf\u7740\u524d\u4e24\u4e2a\u4e3b\u8981\u5206\u91cf\u751f\u6210\u7f51\u683c\nmultiples = np.arange(-2, 2, 0.1)\n# \u6cbf\u7740\u7b2c\u4e00\u4e2a\u5206\u91cf\u7684\u6b65\u9aa4\nfirst = multiples[:, np.newaxis] * pca.components_[0, :]\n# \u6cbf\u7740\u7b2c\u4e8c\u4e2a\u5206\u91cf\u7684\u6b65\u9aa4\nsecond = multiples[:, np.newaxis] * pca.components_[1, :]\n# \u7ec4\u5408\ngrid = first[np.newaxis, :, :] + second[:, np.newaxis, :]\nflat_grid = grid.reshape(-1, data.shape[1])\n\n# \u52a0\u4e0a\u7ed8\u5236\u56fe\u4e0a\u7684 title\ntitles = ['SVC with rbf kernel',\n          'SVC (linear kernel)\\n with Fourier rbf feature map\\n'\n          'n_components=100',\n          'SVC (linear kernel)\\n with Nystroem rbf feature map\\n'\n          'n_components=100']\n\nplt.tight_layout()\nplt.figure(figsize=(12, 5))\n\n# \u9884\u6d4b\u5e76\u4e14\u7ed8\u5236\u51fa\u6765\nfor i, clf in enumerate((kernel_svm, nystroem_approx_svm,\n                         fourier_approx_svm)):\n    # \u7ed8\u5236\u51b3\u7b56\u8fb9\u754c\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u5c06\u4e3a\u7f51\u683c [x_min, x_max]x[y_min, y_max] \u4e2d\u7684\u6bcf\u4e2a\u70b9\u5206\u914d\u4e00\u4e2a\u989c\u8272\u3002\n    plt.subplot(1, 3, i + 1)\n    Z = clf.predict(flat_grid)\n\n    # \u5c06\u7ed3\u679c\u7ed8\u5236\u5230\u5f69\u8272\u56fe\u4e2d\n    Z = Z.reshape(grid.shape[:-1])\n    plt.contourf(multiples, multiples, Z, cmap=plt.cm.Paired)\n    plt.axis('off')\n\n    # \u7ed8\u5236\u8bad\u7ec3\u70b9\n    plt.scatter(X[:, 0], X[:, 1], c=targets_train, cmap=plt.cm.Paired,\n                edgecolors=(0, 0, 0))\n\n    plt.title(titles[i])\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}