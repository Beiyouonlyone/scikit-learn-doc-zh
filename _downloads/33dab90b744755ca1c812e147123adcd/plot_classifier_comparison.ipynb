{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# \u5206\u7c7b\u6bd4\u8f83\n\n\nscikit-learn \u4e2d\u7684\u51e0\u4e2a\u5206\u7c7b\u5668\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u6bd4\u8f83\u3002\n\u8fd9\u4e2a\u4f8b\u5b50\u7684\u76ee\u7684\u662f\u8bf4\u660e\u4e0d\u540c\u5206\u7c7b\u5668\u7684\u51b3\u7b56\u8fb9\u754c\u7684\u6027\u8d28\u3002\n\u8fd9\u4eff\u4f5b\u662f\u5927\u6d77\u4e2d\u7684\u4e00\u6ef4\u6c34\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u4f8b\u5b50\u6240\u4f20\u8fbe\u7684\u76f4\u89c9\u4e0d\u4e00\u5b9a\u4f1a\u8f6c\u79fb\u5230\u771f\u6b63\u7684\u6570\u636e\u96c6\u4e0a\u3002\n\n\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\uff0c\u6570\u636e\u53ef\u4ee5\u66f4\u5bb9\u6613\u5730\u7ebf\u6027\u5206\u79bb\uff0c\u8bf8\u5982\u6734\u7d20\u8d1d\u53f6\u65af\u548c\u7ebf\u6027 SVM \u4e4b\u7c7b\u7684\u5206\u7c7b\u5668\u7684\u7b80\u5355\u6027\u53ef\u80fd\u5bfc\u81f4\u6bd4\u5176\u4ed6\u5206\u7c7b\u5668\u66f4\u597d\u7684\u6cdb\u5316\u3002\n\n\u7ed8\u56fe\u663e\u793a\u4e86\u7eaf\u8272\u548c\u6d4b\u8bd5\u70b9\u534a\u900f\u660e\u7684\u8bad\u7ec3\u70b9\u3002\u53f3\u4e0b\u65b9\u663e\u793a\u4e86\u6d4b\u8bd5\u4eea\u7684\u5206\u7c7b\u7cbe\u5ea6\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)\n\n\n# Code source: Ga\u00ebl Varoquaux\n#              Andreas M\u00fcller\n# Modified for documentation by Jaques Grobler, Joy yx\n# License: BSD 3 clause\n\n# \u5bfc\u5165\u4e00\u4e9b\u5fc5\u8981\u7684\u6a21\u5757\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_moons, make_circles, make_classification\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nh = .02  # \u7f51\u683c\u4e2d\u7684\u6b65\u957f\n\n# \u5404\u5206\u7c7b\u5668\u5bf9\u5e94\u7684\u540d\u79f0\n# \u5404\u5206\u7c7b\u5668\u4e3a 1.k-\u8fd1\u90bb\uff0c\u4e5f\u5c31\u662f kNN 2. \u7ebf\u6027\u652f\u6301\u5411\u91cf\u673a 3. \u5e26\u6709 RBF \u6838\u7684 SVM 4.\u9ad8\u65af\u8fc7\u7a0b 5.\u51b3\u7b56\u6811 6.\u968f\u673a\u68ee\u6797 7.\u795e\u7ecf\u7f51\u7edc 8.\u96c6\u6210\u65b9\u6cd5 AdaBoost 9.\u6734\u7d20\u8d1d\u53f6\u65af 10.\u4e8c\u6b21\u5224\u522b\u5206\u6790\nnames = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n         \"Naive Bayes\", \"QDA\"]\n\n# \u5177\u4f53\u7684\u5206\u7c7b\u5668\u53c2\u6570\u548c\u8c03\u7528\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(kernel=\"linear\", C=0.025),\n    SVC(gamma=2, C=1),\n    GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n    DecisionTreeClassifier(max_depth=5),\n    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n    MLPClassifier(alpha=1),\n    AdaBoostClassifier(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis()]\n\n# make_classification() \u4ea7\u751f\u4e00\u4efd\u5206\u7c7b\u6570\u636e\uff0c\u53c2\u6570\u5982\u4e0b\uff1a\n# make_classification(n_samples=100, n_features=20, n_informative=2, n_redundant=2, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n# n_samples --- \u6837\u672c\u7684\u6761\u6570, n_features --- \u6240\u6709\u7279\u5f81\u7684\u4e2a\u6570, \u5176\u4e2d\u5305\u62ec n_informative \u4e2a\u4fe1\u606f\u7279\u5f81\uff0cn_redundant \u4e2a\u5197\u4f59\u7279\u5f81\uff0cn_repeated \u4e2a\u91cd\u590d\u7279\u5f81\uff0c\u4ee5\u53ca\u968f\u673a\u7ed8\u5236\u7684 n_features-n_informative-n_redundant- n_repeated \u65e0\u7528\u7279\u5f81\u3002\n# n_classes --- \u5206\u7c7b\u95ee\u9898\u7684\u7c7b\uff08\u6216\u6807\u7b7e\uff09\u7684\u6570\u91cf, n_clusters_per_class --- \u6bcf\u4e2a\u7c7b\u7684\u7c07\u6570, weights --- \u5206\u914d\u7ed9\u6bcf\u4e2a\u7c7b\u7684\u6837\u672c\u7684\u6bd4\u4f8b\u3002\u5982\u679c\u6ca1\u6709\uff0c\u90a3\u4e48\u7c7b\u4e4b\u95f4\u662f\u5e73\u8861\u7684\u3002\u8bf7\u6ce8\u610f\uff0c\u5982\u679c len(weights) == n_classes-1, \u5219\u81ea\u52a8\u63a8\u65ad\u6700\u540e\u4e00\u4e2a\u7c7b\u7684\u6743\u91cd\u3002\u5982\u679c\u6743\u91cd\u4e4b\u548c\u8d85\u8fc71\uff0c\u5219\u53ef\u4ee5\u8fd4\u56de n_samples \u4e2a\u6837\u672c\u3002\n# flip_y --- \u968f\u673a\u4ea4\u6362\u7c7b\u7684\u6837\u672c\u90e8\u5206\u3002\u8f83\u5927\u7684\u503c\u4f1a\u5728\u6807\u7b7e\u4e2d\u5f15\u5165\u566a\u58f0\uff0c\u4f7f\u5206\u7c7b\u4efb\u52a1\u66f4\u52a0\u56f0\u96be\u3002 class_sep --- factor \u4e58\u4ee5 hypercube size, \u8f83\u5927\u7684\u503c\u6269\u5c55\u4e86\u7c07/\u7c7b\uff0c\u5e76\u4f7f\u5206\u7c7b\u4efb\u52a1\u66f4\u52a0\u5bb9\u6613\u3002 hypercube --- \u5982\u679c\u4e3a true, \u5219\u5c06\u805a\u7c7b\u653e\u5728 hypercube \u7684\u9876\u70b9\u4e0a\u3002\u5982\u679c\u4e3a false, \u5219\u5c06\u805a\u7c7b\u653e\u5728\u968f\u5373\u591a\u9762\u4f53\u4e0a\u3002\n# shift --- \u6309\u7279\u5b9a\u7684\u503c\u79fb\u52a8\u7279\u5f81\u3002\u5982\u679c\u6ca1\u6709\uff0c\u5219\u7279\u5f81\u88ab\u79fb\u52a8\u5728 [-class_sep, class_sep] \u4e2d\u7ed8\u5236\u7684\u968f\u673a\u503c\u3002 scale --- \u5c06\u7279\u5f81\u4e58\u4ee5\u7279\u5b9a\u503c\u3002\u5982\u679c\u6ca1\u6709\uff0c\u5219\u6309\u7167 [1, 100] \u4e2d\u7ed8\u5236\u7684\u968f\u673a\u503c\u5bf9\u7279\u5f81\u8fdb\u884c\u7f29\u653e\u3002\u8bf7\u6ce8\u610f\uff0c\u7f29\u653e\u53d1\u751f\u5728\u79fb\u4f4d\u4e4b\u540e\u3002\n# shuffle --- \u5c06 samples \u4ee5\u53ca features \u5206\u522b shuffle\u3002 random_state --- \u5982\u679c\u662f int, random_state \u662f\u968f\u673a\u6570\u751f\u6210\u5668\u4f7f\u7528\u7684\u79cd\u5b50; \u5982\u679c\u662f RandomState \u7684\u5b9e\u4f8b\uff0crandom_state \u662f\u968f\u673a\u6570\u751f\u6210\u5668; \u5982\u679c\u6ca1\u6709\uff0c\u968f\u673a\u6570\u751f\u6210\u5668\u662f\u7531 np.random \u4f7f\u7528\u7684 RandomState \u5b9e\u4f8b\u3002\n# \u518d\u5177\u4f53\u7684\uff0c\u8bf7\u770b\u82f1\u6587\u6587\u6863\uff1ahttp://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html\nX, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n                           random_state=1, n_clusters_per_class=1)\nrng = np.random.RandomState(2)\n# numpy.random.uniform(low,high,size) \u4ece\u4e00\u4e2a\u5747\u5300\u5206\u5e03 [low,high) \u4e2d\u968f\u673a\u91c7\u6837\uff0c\u6ce8\u610f\u5b9a\u4e49\u57df\u662f\u5de6\u95ed\u53f3\u5f00\uff0c\u5373\u5305\u542b low\uff0c\u4e0d\u5305\u542b high\u3002\u53c2\u6570\u5982\u4e0b\uff1a\n# low: \u91c7\u6837\u4e0b\u754c\uff0cfloat\u7c7b\u578b\uff0c\u9ed8\u8ba4\u503c\u4e3a0\uff1b\n# high: \u91c7\u6837\u4e0a\u754c\uff0cfloat\u7c7b\u578b\uff0c\u9ed8\u8ba4\u503c\u4e3a1\uff1b\n# size: \u8f93\u51fa\u6837\u672c\u6570\u76ee\uff0c\u4e3aint\u6216\u5143\u7ec4(tuple)\u7c7b\u578b\uff0c\u4f8b\u5982\uff0csize=(m,n,k), \u5219\u8f93\u51fa m*n*k \u4e2a\u6837\u672c\uff0c\u7f3a\u7701\u65f6\u8f93\u51fa1\u4e2a\u503c\u3002\nX += 2 * rng.uniform(size=X.shape)\nlinearly_separable = (X, y)\n\ndatasets = [make_moons(noise=0.3, random_state=0),\n            make_circles(noise=0.2, factor=0.5, random_state=1),\n            linearly_separable\n            ]\n\n# plt.figure() \u65b0\u5efa\u7ed8\u753b\u7a97\u53e3\uff0c\u72ec\u7acb\u663e\u793a\u7ed8\u753b\u7684\u56fe\u7247\nfigure = plt.figure(figsize=(27, 9))\ni = 1\n# \u8fed\u4ee3\u6570\u636e\u96c6\nfor ds_cnt, ds in enumerate(datasets):\n    # \u9884\u5904\u7406\u6570\u636e\u96c6\uff0c\u5206\u4e3a\u8bad\u7ec3\u548c\u6d4b\u8bd5\u90e8\u5206\n    X, y = ds\n    # StandardScaler() \u8ba1\u7b97\u8bad\u7ec3\u96c6\u7684\u5e73\u5747\u503c\u548c\u6807\u51c6\u5dee\uff0c\u4ee5\u4fbf\u6d4b\u8bd5\u6570\u636e\u96c6\u4f7f\u7528\u76f8\u540c\u7684\u53d8\u6362.\u5177\u4f53\u7684\u53c2\u89c1\uff1ahttp://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n    # fit_transform() \u5148\u62df\u5408\u6570\u636e\uff0c\u7136\u540e\u8f6c\u5316\u5b83\u5c06\u5176\u8f6c\u5316\u4e3a\u6807\u51c6\u5f62\u5f0f.\n    # train_test_split() \u968f\u673a\u5212\u5206\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\n    X = StandardScaler().fit_transform(X)\n    X_train, X_test, y_train, y_test = \\\n        train_test_split(X, y, test_size=.4, random_state=42)\n\n    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n    # [X,Y] = meshgrid(x,y) \u5c06\u5411\u91cfx\u548cy\u5b9a\u4e49\u7684\u533a\u57df\u8f6c\u6362\u6210\u77e9\u9635X\u548cY\uff0c\u8fd9\u4e24\u4e2a\u77e9\u9635\u53ef\u4ee5\u7528\u6765\u8868\u793amesh\u548csurf\u7684\u4e09\u7ef4\u7a7a\u95f4\u70b9\u4ee5\u53ca\u4e24\u4e2a\u53d8\u91cf\u7684\u8d4b\u503c\u3002\u5176\u4e2d\u77e9\u9635X\u7684\u884c\u5411\u91cf\u662f\u5411\u91cfx\u7684\u7b80\u5355\u590d\u5236\uff0c\u800c\u77e9\u9635Y\u7684\u5217\u5411\u91cf\u662f\u5411\u91cfy\u7684\u7b80\u5355\u590d\u5236\u3002\n    # \u8be6\u60c5\u53c2\u89c1\uff1ahttps://docs.scipy.org/doc/numpy/reference/generated/numpy.meshgrid.html\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n\n    # \u90a3\u6211\u4eec\u5c31\u9996\u5148\u5c06\u6570\u636e\u96c6\u7ed8\u5236\u51fa\u6765\n    cm = plt.cm.RdBu\n    # ListedColormap() \u662f\u4e00\u4e2a\u4ee5\u53c2\u6570\u4e2d\u7684\u5217\u51fa\u7684\u989c\u8272\u6765\u6620\u5c04\u7684\u51fd\u6570\u3002\n    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n    # subplot() \u5728\u7ed8\u56fe\u533a\u57df\u7684\u5b50\u533a\u57df\u4e2d\u753b\u56fe\n    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n    if ds_cnt == 0:\n        # \u8bbe\u7f6e title\n        ax.set_title(\"Input data\")\n    # \u7ed8\u5236\u8bad\u7ec3\u96c6\u4e2d\u7684\u70b9\n    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n               edgecolors='k')\n    # \u7ed8\u5236\u6d4b\u8bd5\u96c6\u4e2d\u7684\u70b9\n    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n               edgecolors='k')\n    # set_xlim() \u8bbe\u7f6e x \u8f74\u8303\u56f4\n    ax.set_xlim(xx.min(), xx.max())\n    # set_ylim() \u8bbe\u7f6e y \u8f74\u8303\u56f4\n    ax.set_ylim(yy.min(), yy.max())\n    # set_xticks \u8bbe\u7f6e x \u8f74\u5750\u6807\u70b9\n    ax.set_xticks(())\n    # set_yticks() \u8bbe\u7f6e y \u8f74\u5750\u6807\u70b9\n    ax.set_yticks(())\n    i += 1\n\n    # \u8fed\u4ee3\u4e0a\u9762\u6211\u4eec\u5217\u51fa\u6765\u7684\u51e0\u4e2a\u5206\u7c7b\u5668\n    # zip() \u51fd\u6570\u63a5\u53d7\u4efb\u610f\u591a\u4e2a\uff08\u5305\u62ec0\u4e2a\u62161\u4e2a\uff09\u5e8f\u5217\u4f5c\u4e3a\u53c2\u6570\uff0c\u8fd4\u56de\u4e00\u4e2a tuple \u5217\u8868\u3002\u5177\u4f53\u8bf7\u53c2\u89c1\uff1ahttp://www.cnblogs.com/frydsh/archive/2012/07/10/2585370.html\n    for name, clf in zip(names, classifiers):\n        # \u4e3a\u6bcf\u4e2a\u5206\u7c7b\u5668\u5206\u914d\u4e00\u4e2a\u753b\u56fe\u7684\u5c0f\u7684\u5b50\u7ed8\u56fe\u533a\u57df\n        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n        # \u62df\u5408\u5206\u7c7b\u5668\n        clf.fit(X_train, y_train)\n        # \u8ba1\u7b97\u6bcf\u4e2a\u5206\u7c7b\u5668\u7684\u5206\u6570\n        score = clf.score(X_test, y_test)\n\n        # \u7ed8\u5236\u51b3\u7b56\u8fb9\u754c\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u5c06\u4e3a\u7f51\u683c [x_min, x_max]x[y_min, y_max] \u4e2d\u7684\u6bcf\u4e2a\u70b9\u5206\u914d\u4e00\u4e2a\u989c\u8272\u3002\n        if hasattr(clf, \"decision_function\"):\n            # decision_function() \u8ba1\u7b97\u70b9\u5230\u51b3\u7b56\u8fb9\u754c\u7684\u51fd\u6570\u95f4\u9694\n            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n        else:\n            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n\n        # \u5c06\u7ed3\u679c\u653e\u5165\u5f69\u8272\u56fe\u4e2d\n        Z = Z.reshape(xx.shape)\n        # contourf() \u7ed8\u5236\u7b49\u9ad8\u7ebf\n        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n\n        # \u7ed8\u5236\u8bad\u7ec3\u96c6\u4e2d\u7684\u6570\u636e\u70b9\n        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n                   edgecolors='k')\n        # \u4e5f\u5c06\u6d4b\u8bd5\u70b9\u7ed8\u5236\u51fa\u6765\n        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n                   edgecolors='k', alpha=0.6)\n\n        ax.set_xlim(xx.min(), xx.max())\n        ax.set_ylim(yy.min(), yy.max())\n        ax.set_xticks(())\n        ax.set_yticks(())\n        if ds_cnt == 0:\n            ax.set_title(name)\n        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n                size=15, horizontalalignment='right')\n        i += 1\n\n# tight_layout() \u81ea\u52a8\u8c03\u6574\u5b50\u56fe\u53c2\u6570\u4ee5\u7ed9\u5b9a\u6307\u5b9a\u7684\u586b\u5145\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}