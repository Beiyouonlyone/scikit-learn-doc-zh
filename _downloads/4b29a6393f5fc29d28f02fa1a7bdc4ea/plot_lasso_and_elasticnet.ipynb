{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Lasso and Elastic Net for Sparse Signals\n\n\n\u4f30\u8ba1\u624b\u52a8\u4ea7\u751f\u7684\u7a00\u758f\u4fe1\u53f7 Lasso \u548c Elastic-Net \u56de\u5f52\u6a21\u578b\u4e0e\u9644\u52a0\u566a\u58f0\u76f8\u5173\u3002 \u4f30\u8ba1\u7684\u7cfb\u6570\u4e0e\u771f\u5b9e\u6570\u636e\u8fdb\u884c\u6bd4\u8f83\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import r2_score\n\n# #############################################################################\n# Generate some sparse data to play with\n# \u751f\u6210\u4e00\u4e9b\u7a00\u758f\u6570\u636e\u6765\u4f7f\u7528\nnp.random.seed(42)\n\nn_samples, n_features = 50, 200\nX = np.random.randn(n_samples, n_features)\ncoef = 3 * np.random.randn(n_features)\ninds = np.arange(n_features)\nnp.random.shuffle(inds)\ncoef[inds[10:]] = 0  # sparsify coef\ny = np.dot(X, coef)\n\n# add noise\ny += 0.01 * np.random.normal(size=n_samples)\n\n# Split data in train set and test set\nn_samples = X.shape[0]\nX_train, y_train = X[:n_samples // 2], y[:n_samples // 2]\nX_test, y_test = X[n_samples // 2:], y[n_samples // 2:]\n\n# #############################################################################\n# Lasso\nfrom sklearn.linear_model import Lasso\n\n# '''\n# Lasso\uff1a\u662f\u4f30\u8ba1\u7a00\u758f\u7cfb\u6570\u7684\u7ebf\u6027\u6a21\u578b\n# alpha\n#     \u53c2\u6570\u63a7\u5236\u4f30\u8ba1\u7cfb\u6570\u7684\u7a00\u758f\u5ea6\u3002\n#     \u5c06L1\u9879\u500d\u589e\u7684\u5e38\u6570\uff0c\u9ed8\u8ba4\u4e3a1.0\u3002\n#     alpha=0 \u76f8\u5f53\u4e8e\u901a\u8fc7 LinearRegression \u5bf9\u8c61\u6c42\u89e3\u7684\u666e\u901a\u6700\u5c0f\u4e8c\u4e58\u6cd5\u3002\n#     \u51fa\u4e8e\u6570\u503c\u539f\u56e0\uff0c\u4e0d\u5efa\u8bae\u4f7f\u7528 alpha=0 \u4e0e Lasso \u5bf9\u8c61\u3002\u7ed9\u5b9a\u8fd9\u4e2a\uff0c\u4f60\u5e94\u8be5\u4f7f\u7528 LinearRegression \u5bf9\u8c61\u3002\n#     \u5176\u4e2d C \u662f\u901a\u8fc7 alpha=1/C \u6216\u8005 alpha=1/(n_samples*C) \u5f97\u5230\u7684\u3002\n# '''\n# reg = linear_model.Lasso(alpha=0.1)\n# print reg.fit([[0, 0], [1, 1]], [0, 1])\n# print reg.predict([[1, 1]])\nalpha = 0.1\nlasso = Lasso(alpha=alpha)\n\ny_pred_lasso = lasso.fit(X_train, y_train).predict(X_test)\nr2_score_lasso = r2_score(y_test, y_pred_lasso)\nprint(lasso)\nprint(\"r^2 on test data : %f\" % r2_score_lasso)\n\n# #############################################################################\n# ElasticNet\nfrom sklearn.linear_model import ElasticNet\n\nenet = ElasticNet(alpha=alpha, l1_ratio=0.7)\n\ny_pred_enet = enet.fit(X_train, y_train).predict(X_test)\nr2_score_enet = r2_score(y_test, y_pred_enet)\nprint(enet)\nprint(\"r^2 on test data : %f\" % r2_score_enet)\n\nplt.plot(enet.coef_, color='lightgreen', linewidth=2,\n         label='Elastic net coefficients')\nplt.plot(lasso.coef_, color='gold', linewidth=2,\n         label='Lasso coefficients')\nplt.plot(coef, '--', color='navy', label='original coefficients')\nplt.legend(loc='best')\nplt.title(\"Lasso R^2: %f, Elastic Net R^2: %f\"\n          % (r2_score_lasso, r2_score_enet))\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}