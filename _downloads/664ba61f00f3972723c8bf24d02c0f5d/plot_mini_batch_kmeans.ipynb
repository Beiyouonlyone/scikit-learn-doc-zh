{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# K-Means \u548c MiniBatchKMeans \u805a\u7c7b\u7b97\u6cd5\u7684\u6bd4\u8f83\n\n\n\u6211\u4eec\u60f3\u8981\u53bb\u6bd4\u8f83\u4e00\u4e0bMiniBatchKMeans \u548c KMeans \u7b97\u6cd5\u7684\u6027\u80fd:\nMiniBatchKMeans \u66f4\u5feb, \u4f46\u662f\u7ed3\u679c\u4f1a\u7565\u6709\u4e0d\u540c\uff08\u8bf7\u53c2\u9605 `mini_batch_kmeans` \uff09\n\n\u6211\u4eec\u5c06\u5bf9\u4e00\u7ec4\u6570\u636e\u8fdb\u884c\u805a\u7c7b\uff0c\u9996\u5148\u4f7f\u7528 KMeans \u7b97\u6cd5\uff0c\u7136\u540e\u4f7f\u7528 MiniBatchKMeans \u7b97\u6cd5\uff0c\u5e76\u4e14\u7ed8\u5236\u51fa\u76f8\u5e94\u7684\u56fe\u5f62.\n\u6211\u4eec\u8fd8\u5c06\u4e24\u79cd\u7b97\u6cd5\u4e4b\u95f4\u4e0d\u540c\u6807\u7b7e\u7684\u70b9\u7ed9\u7ed8\u5236\u51fa\u6765\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)\n\nimport time\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.cluster import MiniBatchKMeans, KMeans\nfrom sklearn.metrics.pairwise import pairwise_distances_argmin\nfrom sklearn.datasets.samples_generator import make_blobs \n\n# #############################################################################\n# \u751f\u6210\u6837\u672c\u6570\u636e\nnp.random.seed(0)\n\nbatch_size = 45 # MiniBatchKMeans \u4e2d\u7684 batch \u5927\u5c0f\ncenters = [[1, 1], [-1, -1], [1, -1]] # \u8d28\u5fc3\u4f4d\u7f6e\nn_clusters = len(centers) # \u7c07\u6570\u91cf\uff08\u8d28\u5fc3\u6570\u91cf\uff09\nX, labels_true = make_blobs(n_samples=3000, centers=centers, cluster_std=0.7)\n\n# #############################################################################\n# \u4f7f\u7528 KMeans \u7b97\u6cd5\u6765\u8ba1\u7b97\u805a\u7c7b\n\nk_means = KMeans(init='k-means++', n_clusters=3, n_init=10)\nt0 = time.time()\nk_means.fit(X)\nt_batch = time.time() - t0\n\n# #############################################################################\n# \u4f7f\u7528 MiniBatchKMeans \u7b97\u6cd5\u6765\u8ba1\u7b97\u805a\u7c7b\n\nmbk = MiniBatchKMeans(init='k-means++', n_clusters=3, batch_size=batch_size,\n                      n_init=10, max_no_improvement=10, verbose=0)\nt0 = time.time()\nmbk.fit(X)\nt_mini_batch = time.time() - t0\n\n# #############################################################################\n# \u7ed8\u5236\u7ed3\u679c\n\nfig = plt.figure(figsize=(8, 3))\nfig.subplots_adjust(left=0.02, right=0.98, bottom=0.05, top=0.9)\ncolors = ['#4EACC5', '#FF9C34', '#4E9A06']\n\n# \u6211\u4eec\u5e0c\u671b\u5bf9\u4e8e\u6765\u81ea MiniBatchKMeans \u548cKMeans \u7b97\u6cd5\u7684\u76f8\u540c\u7c07\u5177\u6709\u76f8\u540c\u7684\u989c\u8272\u3002\n# \u6211\u4eec\u5c06\u6bcf\u4e2a\u6700\u8fd1\u7684\u805a\u7c7b\u4e2d\u5fc3\u5bf9\u9f50\u3002\nk_means_cluster_centers = np.sort(k_means.cluster_centers_, axis=0)\nmbk_means_cluster_centers = np.sort(mbk.cluster_centers_, axis=0)\nk_means_labels = pairwise_distances_argmin(X, k_means_cluster_centers)\nmbk_means_labels = pairwise_distances_argmin(X, mbk_means_cluster_centers)\norder = pairwise_distances_argmin(k_means_cluster_centers,\n                                  mbk_means_cluster_centers)\n\n# KMeans \u56fe\u50cf\u7ed8\u5236\nax = fig.add_subplot(1, 3, 1)\nfor k, col in zip(range(n_clusters), colors):\n    my_members = k_means_labels == k\n    cluster_center = k_means_cluster_centers[k]\n    ax.plot(X[my_members, 0], X[my_members, 1], 'w',\n            markerfacecolor=col, marker='.')\n    ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\n            markeredgecolor='k', markersize=6)\nax.set_title('KMeans')\nax.set_xticks(())\nax.set_yticks(())\nplt.text(-3.5, 1.8,  'train time: %.2fs\\ninertia: %f' % (\n    t_batch, k_means.inertia_))\n\n# MiniBatchKMeans \u56fe\u50cf\u7ed8\u5236\nax = fig.add_subplot(1, 3, 2)\nfor k, col in zip(range(n_clusters), colors):\n    my_members = mbk_means_labels == order[k]\n    cluster_center = mbk_means_cluster_centers[order[k]]\n    ax.plot(X[my_members, 0], X[my_members, 1], 'w',\n            markerfacecolor=col, marker='.')\n    ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\n            markeredgecolor='k', markersize=6)\nax.set_title('MiniBatchKMeans')\nax.set_xticks(())\nax.set_yticks(())\nplt.text(-3.5, 1.8, 'train time: %.2fs\\ninertia: %f' %\n         (t_mini_batch, mbk.inertia_))\n\n# Initialise the different array to all False\ndifferent = (mbk_means_labels == 4)\nax = fig.add_subplot(1, 3, 3)\n\nfor k in range(n_clusters):\n    different += ((k_means_labels == k) != (mbk_means_labels == order[k]))\n\nidentic = np.logical_not(different)\nax.plot(X[identic, 0], X[identic, 1], 'w',\n        markerfacecolor='#bbbbbb', marker='.')\nax.plot(X[different, 0], X[different, 1], 'w',\n        markerfacecolor='m', marker='.')\nax.set_title('Difference')\nax.set_xticks(())\nax.set_yticks(())\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}