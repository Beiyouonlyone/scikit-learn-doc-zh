

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

    <title>1.10. 决策树 &#8212; scikit-learn 0.19.0 中文文档 - ApacheCN</title>
<!-- htmltitle is before nature.css - we use this hack to load bootstrap first -->
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="stylesheet" href="../_static/css/bootstrap.min.css" media="screen" />
<link rel="stylesheet" href="../_static/css/bootstrap-responsive.css"/>

    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/js/copybutton.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="1.11. 集成方法" href="ensemble.html" />
    <link rel="prev" title="1.9. 朴素贝叶斯" href="naive_bayes.html" />


<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<script src="../_static/js/bootstrap.min.js" type="text/javascript"></script>
<link rel="canonical" href="http://scikit-learn.org/stable/modules/tree.html" />

<script type="text/javascript">
  $("div.buttonNext, div.buttonPrevious").hover(
     function () {
         $(this).css('background-color', '#FF9C34');
     },
     function () {
         $(this).css('background-color', '#A7D6E2');
     }
  );
  function showMenu() {
    var topNav = document.getElementById("scikit-navbar");
    if (topNav.className === "navbar") {
        topNav.className += " responsive";
    } else {
        topNav.className = "navbar";
    }
  };
</script>

  </head><body>

<div class="header-wrapper">
  <div class="header">
      <p class="logo"><a href="../index.html">
          <img src="../_static/scikit-learn-logo-small.png" alt="Logo"/>
      </a>
      </p><div class="navbar" id="scikit-navbar">
          <ul>
              <li><a href="../index.html">首页</a></li>
              <li><a href="../install.html">安装</a></li>
              <li class="btn-li">
                <div class="btn-group">
                    <a href="../documentation.html">文档</a>
                    <a class="btn dropdown-toggle" data-toggle="dropdown">
                      <span class="caret"></span>
                    </a>
                    <ul class="dropdown-menu">
                      <li class="link-title">Scikit-learn 0.19</li>
                      <li><a href="../tutorial/index.html">教程</a></li>
                      <li><a href="../user_guide.html">用户指南</a></li>
                      <li><a href="classes.html">API</a></li>
                      <li><a href="../faq.html">FAQ</a></li>
                      <li><a href="../developers/contributing.html">贡献</a></li>
                      <li class="divider"></li>
                      <li><a href="http://scikit-learn.org/stable/documentation.html">Scikit-learn 0.19 (stable)</a></li>
                      <li><a href="http://scikit-learn.org/0.18/documentation.html">Scikit-learn 0.18</a></li>
                      <li><a href="http://scikit-learn.org/0.17/documentation.html">Scikit-learn 0.17</a></li>
                      <li><a href="../_downloads/scikit-learn-docs.pdf">PDF 文档</a></li>
                    </ul>
                </div>
              </li>
              <li><a href="../auto_examples/index.html">示例</a></li>
              <li><a href="../project-timeline.html">时光轴</a></li>
              <li class="btn-li">
                <div class="btn-group">
                    <a href="javascript:void(0)">项目相关</a>
                    <a class="btn dropdown-toggle" data-toggle="dropdown">
                      <span class="caret"></span>
                    </a>
                    <ul class="dropdown-menu">
                      <li><a href="../project-role.html">项目角色</a></li>
                      <li><a href="../project-check-progress.html">校验进度</a></li>
                      <li><a href="../project-translation-progress.html">翻译进度</a></li>
                      <li><a href="//github.com/apachecn/scikit-learn-doc-zh#%E8%B4%A1%E7%8C%AE%E8%80%85" target="_blank">贡献者</a></li>
                      <li class="divider"></li>
                      <li><a href="../project-timeline.html">时光轴</a></li>
                      <li class="divider"></li>
                      <li><a href="../project-reward.html">项目奖励</a></li>
                      <li class="divider"></li>
                      <li><a href="http://www.apachecn.org/organization/244.html" target="_blank">积分物品</a></li>
                      <li><a href="http://www.apachecn.org/organization/269.html" target="_blank">兑换记录</a></li>
                      <li class="divider"></li>
                      <li><a href="../project-feedback.html">建议反馈</a></li>
                      <li><a href="../project-communication-group.html">技术交流</a></li>
                    </ul>
                </div>
              </li>
              <li><a href="//github.com/apachecn/scikit-learn-doc-zh#%E8%B4%A1%E7%8C%AE%E8%80%85" target="_blank">贡献者</a></li>
              <li><a href="//github.com/apachecn/scikit-learn-doc-zh" target="_blank">GitHub</a></li>
          </ul>
          <a href="javascript:void(0);" onclick="showMenu()">
              <div class="nav-icon">
                  <div class="hamburger-line"></div>
                  <div class="hamburger-line"></div>
                  <div class="hamburger-line"></div>
              </div>
          </a>
          <div class="search_form">
              <div class="gcse-search" id="cse" style="width: 100%;"></div>
          </div>
      </div> <!-- end navbar --></div>
</div>


<!-- Github "fork me" ribbon -->
<a href="https://github.com/apachecn/scikit-learn-doc-zh">
<img class="fork-me"
     style="position: absolute; top: 0; right: 0; border: 0;"
     src="../_static/img/starme.png"
     alt="Star me on GitHub" />
</a>

<div class="content-wrapper">
  <div class="sphinxsidebar">
  <div class="sphinxsidebarwrapper">
      <div class="rel">
  
      <div class="rellink">
      <a href="naive_bayes.html"
      accesskey="P">Previous
      <br/>
      <span class="smallrellink">
      1.9. 朴素贝叶斯
      </span>
          <span class="hiddenrellink">
          1.9. 朴素贝叶斯
          </span>
      </a>
      </div>
          <div class="spacer">
          &nbsp;
          </div>
      <div class="rellink">
      <a href="ensemble.html"
      accesskey="N">Next
      <br/>
      <span class="smallrellink">
      1.11. 集成方法
      </span>
          <span class="hiddenrellink">
          1.11. 集成方法
          </span>
      </a>
      </div>

  <!-- Ad a link to the 'up' page -->
      <div class="spacer">
      &nbsp;
      </div>
      <div class="rellink">
      <a href="../supervised_learning.html">
      Up
      <br/>
      <span class="smallrellink">
      1. 监督学习
      </span>
          <span class="hiddenrellink">
          1. 监督学习
          </span>
          
      </a>
      </div>
  </div>
  
    <p class="doc-version"><b>scikit-learn v0.19.0</b><br/>
    <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
  <p class="citing">Please <b><a href="../about.html#citing-scikit-learn" style="font-size: 110%;">cite us </a></b>if you use the software.</p>
  <ul>
<li><a class="reference internal" href="#">1.10. 决策树</a><ul>
<li><a class="reference internal" href="#tree-classification">1.10.1. 分类</a></li>
<li><a class="reference internal" href="#tree-regression">1.10.2. 回归</a></li>
<li><a class="reference internal" href="#tree-multioutput">1.10.3. 多值输出问题</a></li>
<li><a class="reference internal" href="#tree-complexity">1.10.4. 复杂度分析</a></li>
<li><a class="reference internal" href="#id6">1.10.5. 实际使用技巧</a></li>
<li><a class="reference internal" href="#tree-algorithms">1.10.6. 决策树算法: ID3, C4.5, C5.0 和 CART</a></li>
<li><a class="reference internal" href="#tree-mathematical-formulation">1.10.7. 数学表达</a><ul>
<li><a class="reference internal" href="#id9">1.10.7.1. 分类标准</a></li>
<li><a class="reference internal" href="#id10">1.10.7.2. 回归标准</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </div>
</div>

<input type="checkbox" id="nav-trigger" class="nav-trigger" checked />
<label for="nav-trigger"></label>




    <div class="content">
          
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="tree">
<span id="id1"></span><h1>1.10. 决策树<a class="headerlink" href="#tree" title="Permalink to this headline">¶</a></h1>
<p><strong>Decision Trees (DTs)</strong>  是一种用来 <a class="reference internal" href="#tree-classification"><span class="std std-ref">classification</span></a> 和 <a class="reference internal" href="#tree-regression"><span class="std std-ref">regression</span></a> 的无参监督学习方法。其目的是创建一种模型从数据特征中学习简单的决策规则来预测一个目标变量的值。</p>
<p>例如，在下面的图片中，决策树通过if-then-else的决策规则来学习数据从而估测数一个正弦图像。决策树越深入，决策规则就越复杂并且对数据的拟合越好。</p>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/tree/plot_tree_regression.html"><img alt="modules/../auto_examples/tree/images/sphx_glr_plot_tree_regression_001.png" src="modules/../auto_examples/tree/images/sphx_glr_plot_tree_regression_001.png" /></a>
</div>
<p>决策树的优势:</p>
<blockquote>
<div><ul class="simple">
<li>便于理解和解释。树的结构可以可视化出来。</li>
</ul>
<blockquote>
<div><ul class="simple">
<li>训练需要的数据少。其他机器学习模型通常需要数据规范化，比如构建虚拟变量和移除缺失值,不过请注意，这种模型不支持缺失值。</li>
</ul>
</div></blockquote>
<ul class="simple">
<li>由于训练决策树的数据点的数量导致了决策树的使用开销呈指数分布(训练树模型的时间复杂度是参与训练数据点的对数值)。</li>
<li>能够处理数值型数据和分类数据。其他的技术通常只能用来专门分析某一种变量类型的数据集。详情请参阅算法。</li>
<li>能够处理多路输出的问题。</li>
<li>使用白盒模型。如果某种给定的情况在该模型中是可以观察的，那么就可以轻易的通过布尔逻辑来解释这种情况。相比之下，在黑盒模型中的结果就是很难说明清        楚地。</li>
<li>可以通过数值统计测试来验证该模型。这对事解释验证该模型的可靠性成为可能。</li>
<li>即使该模型假设的结果与真实模型所提供的数据有些违反，其表现依旧良好。</li>
</ul>
</div></blockquote>
<p>决策树的缺点包括:</p>
<blockquote>
<div><ul class="simple">
<li>决策树模型容易产生一个过于复杂的模型,这样的模型对数据的泛化性能会很差。这就是所谓的过拟合.一些策略像剪枝、设置叶节点所需的最小样本数或设置数的最大深度是避免出现      该问题最为有效地方法。</li>
<li>决策树可能是不稳定的，因为数据中的微小变化可能会导致完全不同的树生成。这个问题可以通过决策树的集成来得到缓解</li>
<li>在多方面性能最优和简单化概念的要求下，学习一棵最优决策树通常是一个NP难问题。因此，实际的决策树学习算法是基于启发式算法，例如在每个节点进     行局部最优决策的贪心算法。这样的算法不能保证返回全局最优决策树。这个问题可以通过集成学习来训练多棵决策树来缓解,这多棵决策树一般通过对特征和样本有放回的随机采样来生成。</li>
<li>有些概念很难被决策树学习到,因为决策树很难清楚的表述这些概念。例如XOR，奇偶或者复用器的问题。</li>
<li>如果某些类在问题中占主导地位会使得创建的决策树有偏差。因此，我们建议在拟合前先对数据集进行平衡。</li>
</ul>
</div></blockquote>
<div class="section" id="tree-classification">
<span id="id2"></span><h2>1.10.1. 分类<a class="headerlink" href="#tree-classification" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier" title="sklearn.tree.DecisionTreeClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code></a> 是能够在数据集上执行多分类的类,与其他分类器一样，<a class="reference internal" href="generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier" title="sklearn.tree.DecisionTreeClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code></a> 采用输入两个数组：数组X，用 <code class="docutils literal notranslate"><span class="pre">[n_samples,</span> <span class="pre">n_features]</span></code> 的方式来存放训练样本。整数值数组Y，用 <code class="docutils literal notranslate"><span class="pre">[n_samples]</span></code> 来保存训练样本的类标签:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">tree</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</pre></div>
</div>
<p>执行通过之后，可以使用该模型来预测样本类别:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]])</span>
<span class="go">array([1])</span>
</pre></div>
</div>
<p>另外，也可以预测每个类的概率，这个概率是叶中相同类的训练样本的分数:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">([[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]])</span>
<span class="go">array([[ 0.,  1.]])</span>
</pre></div>
</div>
<p><a class="reference internal" href="generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier" title="sklearn.tree.DecisionTreeClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code></a> 既能用于二分类（其中标签为[-1,1]）也能用于多分类（其中标签为[0,…,k-1]）。使用Lris数据集，我们可以构造一个决策树，如下所示:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">tree</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
</pre></div>
</div>
<p>经过训练，我们可以使用 <a class="reference internal" href="generated/sklearn.tree.export_graphviz.html#sklearn.tree.export_graphviz" title="sklearn.tree.export_graphviz"><code class="xref py py-func docutils literal notranslate"><span class="pre">export_graphviz</span></code></a> 导出器以 <a class="reference external" href="http://www.graphviz.org/">Graphviz</a> 格式导出决策树.
如果你是用 <a class="reference external" href="http://conda.io">conda</a> 来管理包，那么安装 graphviz 二进制文件和 python 包可以用以下指令安装</p>
<blockquote>
<div>conda install python-graphviz</div></blockquote>
<p>或者，可以从 graphviz 项目主页下载 graphviz 的二进制文件，并从 pypi 安装 Python 包装器，并安装 <cite>pip install graphviz</cite> .以下是在整个 iris 数据集上训练的上述树的 graphviz 导出示例; 其结果被保存在 <cite>iris.pdf</cite> 中:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>   &gt;&gt;&gt; import graphviz # doctest: +SKIP
   &gt;&gt;&gt; dot_data = tree.export_graphviz(clf, out_file=None) # doctest: +SKIP
   &gt;&gt;&gt; graph = graphviz.Source(dot_data) # doctest: +SKIP
   &gt;&gt;&gt; graph.render(&quot;iris&quot;) # doctest: +SKIP

:func:`export_graphviz` 出导出还支持各种美化，包括通过他们的类着色节点（或回归值），如果需要，使用显式变量和类名。Jupyter notebook也可以自动找出相同的模块::

   &gt;&gt;&gt; dot_data = tree.export_graphviz(clf, out_file=None, # doctest: +SKIP
                            feature_names=iris.feature_names,  # doctest: +SKIP
                            class_names=iris.target_names,  # doctest: +SKIP
                            filled=True, rounded=True,  # doctest: +SKIP
                            special_characters=True)  # doctest: +SKIP
   &gt;&gt;&gt; graph = graphviz.Source(dot_data)  # doctest: +SKIP
   &gt;&gt;&gt; graph # doctest: +SKIP
</pre></div>
</div>
<div class="figure align-center">
<img alt="../_images/iris.svg" src="../_images/iris.svg" /></div>
<p>执行通过之后，可以使用该模型预测样品类别:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span>
<span class="go">array([0])</span>
</pre></div>
</div>
<p>或者，可以根据决策树叶子树里训练样本中的相同类的分数，使得类预测成为可能:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span>
<span class="go">array([[ 1.,  0.,  0.]])</span>
</pre></div>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/tree/plot_iris.html"><img alt="modules/../auto_examples/tree/images/sphx_glr_plot_iris_001.png" src="modules/../auto_examples/tree/images/sphx_glr_plot_iris_001.png" /></a>
</div>
<div class="topic">
<p class="topic-title first">示例:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/tree/plot_iris.html#sphx-glr-auto-examples-tree-plot-iris-py"><span class="std std-ref">Plot the decision surface of a decision tree on the iris dataset</span></a></li>
</ul>
</div>
</div>
<div class="section" id="tree-regression">
<span id="id3"></span><h2>1.10.2. 回归<a class="headerlink" href="#tree-regression" title="Permalink to this headline">¶</a></h2>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/tree/plot_tree_regression.html"><img alt="modules/../auto_examples/tree/images/sphx_glr_plot_tree_regression_001.png" src="modules/../auto_examples/tree/images/sphx_glr_plot_tree_regression_001.png" /></a>
</div>
<p>决策树通过使用 <a class="reference internal" href="generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor" title="sklearn.tree.DecisionTreeRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">DecisionTreeRegressor</span></code></a> 类也可以用来解决回归问题。如在分类设置中，拟合方法将数组X和数组y作为参数，只有在这种情况下，y数组预期才是浮点值:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">tree</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="go">array([ 0.5])</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">示例:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/tree/plot_tree_regression.html#sphx-glr-auto-examples-tree-plot-tree-regression-py"><span class="std std-ref">Decision Tree Regression</span></a></li>
</ul>
</div>
</div>
<div class="section" id="tree-multioutput">
<span id="id4"></span><h2>1.10.3. 多值输出问题<a class="headerlink" href="#tree-multioutput" title="Permalink to this headline">¶</a></h2>
<p>一个多值输出问题是一个类似当 Y 是大小为当 Y 是大小为 <code class="docutils literal notranslate"><span class="pre">[n_samples,</span> <span class="pre">n_outputs]</span></code> 的2d数组时，有多个输出值需要预测的监督学习问题。</p>
<p>当输出值之间没有关联时，一个很简单的处理该类型的方法是建立一个n独立模型，即每个模型对应一个输出，然后使用这些模型来独立地预测n个输出中的每一个。然而，由于可能与相同输入相关的输出值本身是相关的，所以通常更好的方法是构建能够同时预测所有n个输出的单个模型。首先，因为仅仅是建立了一个模型所以训练时间会更短。第二，最终模型的泛化性能也会有所提升。对于决策树，这一策略可以很容易地用于多输出问题。 这需要以下更改：</p>
<blockquote>
<div><ul class="simple">
<li>在叶中存储n个输出值，而不是一个;</li>
<li>通过计算所有n个输出的平均减少量来作为分裂标准.</li>
</ul>
</div></blockquote>
<p>该模块通过在 <code class="xref py py-class docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span> <span class="pre">`和</span> <span class="pre">:class:`DecisionTreeRegressor</span></code> 中实现该策略来支持多输出问题。如果决策树与大小为 <code class="docutils literal notranslate"><span class="pre">[n_samples,</span> <span class="pre">n_outputs]</span></code> 的输出数组Y向匹配，则得到的估计器将:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>* ``predict`` 是输出n_output的值

* 在 ``predict_proba`` 上输出 n_output 数组列表
</pre></div>
</div>
<p>用多输出决策树进行回归分析 <a class="reference internal" href="../auto_examples/tree/plot_tree_regression_multioutput.html#sphx-glr-auto-examples-tree-plot-tree-regression-multioutput-py"><span class="std std-ref">多输出决策树回归</span></a> 。 在该示例中，输入X是单个实数值，并且输出Y是X的正弦和余弦。</p>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/tree/plot_tree_regression_multioutput.html"><img alt="modules/../auto_examples/tree/images/sphx_glr_plot_tree_regression_multioutput_001.png" src="modules/../auto_examples/tree/images/sphx_glr_plot_tree_regression_multioutput_001.png" /></a>
</div>
<p>使用多输出树进行分类，在 <a class="reference internal" href="../auto_examples/plot_multioutput_face_completion.html#sphx-glr-auto-examples-plot-multioutput-face-completion-py"><span class="std std-ref">用多输出估算器进行面部修复</span></a> 中进行了演示。 在该示例中，输入X是面的上半部分的像素，并且输出Y是这些面的下半部分的像素。</p>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/plot_multioutput_face_completion.html"><img alt="modules/../auto_examples/images/sphx_glr_plot_multioutput_face_completion_001.png" src="modules/../auto_examples/images/sphx_glr_plot_multioutput_face_completion_001.png" /></a>
</div>
<div class="topic">
<p class="topic-title first">示例:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/tree/plot_tree_regression_multioutput.html#sphx-glr-auto-examples-tree-plot-tree-regression-multioutput-py"><span class="std std-ref">多输出决策树回归</span></a></li>
<li><a class="reference internal" href="../auto_examples/plot_multioutput_face_completion.html#sphx-glr-auto-examples-plot-multioutput-face-completion-py"><span class="std std-ref">用多输出估算器进行面部修复</span></a></li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">参考:</p>
<ul class="simple">
<li>M. Dumont et al,  <a class="reference external" href="http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2009/DMWG09/dumont-visapp09-shortpaper.pdf">Fast multi-class image annotation with random subwindows
and multiple output randomized trees</a>, International Conference on
Computer Vision Theory and Applications 2009</li>
</ul>
</div>
</div>
<div class="section" id="tree-complexity">
<span id="id5"></span><h2>1.10.4. 复杂度分析<a class="headerlink" href="#tree-complexity" title="Permalink to this headline">¶</a></h2>
<p>总体来说，用来构建平衡二叉树的运行时间为 <span class="math">O(n_{samples}n_{features}\log(n_{samples}))</span> 查询时间为 <span class="math">O(\log(n_{samples}))</span> 。尽管树的构造算法尝试生成平衡树，但它们并不总能保持平衡。假设子树能大概保持平衡，每个节点的成本包括通过 <span class="math">O(n_{features})</span> 时间复杂度来搜索找到提供熵减小最大的特征。每个节点的花费为 <span class="math">O(n_{features}n_{samples}\log(n_{samples}))</span> ，从而使得整个决策树的构造成本为 <span class="math">O(n_{features}n_{samples}^{2}\log(n_{samples}))</span> 。</p>
<p>Scikit-learn提供了更多有效的方法来创建决策树。初始实现（如上所述）将重新计算沿着给定特征的每个新分割点的类标签直方图（用于分类）或平均值（用于回归）。与分类所有的样本特征，然后再次训练时运行标签计数，可将每个节点的复杂度降低为 <span class="math">O(n_{features}\log(n_{samples}))</span> ，则总的成本花费为 <span class="math">O(n_{features}n_{samples}\log(n_{samples}))</span> 。这是一种对所有基于树的算法的改进选项。默认情况下，对于梯度提升模型该算法是打开的，一般来说它会让训练速度更快。但对于所有其他算法默认是关闭的，当训练深度很深的树时往往会减慢训练速度。</p>
</div>
<div class="section" id="id6">
<h2>1.10.5. 实际使用技巧<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><blockquote>
<div><ul class="simple">
<li>对于拥有大量特征的数据决策树会出现过拟合的现象。获得一个合适的样本比例和特征数量十分重要，因为在高维空间中只有少量的样本的树是十分容易过拟合的。</li>
<li>考虑事先进行降维( <a class="reference internal" href="decomposition.html#pca"><span class="std std-ref">PCA</span></a> , <a class="reference internal" href="decomposition.html#ica"><span class="std std-ref">ICA</span></a> ，使您的树更好地找到具有分辨性的特征。</li>
<li>通过 <code class="docutils literal notranslate"><span class="pre">export</span></code> 功能可以可视化您的决策树。使用 <code class="docutils literal notranslate"><span class="pre">max_depth=3</span></code> 作为初始树深度，让决策树知道如何适应您的数据，然后再增加树的深度。</li>
<li>请记住，填充树的样本数量会增加树的每个附加级别。使用 <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> 来控制输的大小防止过拟合。</li>
<li>通过使用 <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code> 和 <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> 来控制叶节点上的样本数量。当这个值很小时意味着生成的决策树将会过拟合，然而当这个值很大时将会不利于决策树的对样本的学习。所以尝试 <code class="docutils literal notranslate"><span class="pre">min_samples_leaf=5</span></code> 作为初始值。如果样本的变化量很大，可以使用浮点数作为这两个参数中的百分比。两者之间的主要区别在于 <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> 保证叶结点中最少的采样数，而 <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code> 可以创建任意小的叶子，尽管在文献中 <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code> 更常见。</li>
<li>在训练之前平衡您的数据集，以防止决策树偏向于主导类.可以通过从每个类中抽取相等数量的样本来进行类平衡，或者优选地通过将每个类的样本权重 (<code class="docutils literal notranslate"><span class="pre">sample_weight</span></code>) 的和归一化为相同的值。还要注意的是，基于权重的预修剪标准 (<code class="docutils literal notranslate"><span class="pre">min_weight_fraction_leaf</span></code>) 对于显性类别的偏倚偏小，而不是不了解样本权重的标准，如 <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> 。</li>
</ul>
</div></blockquote>
<ul class="simple">
<li>如果样本被加权，则使用基于权重的预修剪标准 <code class="docutils literal notranslate"><span class="pre">min_weight_fraction_leaf</span></code> 来优化树结构将更容易，这确保叶节点包含样本权重的总和的至少一部分。</li>
<li>所有的决策树内部使用 <code class="docutils literal notranslate"><span class="pre">np.float32</span></code> 数组 ，如果训练数据不是这种格式，将会复制数据集。</li>
<li>如果输入的矩阵X为稀疏矩阵，建议您在调用fit之前将矩阵X转换为稀疏的``csc_matrix`` ,在调用predict之前将 <code class="docutils literal notranslate"><span class="pre">csr_matrix</span></code> 稀疏。当特征在大多数样本中具有零值时，与密集矩阵相比，稀疏矩阵输入的训练时间可以快几个数量级。</li>
</ul>
</div></blockquote>
</div>
<div class="section" id="tree-algorithms">
<span id="id3-c4-5-c5-0-cart"></span><h2>1.10.6. 决策树算法: ID3, C4.5, C5.0 和 CART<a class="headerlink" href="#tree-algorithms" title="Permalink to this headline">¶</a></h2>
<p>所有种类的决策树算法有哪些以及它们之间的区别？scikit-learn 中实现何种算法呢？</p>
<p>ID3（Iterative Dichotomiser 3）由 Ross Quinlan 在1986年提出。该算法创建一个多路树，找到每个节点（即以贪心的方式）分类特征，这将产生分类目标的最大信息增益。决策树发展到其最大尺寸，然后通常利用剪枝来提高树对未知数据的泛华能力。</p>
<p>C4.5 是 ID3 的后继者，并且通过动态定义将连续属性值分割成一组离散间隔的离散属性（基于数字变量），消除了特征必须被明确分类的限制。C4.5 将训练的树（即，ID3算法的输出）转换成 if-then 规则的集合。然后评估每个规则的这些准确性，以确定应用它们的顺序。如果规则的准确性没有改变，则需要决策树的树枝来解决。</p>
<p>C5.0 是 Quinlan 根据专有许可证发布的最新版本。它使用更少的内存，并建立比 C4.5 更小的规则集，同时更准确。</p>
<p>CART（Classification and Regression Trees （分类和回归树））与 C4.5 非常相似，但它不同之处在于它支持数值目标变量（回归），并且不计算规则集。CART 使用在每个节点产生最大信息增益的特征和阈值来构造二叉树。</p>
<p>scikit-learn 使用 CART 算法的优化版本。</p>
</div>
<div class="section" id="tree-mathematical-formulation">
<span id="id8"></span><h2>1.10.7. 数学表达<a class="headerlink" href="#tree-mathematical-formulation" title="Permalink to this headline">¶</a></h2>
<p>给定训练向量 <span class="math">x_i \in R^n</span>, i=1,…, l 和标签向量 <span class="math">y \in R^l</span>。决策树递归地分割空间，例如将有相同标签的样本归为一组。</p>
<p>将 <span class="math">m</span> 节点上的数据用 <span class="math">Q</span> 来表示。每一个候选组 <span class="math">\theta = (j, t_m)</span> 包含一个特征 <span class="math">j</span> 和阈值 <span class="math">t_m</span> 将,数据分成 <span class="math">Q_{left}(\theta)</span> 和 <span class="math">Q_{right}(\theta)</span> 子集。</p>
<div class="math">
<p><span class="math">Q_{left}(\theta) = {(x, y) | x_j &lt;= t_m}

Q_{right}(\theta) = Q \setminus Q_{left}(\theta)</span></p>
</div><p>使用不纯度函数 <span class="math">H()</span> 计算 <span class="math">m</span> 处的不纯度,其选择取决于正在解决的任务（分类或回归）</p>
<div class="math">
<p><span class="math">G(Q, \theta) = \frac{n_{left}}{N_m} H(Q_{left}(\theta))
+ \frac{n_{right}}{N_m} H(Q_{right}(\theta))</span></p>
</div><p>选择使不纯度最小化的参数</p>
<div class="math">
<p><span class="math">\theta^* = \operatorname{argmin}_\theta  G(Q, \theta)</span></p>
</div><p>重新计算子集 <span class="math">Q_{left}(\theta^*)</span> 和 <span class="math">Q_{right}(\theta^*)</span> ，直到达到最大允许深度，<span class="math">N_m &lt; \min_{samples}</span> 或 <span class="math">N_m = 1</span>。</p>
<div class="section" id="id9">
<h3>1.10.7.1. 分类标准<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>对于节点 <span class="math">m</span> ，表示具有 <span class="math">N_m</span> 个观测值的区域 <span class="math">R_m</span> ，如果分类结果采用值是 0,1,…,K-1 的值，让</p>
<div class="math">
<p><span class="math">p_{mk} = 1/ N_m \sum_{x_i \in R_m} I(y_i = k)</span></p>
</div><p>是节点 <span class="math">m</span> 中k类观测的比例通常用来处理杂质的方法是Gini</p>
<div class="math">
<p><span class="math">H(X_m) = \sum_k p_{mk} (1 - p_{mk})</span></p>
</div><p>Cross-Entropy （交叉熵）</p>
<div class="math">
<p><span class="math">H(X_m) = - \sum_k p_{mk} \log(p_{mk})</span></p>
</div><p>和 Misclassification （错误分类）</p>
<div class="math">
<p><span class="math">H(X_m) = 1 - \max(p_{mk})</span></p>
</div><p>在 <span class="math">X_m</span> 训练 <span class="math">m</span> 节点上的数据时。</p>
</div>
<div class="section" id="id10">
<h3>1.10.7.2. 回归标准<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<p>如果目标是连续性的值，那么对于节点 <span class="math">m</span> ,表示具有 <span class="math">N_m</span> 个观测值的区域 <span class="math">R_m</span> ，对于以后的分裂节点的位置的决定常用的最小化标准是均方差和平均绝对误差，前者使用终端节点处的平均值来最小化L2误差，后者使用终端节点处的中值来最小化 L1 误差。</p>
<p>Mean Squared Error （均方误差）:</p>
<div class="math">
<p><span class="math">c_m = \frac{1}{N_m} \sum_{i \in N_m} y_i

H(X_m) = \frac{1}{N_m} \sum_{i \in N_m} (y_i - c_m)^2</span></p>
</div><p>Mean Absolute Error（平均绝对误差）:</p>
<div class="math">
<p><span class="math">\bar{y_m} = \frac{1}{N_m} \sum_{i \in N_m} y_i

H(X_m) = \frac{1}{N_m} \sum_{i \in N_m} |y_i - \bar{y_m}|</span></p>
</div><p>在 <span class="math">X_m</span> 训练 <span class="math">m</span> 节点上的数据时。</p>
<div class="topic">
<p class="topic-title first">示例:</p>
<ul class="simple">
<li><a class="reference external" href="https://en.wikipedia.org/wiki/Decision_tree_learning">https://en.wikipedia.org/wiki/Decision_tree_learning</a></li>
<li><a class="reference external" href="https://en.wikipedia.org/wiki/Predictive_analytics">https://en.wikipedia.org/wiki/Predictive_analytics</a></li>
<li>L. Breiman, J. Friedman, R. Olshen, and C. Stone. Classification and
Regression Trees. Wadsworth, Belmont, CA, 1984.</li>
<li>J.R. Quinlan. C4. 5: programs for machine learning. Morgan Kaufmann, 1993.</li>
<li>T. Hastie, R. Tibshirani and J. Friedman.
Elements of Statistical Learning, Springer, 2009.</li>
</ul>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>

      <!-- 评论留言区代码 start -->
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zNDAwMi8xMDU0MA==">
        <script type="text/javascript">
        (function(d, s) {
            var j, e = d.getElementsByTagName(s)[0];

            if (typeof LivereTower === 'function') { return; }

            j = d.createElement(s);
            j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
            j.async = true;

            e.parentNode.insertBefore(j, e);
        })(document, 'script');
        </script>
      </div>
      <!-- 评论留言区代码 end -->

    </div>

    <!-- 提 PR 时按原来文档的字母排序 -->

    

    

    

    

    

    

    

    

    

    

    

    

    
    <!-- modules/tree.html -->
    <div class="apachecn_doc_right">
      校验者: <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@文谊</a><br/>
                 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@皮卡乒的皮卡乓</a><br/>
      翻译者: <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@I Remember</a><br/>
    </div>
    

    

    

    

    

    

    

    
    
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

  </div>

  <div class="footer">
      &copy; 2007 - 2017, scikit-learn developers (BSD License).
    <a href="../_sources/modules/tree.rst.txt" rel="nofollow">Show this page source</a>
  </div>
   <div class="rel">
  
  <div class="buttonPrevious">
    <a href="naive_bayes.html">Previous
    </a>
  </div>
  <div class="buttonNext">
    <a href="ensemble.html">Next
    </a>
  </div>
  
   </div>

  <!-- google analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  
    ga('create', 'UA-102475051-5', 'auto');
    ga('send', 'pageview');
  
  </script>
  
  <!-- baidu tongji -->
  <script>
  var _hmt = _hmt || [];
  (function() {
    var hm = document.createElement("script");
    hm.src = "https://hm.baidu.com/hm.js?9cbab13b4d28a9811ae1d2d2176dab66";
    var s = document.getElementsByTagName("script")[0]; 
    s.parentNode.insertBefore(hm, s);
  })();
  </script>

  <!-- baidu push -->
  <script>
  (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
          bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      }
      else {
          bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
  })();
  </script>
  </body>
</html>