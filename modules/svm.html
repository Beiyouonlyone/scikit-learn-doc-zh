

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

    <title>1.4. 支持向量机 &#8212; scikit-learn 0.19.0 中文文档 - ApacheCN</title>
<!-- htmltitle is before nature.css - we use this hack to load bootstrap first -->
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="stylesheet" href="../_static/css/bootstrap.min.css" media="screen" />
<link rel="stylesheet" href="../_static/css/bootstrap-responsive.css"/>

    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/js/copybutton.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="1.5. 随机梯度下降" href="sgd.html" />
    <link rel="prev" title="1.3. 内核岭回归" href="kernel_ridge.html" />


<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<script src="../_static/js/bootstrap.min.js" type="text/javascript"></script>
<link rel="canonical" href="http://scikit-learn.org/stable/modules/svm.html" />

<script type="text/javascript">
  $("div.buttonNext, div.buttonPrevious").hover(
     function () {
         $(this).css('background-color', '#FF9C34');
     },
     function () {
         $(this).css('background-color', '#A7D6E2');
     }
  );
  function showMenu() {
    var topNav = document.getElementById("scikit-navbar");
    if (topNav.className === "navbar") {
        topNav.className += " responsive";
    } else {
        topNav.className = "navbar";
    }
  };
</script>

  </head><body>

<div class="header-wrapper">
  <div class="header">
      <p class="logo"><a href="../index.html">
          <img src="../_static/scikit-learn-logo-small.png" alt="Logo"/>
      </a>
      </p><div class="navbar" id="scikit-navbar">
          <ul>
              <li><a href="../index.html">首页</a></li>
              <li><a href="../install.html">安装</a></li>
              <li class="btn-li">
                <div class="btn-group">
                    <a href="../documentation.html">文档</a>
                    <a class="btn dropdown-toggle" data-toggle="dropdown">
                      <span class="caret"></span>
                    </a>
                    <ul class="dropdown-menu">
                      <li class="link-title">Scikit-learn 0.19</li>
                      <li><a href="../tutorial/index.html">教程</a></li>
                      <li><a href="../user_guide.html">用户指南</a></li>
                      <li><a href="classes.html">API</a></li>
                      <li><a href="../faq.html">FAQ</a></li>
                      <li><a href="../developers/contributing.html">贡献</a></li>
                      <li class="divider"></li>
                      <li><a href="http://scikit-learn.org/stable/documentation.html">Scikit-learn 0.19 (stable)</a></li>
                      <li><a href="http://scikit-learn.org/0.18/documentation.html">Scikit-learn 0.18</a></li>
                      <li><a href="http://scikit-learn.org/0.17/documentation.html">Scikit-learn 0.17</a></li>
                      <li><a href="../_downloads/scikit-learn-docs.pdf">PDF 文档</a></li>
                    </ul>
                </div>
              </li>
              <li><a href="../auto_examples/index.html">示例</a></li>
              <li><a href="../project-timeline.html">时光轴</a></li>
              <li class="btn-li">
                <div class="btn-group">
                    <a href="javascript:void(0)">项目相关</a>
                    <a class="btn dropdown-toggle" data-toggle="dropdown">
                      <span class="caret"></span>
                    </a>
                    <ul class="dropdown-menu">
                      <li><a href="../project-role.html">项目角色</a></li>
                      <li><a href="../project-check-progress.html">校验进度</a></li>
                      <li><a href="../project-translation-progress.html">翻译进度</a></li>
                      <li><a href="//github.com/apachecn/scikit-learn-doc-zh#%E8%B4%A1%E7%8C%AE%E8%80%85" target="_blank">贡献者</a></li>
                      <li class="divider"></li>
                      <li><a href="../project-timeline.html">时光轴</a></li>
                      <li class="divider"></li>
                      <li><a href="../project-reward.html">项目奖励</a></li>
                      <li class="divider"></li>
                      <li><a href="http://www.apachecn.org/organization/244.html" target="_blank">积分物品</a></li>
                      <li><a href="http://www.apachecn.org/organization/269.html" target="_blank">兑换记录</a></li>
                      <li class="divider"></li>
                      <li><a href="../project-feedback.html">建议反馈</a></li>
                      <li><a href="../project-communication-group.html">技术交流</a></li>
                    </ul>
                </div>
              </li>
              <li><a href="//github.com/apachecn/scikit-learn-doc-zh#%E8%B4%A1%E7%8C%AE%E8%80%85" target="_blank">贡献者</a></li>
              <li><a href="//github.com/apachecn/scikit-learn-doc-zh" target="_blank">GitHub</a></li>
          </ul>
          <a href="javascript:void(0);" onclick="showMenu()">
              <div class="nav-icon">
                  <div class="hamburger-line"></div>
                  <div class="hamburger-line"></div>
                  <div class="hamburger-line"></div>
              </div>
          </a>
          <div class="search_form">
              <div class="gcse-search" id="cse" style="width: 100%;"></div>
          </div>
      </div> <!-- end navbar --></div>
</div>


<!-- Github "fork me" ribbon -->
<a href="https://github.com/apachecn/scikit-learn-doc-zh">
<img class="fork-me"
     style="position: absolute; top: 0; right: 0; border: 0;"
     src="../_static/img/starme.png"
     alt="Star me on GitHub" />
</a>

<div class="content-wrapper">
  <div class="sphinxsidebar">
  <div class="sphinxsidebarwrapper">
      <div class="rel">
  
      <div class="rellink">
      <a href="kernel_ridge.html"
      accesskey="P">Previous
      <br/>
      <span class="smallrellink">
      1.3. 内核岭回归
      </span>
          <span class="hiddenrellink">
          1.3. 内核岭回归
          </span>
      </a>
      </div>
          <div class="spacer">
          &nbsp;
          </div>
      <div class="rellink">
      <a href="sgd.html"
      accesskey="N">Next
      <br/>
      <span class="smallrellink">
      1.5. 随机梯度下降
      </span>
          <span class="hiddenrellink">
          1.5. 随机梯度下降
          </span>
      </a>
      </div>

  <!-- Ad a link to the 'up' page -->
      <div class="spacer">
      &nbsp;
      </div>
      <div class="rellink">
      <a href="../supervised_learning.html">
      Up
      <br/>
      <span class="smallrellink">
      1. 监督学习
      </span>
          <span class="hiddenrellink">
          1. 监督学习
          </span>
          
      </a>
      </div>
  </div>
  
    <p class="doc-version"><b>scikit-learn v0.19.0</b><br/>
    <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
  <p class="citing">Please <b><a href="../about.html#citing-scikit-learn" style="font-size: 110%;">cite us </a></b>if you use the software.</p>
  <ul>
<li><a class="reference internal" href="#">1.4. 支持向量机</a><ul>
<li><a class="reference internal" href="#svm-classification">1.4.1. 分类</a><ul>
<li><a class="reference internal" href="#svm-multi-class">1.4.1.1. 多元分类</a></li>
<li><a class="reference internal" href="#scores-probabilities">1.4.1.2. 得分和概率</a></li>
<li><a class="reference internal" href="#id5">1.4.1.3. 非均衡问题</a></li>
</ul>
</li>
<li><a class="reference internal" href="#svm-regression">1.4.2. 回归</a></li>
<li><a class="reference internal" href="#novelty">1.4.3. 密度估计, 异常（novelty）检测</a></li>
<li><a class="reference internal" href="#id7">1.4.4. 复杂度</a></li>
<li><a class="reference internal" href="#id8">1.4.5. 使用诀窍</a></li>
<li><a class="reference internal" href="#svm-kernels">1.4.6. 核函数</a><ul>
<li><a class="reference internal" href="#id10">1.4.6.1. 自定义核</a><ul>
<li><a class="reference internal" href="#python">1.4.6.1.1. 使用 python 函数作为内核</a></li>
<li><a class="reference internal" href="#gram">1.4.6.1.2. 使用 Gram 矩阵</a></li>
<li><a class="reference internal" href="#rbf">1.4.6.1.3. RBF 内核参数</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#svm-mathematical-formulation">1.4.7. 数学公式</a><ul>
<li><a class="reference internal" href="#svc">1.4.7.1. SVC</a></li>
<li><a class="reference internal" href="#nusvc">1.4.7.2. NuSVC</a></li>
<li><a class="reference internal" href="#svr">1.4.7.3. SVR</a></li>
</ul>
</li>
<li><a class="reference internal" href="#svm-implementation-details">1.4.8. 实现细节</a></li>
</ul>
</li>
</ul>

  </div>
</div>

<input type="checkbox" id="nav-trigger" class="nav-trigger" checked />
<label for="nav-trigger"></label>




    <div class="content">
          
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="svm">
<span id="id1"></span><h1>1.4. 支持向量机<a class="headerlink" href="#svm" title="Permalink to this headline">¶</a></h1>
<p><strong>支持向量机 (SVMs)</strong> 可用于以下监督学习算法 <a class="reference internal" href="#svm-classification"><span class="std std-ref">分类</span></a>, <a class="reference internal" href="#svm-regression"><span class="std std-ref">回归</span></a> 和  <a class="reference internal" href="#svm-outlier-detection"><span class="std std-ref">异常检测</span></a>.</p>
<p>支持向量机的优势在于:</p>
<blockquote>
<div><ul class="simple">
<li>在高维空间中非常高效.</li>
<li>即使在数据维度比样本数量大的情况下仍然有效.</li>
<li>在决策函数（称为支持向量）中使用训练集的子集,因此它也是高效利用内存的.</li>
<li>通用性: 不同的核函数 <a class="reference internal" href="#svm-kernels"><span class="std std-ref">核函数</span></a> 与特定的决策函数一一对应.常见的 kernel 已</li>
</ul>
<p>经提供,也可以指定定制的内核.</p>
</div></blockquote>
<p>支持向量机的缺点包括:</p>
<blockquote>
<div><ul class="simple">
<li>如果特征数量比样本数量大得多,在选择核函数 <a class="reference internal" href="#svm-kernels"><span class="std std-ref">核函数</span></a> 时要避免过拟合,</li>
</ul>
<p>而且正则化项是非常重要的.</p>
<ul class="simple">
<li>支持向量机不直接提供概率估计,这些都是使用昂贵的五次交叉验算计算的.
(详情见 <a class="reference internal" href="#scores-probabilities"><span class="std std-ref">Scores and probabilities</span></a>, 在下文中).</li>
</ul>
</div></blockquote>
<p>在 scikit-learn 中,支持向量机提供 dense(<code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> ,可以通过 <code class="docutils literal notranslate"><span class="pre">numpy.asarray</span></code> 进行转换) 和 sparse (任何 <code class="docutils literal notranslate"><span class="pre">scipy.sparse</span></code>) 样例向量作为输入.然而,要使用支持向量机来对 sparse 数据作预测,它必须已经拟合这样的数据.使用 C 代码的 <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> (dense) 或者带有 <code class="docutils literal notranslate"><span class="pre">dtype=float64</span></code> 的 <code class="docutils literal notranslate"><span class="pre">scipy.sparse.csr_matrix</span></code> (sparse) 来优化性能.</p>
<div class="section" id="svm-classification">
<span id="id2"></span><h2>1.4.1. 分类<a class="headerlink" href="#svm-classification" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="sklearn.svm.SVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a>, <a class="reference internal" href="generated/sklearn.svm.NuSVC.html#sklearn.svm.NuSVC" title="sklearn.svm.NuSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">NuSVC</span></code></a> 和 <a class="reference internal" href="generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" title="sklearn.svm.LinearSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearSVC</span></code></a> 能在数据集中实现多元分类.</p>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/svm/plot_iris.html"><img alt="modules/../auto_examples/svm/images/sphx_glr_plot_iris_001.png" src="modules/../auto_examples/svm/images/sphx_glr_plot_iris_001.png" /></a>
</div>
<p><a class="reference internal" href="generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="sklearn.svm.SVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a> 和 <a class="reference internal" href="generated/sklearn.svm.NuSVC.html#sklearn.svm.NuSVC" title="sklearn.svm.NuSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">NuSVC</span></code></a> 是相似的方法, 但是接受稍许不同的参数设置并且有不同的数学方程(在这部分看 <a class="reference internal" href="#svm-mathematical-formulation"><span class="std std-ref">数学公式</span></a>). 另一方面, <a class="reference internal" href="generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" title="sklearn.svm.LinearSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearSVC</span></code></a> 是另一个实现线性核函数的支持向量分类. 记住 <a class="reference internal" href="generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" title="sklearn.svm.LinearSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearSVC</span></code></a> 不接受关键词 <code class="docutils literal notranslate"><span class="pre">kernel</span></code>, 因为它被假设为线性的. 它也缺少一些 <a class="reference internal" href="generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="sklearn.svm.SVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a> 和 <a class="reference internal" href="generated/sklearn.svm.NuSVC.html#sklearn.svm.NuSVC" title="sklearn.svm.NuSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">NuSVC</span></code></a> 的成员(members) 比如 <code class="docutils literal notranslate"><span class="pre">support_</span></code> .</p>
<p>和其他分类器一样, <a class="reference internal" href="generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="sklearn.svm.SVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a>, <a class="reference internal" href="generated/sklearn.svm.NuSVC.html#sklearn.svm.NuSVC" title="sklearn.svm.NuSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">NuSVC</span></code></a> 和 <a class="reference internal" href="generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" title="sklearn.svm.LinearSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearSVC</span></code></a> 将两个数组作为输入:  <code class="docutils literal notranslate"><span class="pre">[n_samples,</span> <span class="pre">n_features]</span></code> 大小的数组 X 作为训练样本, <code class="docutils literal notranslate"><span class="pre">[n_samples]</span></code> 大小的数组 y 作为类别标签(字符串或者整数):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">svm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  
<span class="go">SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,</span>
<span class="go">    decision_function_shape=&#39;ovr&#39;, degree=3, gamma=&#39;auto&#39;, kernel=&#39;rbf&#39;,</span>
<span class="go">    max_iter=-1, probability=False, random_state=None, shrinking=True,</span>
<span class="go">    tol=0.001, verbose=False)</span>
</pre></div>
</div>
<p>在拟合后, 这个模型可以用来预测新的值:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]])</span>
<span class="go">array([1])</span>
</pre></div>
</div>
<p>SVMs 决策函数取决于训练集的一些子集, 称作支持向量. 这些支持向量的部分特性可以在 <code class="docutils literal notranslate"><span class="pre">support_vectors_</span></code>, <code class="docutils literal notranslate"><span class="pre">support_</span></code> 和 <code class="docutils literal notranslate"><span class="pre">n_support</span></code> 找到:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># 获得支持向量</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">support_vectors_</span>
<span class="go">array([[ 0.,  0.],</span>
<span class="go">       [ 1.,  1.]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 获得支持向量的索引get indices of support vectors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">support_</span> 
<span class="go">array([0, 1]...)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 为每一个类别获得支持向量的数量</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">n_support_</span> 
<span class="go">array([1, 1]...)</span>
</pre></div>
</div>
<div class="section" id="svm-multi-class">
<span id="id3"></span><h3>1.4.1.1. 多元分类<a class="headerlink" href="#svm-multi-class" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="sklearn.svm.SVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a> 和 <a class="reference internal" href="generated/sklearn.svm.NuSVC.html#sklearn.svm.NuSVC" title="sklearn.svm.NuSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">NuSVC</span></code></a> 为多元分类实现了 “one-against-one” 的方法 (Knerr et al., 1990) 如果 <code class="docutils literal notranslate"><span class="pre">n_class</span></code> 是类别的数量, 那么 <code class="docutils literal notranslate"><span class="pre">n_class</span> <span class="pre">*</span> <span class="pre">(n_class</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">/</span> <span class="pre">2</span></code> 分类器被重构, 而且每一个从两个类别中训练数据. 为了给其他分类器提供一致的交互, <code class="docutils literal notranslate"><span class="pre">decision_function_shape</span></code> 选项允许聚合 “one-against-one” 分类器的结果成 <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_classes)</span></code> 的大小到决策函数:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">decision_function_shape</span><span class="o">=</span><span class="s1">&#39;ovo&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span> 
<span class="go">SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,</span>
<span class="go">    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=&#39;auto&#39;, kernel=&#39;rbf&#39;,</span>
<span class="go">    max_iter=-1, probability=False, random_state=None, shrinking=True,</span>
<span class="go">    tol=0.001, verbose=False)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dec</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">decision_function</span><span class="p">([[</span><span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># 4 classes: 4*3/2 = 6</span>
<span class="go">6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">decision_function_shape</span> <span class="o">=</span> <span class="s2">&quot;ovr&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dec</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">decision_function</span><span class="p">([[</span><span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># 4 classes</span>
<span class="go">4</span>
</pre></div>
</div>
<p>另一方面, <a class="reference internal" href="generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" title="sklearn.svm.LinearSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearSVC</span></code></a> 实现 “one-vs-the-rest” 多类别策略, 从而训练 n 类别的模型. 如果只有两类, 只训练一个模型.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lin_clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">LinearSVC</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lin_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span> 
<span class="go">LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,</span>
<span class="go">     intercept_scaling=1, loss=&#39;squared_hinge&#39;, max_iter=1000,</span>
<span class="go">     multi_class=&#39;ovr&#39;, penalty=&#39;l2&#39;, random_state=None, tol=0.0001,</span>
<span class="go">     verbose=0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dec</span> <span class="o">=</span> <span class="n">lin_clf</span><span class="o">.</span><span class="n">decision_function</span><span class="p">([[</span><span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="go">4</span>
</pre></div>
</div>
<p>参见 <a class="reference internal" href="#svm-mathematical-formulation"><span class="std std-ref">数学公式</span></a> 查看决策函数的完整描述.</p>
<p>记住 <a class="reference internal" href="generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" title="sklearn.svm.LinearSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearSVC</span></code></a> 也实现了可选择的多类别策略, 通过使用选项 <code class="docutils literal notranslate"><span class="pre">multi_class='crammer_singer'</span></code>, 所谓的多元 SVM 由 Crammer 和 Singer 明确表达. 这个方法是一致的, 对于 one-vs-rest 是不正确的. 实际上, one-vs-rest 分类通常受到青睐, 因为结果大多数是相似的, 但是运行时间却显著减少.</p>
<p>对于 “one-vs-rest” <a class="reference internal" href="generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" title="sklearn.svm.LinearSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearSVC</span></code></a>, 属性 <code class="docutils literal notranslate"><span class="pre">coef_</span></code> 和 <code class="docutils literal notranslate"><span class="pre">intercept_</span></code> 分别具有 <code class="docutils literal notranslate"><span class="pre">[n_class,</span> <span class="pre">n_features]</span></code> 和 <code class="docutils literal notranslate"><span class="pre">[n_class]</span></code> 尺寸. 系数的每一行符合 <code class="docutils literal notranslate"><span class="pre">n_class</span></code> 的许多 one-vs-rest 分类器之一, 并且就以这一类的顺序与拦截器(intercepts)相似.</p>
<p>至于 one-vs-one <a class="reference internal" href="generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="sklearn.svm.SVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a>, 属性特征的布局(layout)有少多些复杂. 考虑到有一种线性核函数, <code class="docutils literal notranslate"><span class="pre">coef_</span></code> 和 <code class="docutils literal notranslate"><span class="pre">intercept_</span></code> 的布局(layout)与上文描述成 <a class="reference internal" href="generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" title="sklearn.svm.LinearSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearSVC</span></code></a> 相似, 除了 <code class="docutils literal notranslate"><span class="pre">coef_</span></code> 的形状 <code class="docutils literal notranslate"><span class="pre">[n_class</span> <span class="pre">*</span> <span class="pre">(n_class</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">/</span> <span class="pre">2,</span> <span class="pre">n_features]</span></code>, 与许多二元的分类器相似. 0到n的类别顺序是 “0 vs 1”, “0 vs 2” , … “0 vs n”, “1 vs 2”, “1 vs 3”, “1 vs n”, … “n-1 vs n”.</p>
<p><code class="docutils literal notranslate"><span class="pre">dual_coef_</span></code> 的 shape 是 <code class="docutils literal notranslate"><span class="pre">[n_class-1,</span> <span class="pre">n_SV]</span></code>, 这个结构有些难以理解.
对应于支持向量的列与 <code class="docutils literal notranslate"><span class="pre">n_class</span> <span class="pre">*</span> <span class="pre">(n_class</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">/</span> <span class="pre">2</span></code> “one-vs-one” 分类器相关.
每一个支持向量用于 <code class="docutils literal notranslate"><span class="pre">n_class</span> <span class="pre">-</span> <span class="pre">1</span></code> 分类器中.对于这些分类器,每一行的 <code class="docutils literal notranslate"><span class="pre">n_class</span> <span class="pre">-</span> <span class="pre">1</span></code>
条目对应于对偶系数(dual coefficients).</p>
<p>通过这个例子更容易说明:</p>
<p>考虑一个三类的问题,类0有三个支持向量 <span class="math">v^{0}_0, v^{1}_0, v^{2}_0</span> 而类 1 和 2 分别有
如下两个支持向量 <span class="math">v^{0}_1, v^{1}_1</span> and <span class="math">v^{0}_2, v^{1}_2</span>.对于每个支持
向量 <span class="math">v^{j}_i</span>, 有两个对偶系数.在类别 <span class="math">i</span> 和 <span class="math">k</span> <span class="math">\alpha^{j}_{i,k}</span> 中,
我们将支持向量的系数记录为 <span class="math">v^{j}_i</span>
那么 <code class="docutils literal notranslate"><span class="pre">dual_coef_</span></code> 可以表示为:</p>
<table border="1" class="docutils">
<colgroup>
<col width="36%" />
<col width="36%" />
<col width="27%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><span class="math">\alpha^{0}_{0,1}</span></td>
<td><span class="math">\alpha^{0}_{0,2}</span></td>
<td rowspan="3">Coefficients
for SVs of class 0</td>
</tr>
<tr class="row-even"><td><span class="math">\alpha^{1}_{0,1}</span></td>
<td><span class="math">\alpha^{1}_{0,2}</span></td>
</tr>
<tr class="row-odd"><td><span class="math">\alpha^{2}_{0,1}</span></td>
<td><span class="math">\alpha^{2}_{0,2}</span></td>
</tr>
<tr class="row-even"><td><span class="math">\alpha^{0}_{1,0}</span></td>
<td><span class="math">\alpha^{0}_{1,2}</span></td>
<td rowspan="2">Coefficients
for SVs of class 1</td>
</tr>
<tr class="row-odd"><td><span class="math">\alpha^{1}_{1,0}</span></td>
<td><span class="math">\alpha^{1}_{1,2}</span></td>
</tr>
<tr class="row-even"><td><span class="math">\alpha^{0}_{2,0}</span></td>
<td><span class="math">\alpha^{0}_{2,1}</span></td>
<td rowspan="2">Coefficients
for SVs of class 2</td>
</tr>
<tr class="row-odd"><td><span class="math">\alpha^{1}_{2,0}</span></td>
<td><span class="math">\alpha^{1}_{2,1}</span></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="scores-probabilities">
<span id="id4"></span><h3>1.4.1.2. 得分和概率<a class="headerlink" href="#scores-probabilities" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="sklearn.svm.SVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a> 方法的 <code class="docutils literal notranslate"><span class="pre">decision_function</span></code> 给每一个样例每一个类别分值(scores)(或者在一个二元类中每一个样例一个分值).
当构造器(constructor)选项 <code class="docutils literal notranslate"><span class="pre">probability</span></code> 设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code> 的时候, 类成员可能性评估开启.(来自 <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> 和 <code class="docutils literal notranslate"><span class="pre">predict_log_proba</span></code> 方法)
在二元分类中,概率使用 Platt scaling 进行标准化: 在 SVM 分数上的逻辑回归,在训练集上用额外的交叉验证来拟合.在多类情况下,这可以扩展为 per Wu et al.(2004)</p>
<p>不用说,对于大数据集来说,在 Platt scaling 中进行交叉验证是一项昂贵的操作.
另外,可能性预测可能与 scores 不一致,因为 scores 的 “argmax” 可能不是可能性的 argmax.
(例如,在二元分类中,一个样本可能被标记为一个有可能性的类 <code class="docutils literal notranslate"><span class="pre">predict</span></code> &lt;½ according to <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>.) Platt 的方法也有理论问题.
如果 confidence scores 必要,但是这些没必要是可能性, 那么建议设置 <code class="docutils literal notranslate"><span class="pre">probability=False</span></code> 并使用 <code class="docutils literal notranslate"><span class="pre">decision_function</span></code> 而不是 <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>.</p>
<div class="topic">
<p class="topic-title first">参考:</p>
<ul class="simple">
<li>Wu, Lin and Weng,
<a href="#id13"><span class="problematic" id="id14">`&quot;Probability estimates for multi-class classification by pairwise coupling（成对耦合的多类分类的概率估计）&quot;&lt;http://www.csie.ntu.edu.tw/~cjlin/papers/svmprob/svmprob.pdf&gt;`_</span></a>, JMLR 5:975-1005, 2004.</li>
<li>Platt
<a href="#id15"><span class="problematic" id="id16">`&quot;Probabilistic outputs for SVMs and comparisons to regularized likelihood methods（SVMs 的概率输出和与规则化似然方法的比较）&quot;&lt;http://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf&gt;`_</span></a> .</li>
</ul>
</div>
</div>
<div class="section" id="id5">
<h3>1.4.1.3. 非均衡问题<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>这个问题期望给予某一类或某个别样例能使用的关键词 <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> 和 <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> 提高权重(importance).</p>
<p><a class="reference internal" href="generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="sklearn.svm.SVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a> (而不是 <a class="reference internal" href="generated/sklearn.svm.NuSVC.html#sklearn.svm.NuSVC" title="sklearn.svm.NuSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">NuSVC</span></code></a>) 在 <code class="docutils literal notranslate"><span class="pre">fit</span></code> 方法中生成了一个关键词 <code class="docutils literal notranslate"><span class="pre">class_weight</span></code>. 它是形如 <code class="docutils literal notranslate"><span class="pre">{class_label</span> <span class="pre">:</span> <span class="pre">value}</span></code> 的字典, value 是浮点数大于 0 的值, 把类 <code class="docutils literal notranslate"><span class="pre">class_label</span></code> 的参数 <code class="docutils literal notranslate"><span class="pre">C</span></code> 设置为 <code class="docutils literal notranslate"><span class="pre">C</span> <span class="pre">*</span> <span class="pre">value</span></code>.</p>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/svm/plot_separating_hyperplane_unbalanced.html"><img alt="modules/../auto_examples/svm/images/sphx_glr_plot_separating_hyperplane_unbalanced_001.png" src="modules/../auto_examples/svm/images/sphx_glr_plot_separating_hyperplane_unbalanced_001.png" /></a>
</div>
<p><a class="reference internal" href="generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="sklearn.svm.SVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a>, <a class="reference internal" href="generated/sklearn.svm.NuSVC.html#sklearn.svm.NuSVC" title="sklearn.svm.NuSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">NuSVC</span></code></a>, <a class="reference internal" href="generated/sklearn.svm.SVR.html#sklearn.svm.SVR" title="sklearn.svm.SVR"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVR</span></code></a>, <a class="reference internal" href="generated/sklearn.svm.NuSVR.html#sklearn.svm.NuSVR" title="sklearn.svm.NuSVR"><code class="xref py py-class docutils literal notranslate"><span class="pre">NuSVR</span></code></a> 和 <a class="reference internal" href="generated/sklearn.svm.OneClassSVM.html#sklearn.svm.OneClassSVM" title="sklearn.svm.OneClassSVM"><code class="xref py py-class docutils literal notranslate"><span class="pre">OneClassSVM</span></code></a> 在 <code class="docutils literal notranslate"><span class="pre">fit</span></code> 方法中通过关键词 <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code>  为单一样例实现权重weights.与 <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> 相似, 这些把第i个样例的参数 <code class="docutils literal notranslate"><span class="pre">C</span></code> 换成 <code class="docutils literal notranslate"><span class="pre">C</span> <span class="pre">*</span> <span class="pre">sample_weight[i]</span></code>.</p>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/svm/plot_weighted_samples.html"><img alt="modules/../auto_examples/svm/images/sphx_glr_plot_weighted_samples_001.png" src="modules/../auto_examples/svm/images/sphx_glr_plot_weighted_samples_001.png" /></a>
</div>
<div class="topic">
<p class="topic-title first">例子:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/svm/plot_iris.html#sphx-glr-auto-examples-svm-plot-iris-py"><span class="std std-ref">在鸢尾花卉数据集上绘制不同的 SVM 分类器</span></a>,</li>
<li><a class="reference internal" href="../auto_examples/svm/plot_separating_hyperplane.html#sphx-glr-auto-examples-svm-plot-separating-hyperplane-py"><span class="std std-ref">SVM: Maximum margin separating hyperplane</span></a>,</li>
<li><a class="reference internal" href="../auto_examples/svm/plot_separating_hyperplane_unbalanced.html#sphx-glr-auto-examples-svm-plot-separating-hyperplane-unbalanced-py"><span class="std std-ref">SVM: 分离不平衡类的超平面</span></a></li>
<li><a class="reference internal" href="../auto_examples/svm/plot_svm_anova.html#sphx-glr-auto-examples-svm-plot-svm-anova-py"><span class="std std-ref">SVM-Anova: SVM with univariate feature selection</span></a>,</li>
<li><a class="reference internal" href="../auto_examples/svm/plot_svm_nonlinear.html#sphx-glr-auto-examples-svm-plot-svm-nonlinear-py"><span class="std std-ref">Non-linear SVM</span></a></li>
<li><a class="reference internal" href="../auto_examples/svm/plot_weighted_samples.html#sphx-glr-auto-examples-svm-plot-weighted-samples-py"><span class="std std-ref">SVM: Weighted samples</span></a>,</li>
</ul>
</div>
</div>
</div>
<div class="section" id="svm-regression">
<span id="id6"></span><h2>1.4.2. 回归<a class="headerlink" href="#svm-regression" title="Permalink to this headline">¶</a></h2>
<p>支持向量分类的方法可以被扩展用作解决回归问题. 这个方法被称作支持向量回归.</p>
<p>支持向量分类生成的模型(如前描述)只依赖于训练集的子集,因为构建模型的 cost function 不在乎边缘之外的训练点. 类似的,支持向量回归生成的模型只依赖于训练集的子集, 因为构建模型的 cost function 忽略任何接近于模型预测的训练数据.</p>
<p>支持向量分类有三种不同的实现形式:
<a class="reference internal" href="generated/sklearn.svm.SVR.html#sklearn.svm.SVR" title="sklearn.svm.SVR"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVR</span></code></a>, <a class="reference internal" href="generated/sklearn.svm.NuSVR.html#sklearn.svm.NuSVR" title="sklearn.svm.NuSVR"><code class="xref py py-class docutils literal notranslate"><span class="pre">NuSVR</span></code></a> 和 <a class="reference internal" href="generated/sklearn.svm.LinearSVR.html#sklearn.svm.LinearSVR" title="sklearn.svm.LinearSVR"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearSVR</span></code></a>. 在只考虑线性核的情况下, <a class="reference internal" href="generated/sklearn.svm.LinearSVR.html#sklearn.svm.LinearSVR" title="sklearn.svm.LinearSVR"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearSVR</span></code></a>  比 <a class="reference internal" href="generated/sklearn.svm.SVR.html#sklearn.svm.SVR" title="sklearn.svm.SVR"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVR</span></code></a> 提供一个更快的实现形式, 然而比起 <a class="reference internal" href="generated/sklearn.svm.SVR.html#sklearn.svm.SVR" title="sklearn.svm.SVR"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVR</span></code></a> 和 <a class="reference internal" href="generated/sklearn.svm.LinearSVR.html#sklearn.svm.LinearSVR" title="sklearn.svm.LinearSVR"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearSVR</span></code></a>, <a class="reference internal" href="generated/sklearn.svm.NuSVR.html#sklearn.svm.NuSVR" title="sklearn.svm.NuSVR"><code class="xref py py-class docutils literal notranslate"><span class="pre">NuSVR</span></code></a> 实现一个稍微不同的构思(formulation).细节参见 <a class="reference internal" href="#svm-implementation-details"><span class="std std-ref">实现细节</span></a>.</p>
<p>与分类的类别一样, fit方法会调用参数向量 X, y, 只在 y 是浮点数而不是整数型.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">svm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVR</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> 
<span class="go">SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=&#39;auto&#39;,</span>
<span class="go">    kernel=&#39;rbf&#39;, max_iter=-1, shrinking=True, tol=0.001, verbose=False)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="go">array([ 1.5])</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">样例:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/svm/plot_svm_regression.html#sphx-glr-auto-examples-svm-plot-svm-regression-py"><span class="std std-ref">支持向量回归（SVR），使用 linear and non-linear 内核</span></a></li>
</ul>
</div>
</div>
<div class="section" id="novelty">
<span id="svm-outlier-detection"></span><h2>1.4.3. 密度估计, 异常（novelty）检测<a class="headerlink" href="#novelty" title="Permalink to this headline">¶</a></h2>
<p>但类别的 SVM 用于异常检测, 即给予一个样例集, 它会检测这个样例集的 soft boundary 以便给新的数据点分类,
看它是否属于这个样例集. 生成的类称作 <a class="reference internal" href="generated/sklearn.svm.OneClassSVM.html#sklearn.svm.OneClassSVM" title="sklearn.svm.OneClassSVM"><code class="xref py py-class docutils literal notranslate"><span class="pre">OneClassSVM</span></code></a>.</p>
<p>这种情况下, 因为它属于非监督学习的一类, 没有类标签, fit 方法只会考虑输入数组X.</p>
<p>在章节 <a class="reference internal" href="outlier_detection.html#outlier-detection"><span class="std std-ref">新奇和异常值检测</span></a> 查看这个应用的更多细节.</p>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/svm/plot_oneclass.html"><img alt="modules/../auto_examples/svm/images/sphx_glr_plot_oneclass_001.png" src="modules/../auto_examples/svm/images/sphx_glr_plot_oneclass_001.png" /></a>
</div>
<div class="topic">
<p class="topic-title first">示例:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/svm/plot_oneclass.html#sphx-glr-auto-examples-svm-plot-oneclass-py"><span class="std std-ref">One-class SVM with non-linear kernel (RBF)</span></a></li>
<li><a class="reference internal" href="../auto_examples/applications/plot_species_distribution_modeling.html#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py"><span class="std std-ref">Species distribution modeling</span></a></li>
</ul>
</div>
</div>
<div class="section" id="id7">
<h2>1.4.4. 复杂度<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<p>支持向量机是个强大的工具，不过它的计算和存储空间要求也会随着要训练向量的数目增加而快速增加。
SVM的核心是一个二次规划问题(Quadratic Programming, QP)，是将支持向量和训练数据的其余部分分离开来。
在实践中(数据集相关)，会根据 <a class="reference external" href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/">libsvm</a> 的缓存有多效，在 <span class="math">O(n_{features} \times n_{samples}^2)</span> 和
<span class="math">O(n_{features} \times n_{samples}^3)</span> 之间基于 <a class="reference external" href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/">libsvm</a> 的缩放操作才会调用这个 QP 解析器。
如果数据是非常稀疏，那 <span class="math">n_{features}</span>  就用样本向量中非零特征的平均数量去替换。</p>
<p>另外请注意，在线性情况下，由 <a class="reference external" href="http://www.csie.ntu.edu.tw/~cjlin/liblinear/">liblinear</a> 操作的 <a class="reference internal" href="generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" title="sklearn.svm.LinearSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearSVC</span></code></a> 算法要比由它的 <a class="reference external" href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/">libsvm</a> 对应的
<a class="reference internal" href="generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="sklearn.svm.SVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a> 更为高效，并且它几乎可以线性缩放到数百万样本或者特征。</p>
</div>
<div class="section" id="id8">
<h2>1.4.5. 使用诀窍<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><ul>
<li><p class="first"><strong>避免数据复制</strong>: 对于 <a class="reference internal" href="generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="sklearn.svm.SVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a>， <a class="reference internal" href="generated/sklearn.svm.SVR.html#sklearn.svm.SVR" title="sklearn.svm.SVR"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVR</span></code></a>， <a class="reference internal" href="generated/sklearn.svm.NuSVC.html#sklearn.svm.NuSVC" title="sklearn.svm.NuSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">NuSVC</span></code></a> 和
<a class="reference internal" href="generated/sklearn.svm.NuSVR.html#sklearn.svm.NuSVR" title="sklearn.svm.NuSVR"><code class="xref py py-class docutils literal notranslate"><span class="pre">NuSVR</span></code></a>， 如果数据是通过某些方法而不是用 C 有序的连续双精度，那它先会调用底层的 C 命令再复制。
您可以通过检查它的 <code class="docutils literal notranslate"><span class="pre">flags</span></code> 属性，来确定给定的 numpy 数组是不是 C 连续的。</p>
<p>对于 <a class="reference internal" href="generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" title="sklearn.svm.LinearSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearSVC</span></code></a> (和 <a class="reference internal" href="generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticRegression</span></code></a>) 的任何输入，都会以 numpy 数组形式，被复制和转换为
用 liblinear 内部稀疏数据去表达（双精度浮点型 float 和非零部分的 int32 索引）。
如果您想要一个适合大规模的线性分类器，又不打算复制一个密集的 C-contiguous 双精度 numpy 数组作为输入，
那我们建议您去使用 <a class="reference internal" href="generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier" title="sklearn.linear_model.SGDClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">SGDClassifier</span></code></a> 类作为替代。目标函数可以配置为和 <a class="reference internal" href="generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" title="sklearn.svm.LinearSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearSVC</span></code></a>
模型差不多相同的。</p>
</li>
<li><p class="first"><strong>内核的缓存大小</strong>: 在大规模问题上，对于 <a class="reference internal" href="generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="sklearn.svm.SVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a>, <a class="reference internal" href="generated/sklearn.svm.SVR.html#sklearn.svm.SVR" title="sklearn.svm.SVR"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVR</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">nuSVC</span></code> 和
<a class="reference internal" href="generated/sklearn.svm.NuSVR.html#sklearn.svm.NuSVR" title="sklearn.svm.NuSVR"><code class="xref py py-class docutils literal notranslate"><span class="pre">NuSVR</span></code></a>, 内核缓存的大小会特别影响到运行时间。如果您有足够可用的 RAM，不妨把它的 <code class="docutils literal notranslate"><span class="pre">缓存大小</span></code>
设得比默认的 200(MB) 要高，例如为 500(MB) 或者 1000(MB)。</p>
</li>
<li><p class="first"><strong>惩罚系数C的设置</strong>:在合理的情况下， <code class="docutils literal notranslate"><span class="pre">C</span></code> 的默认选择为 <code class="docutils literal notranslate"><span class="pre">1</span></code> 。如果您有很多混杂的观察数据，
您应该要去调小它。 <code class="docutils literal notranslate"><span class="pre">C</span></code> 越小，就能更好地去正规化估计。</p>
</li>
<li><p class="first">支持向量机算法本身不是用来扩大不变性，所以 <strong>我们强烈建议您去扩大数据量</strong>. 举个例子，对于输入向量 X，
规整它的每个数值范围为 [0, 1] 或 [-1, +1] ，或者标准化它的为均值为0方差为1的数据分布。请注意，
相同的缩放标准必须要应用到所有的测试向量，从而获得有意义的结果。 请参考章节
<a class="reference internal" href="preprocessing.html#preprocessing"><span class="std std-ref">预处理数据</span></a> ，那里会提供到更多关于缩放和规整。</p>
</li>
<li><p class="first">在 <a class="reference internal" href="generated/sklearn.svm.NuSVC.html#sklearn.svm.NuSVC" title="sklearn.svm.NuSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">NuSVC</span></code></a>/<a class="reference internal" href="generated/sklearn.svm.OneClassSVM.html#sklearn.svm.OneClassSVM" title="sklearn.svm.OneClassSVM"><code class="xref py py-class docutils literal notranslate"><span class="pre">OneClassSVM</span></code></a>/<a class="reference internal" href="generated/sklearn.svm.NuSVR.html#sklearn.svm.NuSVR" title="sklearn.svm.NuSVR"><code class="xref py py-class docutils literal notranslate"><span class="pre">NuSVR</span></code></a> 内的参数 <code class="docutils literal notranslate"><span class="pre">nu</span></code> ，
近似是训练误差和支持向量的比值。</p>
</li>
<li><p class="first">在 <a class="reference internal" href="generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="sklearn.svm.SVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a>, ，如果分类器的数据不均衡（就是说，很多正例很少负例），设置 <code class="docutils literal notranslate"><span class="pre">class_weight='balanced'</span></code>
与/或尝试不同的惩罚系数 <code class="docutils literal notranslate"><span class="pre">C</span></code> 。</p>
</li>
<li><p class="first">在拟合模型时，底层 <a class="reference internal" href="generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" title="sklearn.svm.LinearSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearSVC</span></code></a> 操作使用了随机数生成器去选择特征。
所以不要感到意外，对于相同的数据输入，也会略有不同的输出结果。如果这个发生了，
尝试用更小的 tol 参数。</p>
</li>
<li><p class="first">使用由 <code class="docutils literal notranslate"><span class="pre">LinearSVC(loss='l2',</span> <span class="pre">penalty='l1',</span>
<span class="pre">dual=False)</span></code> 提供的 L1 惩罚去产生稀疏解，也就是说，特征权重的子集不同于零，这样做有助于决策函数。
随着增加 <code class="docutils literal notranslate"><span class="pre">C</span></code> 会产生一个更复杂的模型（要做更多的特征选择）。可以使用 <a class="reference internal" href="generated/sklearn.svm.l1_min_c.html#sklearn.svm.l1_min_c" title="sklearn.svm.l1_min_c"><code class="xref py py-func docutils literal notranslate"><span class="pre">l1_min_c</span></code></a> 去计算 <code class="docutils literal notranslate"><span class="pre">C</span></code> 的数值，去产生一个”null” 模型（所有的权重等于零）。</p>
</li>
</ul>
</div></blockquote>
</div>
<div class="section" id="svm-kernels">
<span id="id9"></span><h2>1.4.6. 核函数<a class="headerlink" href="#svm-kernels" title="Permalink to this headline">¶</a></h2>
<p><em>核函数</em> 可以是以下任何形式：:</p>
<blockquote>
<div><ul class="simple">
<li>线性: <span class="math">\langle x, x'\rangle</span>.</li>
<li>多项式: <span class="math">(\gamma \langle x, x'\rangle + r)^d</span>.
<span class="math">d</span> 是关键词 <code class="docutils literal notranslate"><span class="pre">degree</span></code>, <span class="math">r</span> 指定 <code class="docutils literal notranslate"><span class="pre">coef0</span></code>。</li>
<li>rbf: <span class="math">\exp(-\gamma \|x-x'\|^2)</span>. <span class="math">\gamma</span> 是关键词 <code class="docutils literal notranslate"><span class="pre">gamma</span></code>, 必须大于 0。</li>
<li>sigmoid (<span class="math">\tanh(\gamma \langle x,x'\rangle + r)</span>),
其中 <span class="math">r</span> 指定 <code class="docutils literal notranslate"><span class="pre">coef0</span></code>。</li>
</ul>
</div></blockquote>
<p>初始化时，不同内核由不同的函数名调用:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">linear_svc</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear_svc</span><span class="o">.</span><span class="n">kernel</span>
<span class="go">&#39;linear&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rbf_svc</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rbf_svc</span><span class="o">.</span><span class="n">kernel</span>
<span class="go">&#39;rbf&#39;</span>
</pre></div>
</div>
<div class="section" id="id10">
<h3>1.4.6.1. 自定义核<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<p>您可以自定义自己的核，通过使用python函数作为内核或者通过预计算 Gram 矩阵。</p>
<p>自定义内核的分类器和别的分类器一样，除了下面这几点:</p>
<blockquote>
<div><ul class="simple">
<li>空间 <code class="docutils literal notranslate"><span class="pre">support_vectors_</span></code> 现在不是空的, 只有支持向量的索引被存储在 <code class="docutils literal notranslate"><span class="pre">support_</span></code></li>
<li>请把 <code class="docutils literal notranslate"><span class="pre">fit()</span></code> 模型中的第一个参数的引用（不是副本）存储为将来的引用。
如果在 <code class="docutils literal notranslate"><span class="pre">fit()</span></code> 和 <code class="docutils literal notranslate"><span class="pre">predict()</span></code> 之间有数组发生改变，您将会碰到意料外的结果。</li>
</ul>
</div></blockquote>
<div class="section" id="python">
<h4>1.4.6.1.1. 使用 python 函数作为内核<a class="headerlink" href="#python" title="Permalink to this headline">¶</a></h4>
<p>在构造时，您同样可以通过一个函数传递到关键词 <code class="docutils literal notranslate"><span class="pre">kernel</span></code> ，来使用您自己定义的内核。</p>
<p>您的内核必须要以两个矩阵作为参数，大小分别是
<code class="docutils literal notranslate"><span class="pre">(n_samples_1,</span> <span class="pre">n_features)</span></code>, <code class="docutils literal notranslate"><span class="pre">(n_samples_2,</span> <span class="pre">n_features)</span></code>
和返回一个内核矩阵，shape 是 <code class="docutils literal notranslate"><span class="pre">(n_samples_1,</span> <span class="pre">n_samples_2)</span></code>.</p>
<p>以下代码定义一个线性核，和构造一个使用该内核的分类器例子:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">svm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">my_kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">my_kernel</span><span class="p">)</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">例子:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/svm/plot_custom_kernel.html#sphx-glr-auto-examples-svm-plot-custom-kernel-py"><span class="std std-ref">SVM with custom kernel</span></a>.</li>
</ul>
</div>
</div>
<div class="section" id="gram">
<h4>1.4.6.1.2. 使用 Gram 矩阵<a class="headerlink" href="#gram" title="Permalink to this headline">¶</a></h4>
<p>在适应算法中，设置 <code class="docutils literal notranslate"><span class="pre">kernel='precomputed'</span></code> 和把 X 替换为 Gram 矩阵。
此时，必须要提供在 <em>所有</em> 训练矢量和测试矢量中的内核值。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">svm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;precomputed&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 线性内核计算</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gram</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">gram</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="c1"># doctest: +NORMALIZE_WHITESPACE</span>
<span class="go">SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,</span>
<span class="go">    decision_function_shape=&#39;ovr&#39;, degree=3, gamma=&#39;auto&#39;,</span>
<span class="go">    kernel=&#39;precomputed&#39;, max_iter=-1, probability=False,</span>
<span class="go">    random_state=None, shrinking=True, tol=0.001, verbose=False)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 预测训练样本</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">gram</span><span class="p">)</span>
<span class="go">array([0, 1])</span>
</pre></div>
</div>
</div>
<div class="section" id="rbf">
<h4>1.4.6.1.3. RBF 内核参数<a class="headerlink" href="#rbf" title="Permalink to this headline">¶</a></h4>
<p>当用 <em>径向基</em> (RBF) 内核去训练 SVM，有两个参数必须要去考虑： <code class="docutils literal notranslate"><span class="pre">C</span></code> 惩罚系数和 <code class="docutils literal notranslate"><span class="pre">gamma</span></code> 。参数 <code class="docutils literal notranslate"><span class="pre">C</span></code> ，
通用在所有 SVM 内核，与决策表面的简单性相抗衡，可以对训练样本的误分类进行有价转换。
较小的 <code class="docutils literal notranslate"><span class="pre">C</span></code> 会使决策表面更平滑，同时较高的 <code class="docutils literal notranslate"><span class="pre">C</span></code> 旨在正确地分类所有训练样本。 <code class="docutils literal notranslate"><span class="pre">Gamma</span></code> 定义了单一
训练样本能起到多大的影响。较大的 <code class="docutils literal notranslate"><span class="pre">gamma</span></code> 会更让其他样本受到影响。</p>
<p>选择合适的 <code class="docutils literal notranslate"><span class="pre">C</span></code> 和 <code class="docutils literal notranslate"><span class="pre">gamma</span></code> ，对SVM的性能起到很关键的作用。建议一点是
使用 &nbsp;<a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection.GridSearchCV</span></code></a> 与 <code class="docutils literal notranslate"><span class="pre">C</span></code> 和 <code class="docutils literal notranslate"><span class="pre">gamma</span></code> 相隔
成倍差距从而选择到好的数值。</p>
<div class="topic">
<p class="topic-title first">例子:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/svm/plot_rbf_parameters.html#sphx-glr-auto-examples-svm-plot-rbf-parameters-py"><span class="std std-ref">RBF SVM parameters</span></a></li>
</ul>
</div>
</div>
</div>
</div>
<div class="section" id="svm-mathematical-formulation">
<span id="id11"></span><h2>1.4.7. 数学公式<a class="headerlink" href="#svm-mathematical-formulation" title="Permalink to this headline">¶</a></h2>
<p>支持向量机在高维度或无穷维度空间中，构建一个超平面或者一系列的超平面，可以用于分类、回归或者别的任务。
直观地看，借助超平面去实现一个好的分割， 能在任意类别中使最为接近的训练数据点具有最大的间隔距离（即所
谓的函数余量），这样做是因为通常更大的余量能有更低的分类器泛化误差。</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="modules/../auto_examples/svm/images/sphx_glr_plot_separating_hyperplane_001.png"><img alt="modules/../auto_examples/svm/images/sphx_glr_plot_separating_hyperplane_001.png" src="modules/../auto_examples/svm/images/sphx_glr_plot_separating_hyperplane_001.png" /></a>
</div>
<div class="section" id="svc">
<h3>1.4.7.1. SVC<a class="headerlink" href="#svc" title="Permalink to this headline">¶</a></h3>
<p>在两类中，给定训练向量 <span class="math">x_i \in \mathbb{R}^p</span>, i=1,…, n, 和一个向量 <span class="math">y \in \{1, -1\}^n</span>, SVC能解决
如下主要问题:</p>
<div class="math">
<p><span class="math">\min_ {w, b, \zeta} \frac{1}{2} w^T w + C \sum_{i=1}^{n} \zeta_i



\textrm {subject to } &amp; y_i (w^T \phi (x_i) + b) \geq 1 - \zeta_i,\\
&amp; \zeta_i \geq 0, i=1, ..., n</span></p>
</div><p>它的对偶是</p>
<div class="math">
<p><span class="math">\min_{\alpha} \frac{1}{2} \alpha^T Q \alpha - e^T \alpha


\textrm {subject to } &amp; y^T \alpha = 0\\
&amp; 0 \leq \alpha_i \leq C, i=1, ..., n</span></p>
</div><p>其中 <span class="math">e</span> 是所有的向量， <span class="math">C &gt; 0</span> 是上界，<span class="math">Q</span> 是一个 <span class="math">n</span> 由 <span class="math">n</span> 个半正定矩阵，
而 <span class="math">Q_{ij} \equiv y_i y_j K(x_i, x_j)</span> ，其中 <span class="math">K(x_i, x_j) = \phi (x_i)^T \phi (x_j)</span> 是内核。所以训练向量是通过函数 <span class="math">\phi</span>，间接反映到一个更高维度的（无穷的）空间。</p>
<p>决策函数是:</p>
<div class="math">
<p><span class="math">\operatorname{sgn}(\sum_{i=1}^n y_i \alpha_i K(x_i, x) + \rho)</span></p>
</div><p>注意:</p>
<p>虽然这些SVM模型是从 <a class="reference external" href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/">libsvm</a> 和 <a class="reference external" href="http://www.csie.ntu.edu.tw/~cjlin/liblinear/">liblinear</a> 中派生出来，使用了 <code class="docutils literal notranslate"><span class="pre">C</span></code> 作为调整参数，但是大多数的
攻击使用了 <code class="docutils literal notranslate"><span class="pre">alpha</span></code>。两个模型的正则化量之间的精确等价，取决于模型优化的准确目标函数。举
个例子，当使用的估计器是 <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.linear_model.Ridge</span></code> 做回归时，他们之间的相关性是 <span class="math">C = \frac{1}{alpha}</span>。</p>
<p>这些参数能通过成员 <code class="docutils literal notranslate"><span class="pre">dual_coef_</span></code>、 <code class="docutils literal notranslate"><span class="pre">support_vectors_</span></code> 、 <code class="docutils literal notranslate"><span class="pre">intercept_</span></code> 去访问，这些成员分别控制了输出 <span class="math">y_i \alpha_i</span>、支持向量和无关项 <span class="math">\rho</span> ：</p>
<div class="topic">
<p class="topic-title first">参考文献:</p>
<ul class="simple">
<li><a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.17.7215">“Automatic Capacity Tuning of Very Large VC-dimension Classifiers”</a>,
I. Guyon, B. Boser, V. Vapnik - Advances in neural information
processing 1993.</li>
<li><a class="reference external" href="http://link.springer.com/article/10.1007%2FBF00994018">“Support-vector networks”</a>,
C. Cortes, V. Vapnik - Machine Learning, 20, 273-297 (1995).</li>
</ul>
</div>
</div>
<div class="section" id="nusvc">
<h3>1.4.7.2. NuSVC<a class="headerlink" href="#nusvc" title="Permalink to this headline">¶</a></h3>
<p>我们引入一个新的参数 <span class="math">\nu</span> 来控制支持向量的数量和训练误差。参数 <span class="math">\nu \in (0,
1]</span> 是训练误差分数的上限和支持向量分数的下限。</p>
<p>可以看出， <span class="math">\nu</span>-SVC 公式是 <span class="math">C</span>-SVC 的再参数化，所以数学上是等效的。</p>
</div>
<div class="section" id="svr">
<h3>1.4.7.3. SVR<a class="headerlink" href="#svr" title="Permalink to this headline">¶</a></h3>
<p>给定训练向量 <span class="math">x_i \in \mathbb{R}^p</span>, i=1,…, n，向量 <span class="math">y \in \mathbb{R}^n</span> <span class="math">\varepsilon</span>-SVR
能解决以下的主要问题：</p>
<div class="math">
<p><span class="math">\min_ {w, b, \zeta, \zeta^*} \frac{1}{2} w^T w + C \sum_{i=1}^{n} (\zeta_i + \zeta_i^*)



\textrm {subject to } &amp; y_i - w^T \phi (x_i) - b \leq \varepsilon + \zeta_i,\\
                      &amp; w^T \phi (x_i) + b - y_i \leq \varepsilon + \zeta_i^*,\\
                      &amp; \zeta_i, \zeta_i^* \geq 0, i=1, ..., n</span></p>
</div><p>它的对偶是</p>
<div class="math">
<p><span class="math">\min_{\alpha, \alpha^*} \frac{1}{2} (\alpha - \alpha^*)^T Q (\alpha - \alpha^*) + \varepsilon e^T (\alpha + \alpha^*) - y^T (\alpha - \alpha^*)


\textrm {subject to } &amp; e^T (\alpha - \alpha^*) = 0\\
&amp; 0 \leq \alpha_i, \alpha_i^* \leq C, i=1, ..., n</span></p>
</div><p>其中 <span class="math">e</span> 是所有的向量， <span class="math">C &gt; 0</span> 是上界，<span class="math">Q</span> 是一个 <span class="math">n</span> 由 <span class="math">n</span> 个半正定矩阵，
而 <span class="math">Q_{ij} \equiv K(x_i, x_j) = \phi (x_i)^T \phi (x_j)</span> 是内核。
所以训练向量是通过函数 <span class="math">\phi</span>，间接反映到一个更高维度的（无穷的）空间。</p>
<p>决策函数是:</p>
<div class="math">
<p><span class="math">\sum_{i=1}^n (\alpha_i - \alpha_i^*) K(x_i, x) + \rho</span></p>
</div><p>这些参数能通过成员 <code class="docutils literal notranslate"><span class="pre">dual_coef_</span></code>、 <code class="docutils literal notranslate"><span class="pre">support_vectors_</span></code> 、 <code class="docutils literal notranslate"><span class="pre">intercept_</span></code> 去访问，这些
成员分别控制了不同的 <span class="math">\alpha_i - \alpha_i^*</span>、支持向量和无关项 <span class="math">\rho</span>：</p>
<div class="topic">
<p class="topic-title first">参考文献:</p>
<ul class="simple">
<li><a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.114.4288">“A Tutorial on Support Vector Regression”</a>,
Alex J. Smola, Bernhard Schölkopf - Statistics and Computing archive
Volume 14 Issue 3, August 2004, p. 199-222.</li>
</ul>
</div>
</div>
</div>
<div class="section" id="svm-implementation-details">
<span id="id12"></span><h2>1.4.8. 实现细节<a class="headerlink" href="#svm-implementation-details" title="Permalink to this headline">¶</a></h2>
<p>在底层里，我们使用 <a class="reference external" href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/">libsvm</a> 和 <a class="reference external" href="http://www.csie.ntu.edu.tw/~cjlin/liblinear/">liblinear</a> 去处理所有的计算。这些库都使用了 C 和 Cython 去包装。</p>
<div class="topic">
<p class="topic-title first">参考文献:</p>
<p>有关实现的描述和使用算法的细节，请参考</p>
<blockquote>
<div><ul class="simple">
<li><a class="reference external" href="http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf">LIBSVM: A Library for Support Vector Machines</a>.</li>
<li><a class="reference external" href="http://www.csie.ntu.edu.tw/~cjlin/liblinear/">LIBLINEAR – A Library for Large Linear Classification</a>.</li>
</ul>
</div></blockquote>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>

      <!-- 评论留言区代码 start -->
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zNDAwMi8xMDU0MA==">
        <script type="text/javascript">
        (function(d, s) {
            var j, e = d.getElementsByTagName(s)[0];

            if (typeof LivereTower === 'function') { return; }

            j = d.createElement(s);
            j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
            j.async = true;

            e.parentNode.insertBefore(j, e);
        })(document, 'script');
        </script>
      </div>
      <!-- 评论留言区代码 end -->

    </div>

    <!-- 提 PR 时按原来文档的字母排序 -->

    

    

    

    

    

    
    <!-- modules/svm.html -->
    <div class="apachecn_doc_right">
      校验者: <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/weiyd">@尔了个达</a><br/>
                 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@维</a><br/>
                 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@子浪</a><br/>
                 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@小瑶</a><br/>
      翻译者: <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@Damon</a><br/>
                 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@Leon晋</a><br/>
    </div>
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    
    
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

  </div>

  <div class="footer">
      &copy; 2007 - 2017, scikit-learn developers (BSD License).
    <a href="../_sources/modules/svm.rst.txt" rel="nofollow">Show this page source</a>
  </div>
   <div class="rel">
  
  <div class="buttonPrevious">
    <a href="kernel_ridge.html">Previous
    </a>
  </div>
  <div class="buttonNext">
    <a href="sgd.html">Next
    </a>
  </div>
  
   </div>

  <!-- google analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  
    ga('create', 'UA-102475051-5', 'auto');
    ga('send', 'pageview');
  
  </script>
  
  <!-- baidu tongji -->
  <script>
  var _hmt = _hmt || [];
  (function() {
    var hm = document.createElement("script");
    hm.src = "https://hm.baidu.com/hm.js?9cbab13b4d28a9811ae1d2d2176dab66";
    var s = document.getElementsByTagName("script")[0]; 
    s.parentNode.insertBefore(hm, s);
  })();
  </script>

  <!-- baidu push -->
  <script>
  (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
          bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      }
      else {
          bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
  })();
  </script>
  </body>
</html>